## Me:

```
hello-world (main) ✗)./quickstart.sh
==================================
LangChain批评演示 - 快速启动向导
==================================

📍 步骤1: 检查Python环境...
✅ 找到Python: Python 3.13.5

📍 步骤2: 设置虚拟环境...
✅ 虚拟环境已存在
激活虚拟环境...
✅ 虚拟环境已激活

📍 步骤3: 安装依赖包...
正在安装OpenAI库（用于DeepSeek API）...

[notice] A new release of pip is available: 25.1.1 -> 25.3
[notice] To update, run: pip install --upgrade pip
正在安装LangChain...

[notice] A new release of pip is available: 25.1.1 -> 25.3
[notice] To update, run: pip install --upgrade pip
正在安装SerpAPI（Agent演示需要）...

[notice] A new release of pip is available: 25.1.1 -> 25.3
[notice] To update, run: pip install --upgrade pip
✅ 依赖安装完成

📍 步骤4: 检查API密钥...
⚠️  未检测到DEEPSEEK_API_KEY环境变量

请输入你的DeepSeek API密钥（可以从 https://platform.deepseek.com 获取）：

✅ API密钥已设置（当前会话有效）

⚠️  未检测到SERPAPI_API_KEY（Agent演示需要）

是否现在设置SERPAPI_API_KEY？(y/n)
（可以从 https://serpapi.com 注册获取免费密钥，跳过则无法运行Agent演示）
y
请输入你的SerpAPI密钥：

✅ SerpAPI密钥已设置

==================================
🎯 准备完成！请选择要运行的演示：
==================================

1. 运行主演示 - 缺点1-3对比
   （过度使用对象类、Prompt模板复杂、对话记忆复杂）

2. 运行Agent演示 - 缺点4-5对比
   （Agent性能问题、实现不透明）

3. 运行改进版演示 - DeepSeek官方库优雅解决方案 ⭐️ NEW
   （展示如何用DeepSeek官方库优雅解决缺点1-3）

4. 运行全部演示

5. 退出

请输入选项 (1-5): 3

🚀 运行改进版演示...

================================================================================
LangChain 缺点改进演示 - DeepSeek官方库优雅解决方案
================================================================================

✨ 改进方案1: 简洁直接的API调用
--------------------------------------------------------------------------------
问题: LangChain需要创建ChatOpenAI对象和HumanMessage对象
解决: DeepSeek官方库直接使用字典，简洁明了

代码示例:

from openai import OpenAI

client = OpenAI(
    api_key=os.environ.get("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)

# 直接使用字典，无需创建额外的消息对象
messages = [{"role": "user", "content": "Translate this sentence from English to French. I love programming."}]
response = client.chat.completions.create(
    model="deepseek-chat",
    messages=messages,
    temperature=0
)
print(response.choices[0].message.content)


执行结果:
✅ J'adore la programmation.
⏱️  耗时: 1.15秒

💡 优势:
   ✓ 无需学习额外的对象类（ChatOpenAI、HumanMessage）
   ✓ 代码更短、更直观
   ✓ 使用标准的OpenAI API，通用性强
   ✓ 易于调试和维护


================================================================================
✨ 改进方案2: Python原生f-strings构建Prompt
--------------------------------------------------------------------------------
问题: LangChain使用ChatPromptTemplate、SystemMessagePromptTemplate等多层嵌套
解决: 直接使用Python f-strings，简单高效

代码示例:

# 使用f-strings构建prompt
input_language = "English"
output_language = "French"
text = "I love programming."

messages = [
    {
        "role": "system",
        "content": f"You are a helpful assistant that translates {input_language} to {output_language}."
    },
    {
        "role": "user",
        "content": text
    }
]

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=messages,
    temperature=0
)
print(response.choices[0].message.content)


执行结果:
✅ J'adore la programmation.
⏱️  耗时: 1.04秒

💡 优势:
   ✓ 无需学习ChatPromptTemplate、SystemMessagePromptTemplate等复杂类
   ✓ 使用Python开发者熟悉的f-strings
   ✓ 代码更少、更易读
   ✓ 灵活性更高，可以轻松组合复杂的prompt


================================================================================
✨ 改进方案3: 使用简单列表管理对话历史
--------------------------------------------------------------------------------
问题: LangChain使用RunnableWithMessageHistory、MessagesPlaceholder等复杂概念
解决: 直接使用Python列表保存消息历史，简单透明

代码示例:

# 使用简单的列表保存对话历史
conversation_history = [
    {
        "role": "system",
        "content": "The following is a friendly conversation between a human and an AI. "
                   "The AI is talkative and provides lots of specific details from its context."
    }
]

# 第一轮对话
user_input = "Hi there!"
conversation_history.append({"role": "user", "content": user_input})

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=conversation_history,
    temperature=0
)

assistant_response = response.choices[0].message.content
conversation_history.append({"role": "assistant", "content": assistant_response})
print(f"AI: {assistant_response}")

# 第二轮对话
user_input = "What's 2+2?"
conversation_history.append({"role": "user", "content": user_input})

response = client.chat.completions.create(
    model="deepseek-chat",
    messages=conversation_history,
    temperature=0
)

assistant_response = response.choices[0].message.content
conversation_history.append({"role": "assistant", "content": assistant_response})
print(f"AI: {assistant_response}")

# 查看完整的对话历史
print(f"\n对话历史共 {len(conversation_history)} 条消息")


执行结果:
👤 User: Hi there!
🤖 AI: Hello! 👋 It's great to meet you! How can I help you today? Whether you have questions, need advice, or just want to chat, I'm here for you. What's on your mind?
⏱️  耗时: 2.59秒

👤 User: What's 2+2?
🤖 AI: That's a classic! 2 + 2 equals **4**. 😊

If you're feeling playful, I could also say it's "a small but mighty number" or "the answer to one of life's simplest yet most satisfying equations." Want to explore something more challenging or fun?
⏱️  耗时: 3.23秒

📝 完整对话历史 (5 条消息):
   1. ⚙️ [system] The following is a friendly conversation between a human and...
   2. 👤 [user] Hi there!
   3. 🤖 [assistant] Hello! 👋 It's great to meet you! How can I help you today? W...
   4. 👤 [user] What's 2+2?
   5. 🤖 [assistant] That's a classic! 2 + 2 equals **4**. 😊

If you're feeling p...

💡 优势:
   ✓ 无需学习RunnableWithMessageHistory、MessagesPlaceholder等概念
   ✓ 对话历史清晰可见，易于调试
   ✓ 可以轻松实现自定义的历史管理策略（如限制长度、保存到数据库等）
   ✓ 完全掌控数据流，不依赖黑盒抽象


================================================================================
🚀 进阶示例: 实现实用的对话历史管理
--------------------------------------------------------------------------------

代码示例:

class SimpleConversation:
    def __init__(self, client, system_prompt="", max_history=20):
        self.client = client
        self.max_history = max_history
        self.messages = []
        if system_prompt:
            self.messages.append({"role": "system", "content": system_prompt})
    
    def chat(self, user_input, temperature=0.7):
        self.messages.append({"role": "user", "content": user_input})
        response = self.client.chat.completions.create(
            model="deepseek-chat",
            messages=self.messages,
            temperature=temperature
        )
        assistant_response = response.choices[0].message.content
        self.messages.append({"role": "assistant", "content": assistant_response})
        self._trim_history()
        return assistant_response
    
    def _trim_history(self):
        # 保持历史长度在限制范围内
        system_messages = [msg for msg in self.messages if msg["role"] == "system"]
        other_messages = [msg for msg in self.messages if msg["role"] != "system"]
        if len(other_messages) > self.max_history:
            other_messages = other_messages[-self.max_history:]
        self.messages = system_messages + other_messages

# 使用示例
conv = SimpleConversation(
    client,
    system_prompt="You are a helpful math tutor.",
    max_history=10
)

response = conv.chat("What is 5 + 3?")
print(response)


执行结果:

👤 User: What is 5 + 3?
🤖 AI: 5 + 3 = **8**
⏱️  耗时: 1.12秒

👤 User: What about if I multiply that by 2?
🤖 AI: You said "that" refers to the previous result (8).  

So:  
\[
8 \times 2 = 16
\]

**Answer:** 16
⏱️  耗时: 2.17秒

👤 User: And divide by 4?
🤖 AI: You’re now dividing the previous result (16) by 4.

\[
16 \div 4 = 4
\]

**Answer:** 4
⏱️  耗时: 3.32秒

📝 最终对话历史: 7 条消息

💡 进阶方案的优势:
   ✓ 封装了常用的对话管理逻辑
   ✓ 自动管理历史长度，避免token溢出
   ✓ 代码简洁（不到50行），易于理解和修改
   ✓ 完全透明，没有隐藏的魔法
   ✓ 可以轻松扩展（如添加流式输出、保存到数据库等）

================================================================================
📊 总结：DeepSeek官方库 vs LangChain
================================================================================

┌────────────────────┬──────────────────────────┬─────────────────────────┐
│ 功能               │ LangChain方式            │ DeepSeek官方库方式      │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ 基本调用           │ ChatOpenAI + HumanMessage│ 简单字典 + OpenAI客户端 │
│                    │ (需要学习2个新类)        │ (标准OpenAI API)        │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ Prompt构建         │ ChatPromptTemplate +     │ Python原生f-strings     │
│                    │ SystemMessagePromptTemplate│ (无需额外学习)         │
│                    │ + HumanMessagePromptTemplate│                       │
│                    │ (需要学习3个新类)        │                         │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ 对话历史管理       │ RunnableWithMessageHistory│ 简单的Python列表        │
│                    │ + MessagesPlaceholder +  │ (完全透明、易于调试)    │
│                    │ InMemoryChatMessageHistory│                        │
│                    │ (需要学习多个复杂概念)   │                         │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ 学习曲线           │ 陡峭（大量抽象概念）     │ 平缓（标准Python+API）  │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ 代码可读性         │ 较差（多层抽象）         │ 优秀（简洁直观）        │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ 调试难度           │ 困难（黑盒抽象）         │ 简单（透明可控）        │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ 灵活性             │ 受框架限制               │ 完全自由                │
├────────────────────┼──────────────────────────┼─────────────────────────┤
│ API稳定性          │ 频繁变化（v0.x→v1.x      │ 稳定（标准OpenAI API）  │
│                    │ 很多API被废弃）          │                         │
└────────────────────┴──────────────────────────┴─────────────────────────┘

🎯 核心结论:

1. ✅ 缺点1（过度使用对象类）已解决
   → DeepSeek官方库使用简单字典，无需额外的对象包装

2. ✅ 缺点2（Prompt模板复杂）已解决
   → 使用Python原生f-strings，简洁高效

3. ✅ 缺点3（对话记忆管理复杂）已解决
   → 使用简单的Python列表，完全透明可控

💡 建议:

对于简单到中等复杂度的LLM应用，直接使用DeepSeek官方库（或OpenAI SDK）是更好的选择：
  • 代码更少、更清晰
  • 学习成本更低
  • 调试更容易
  • 性能更可控
  • API更稳定

只有在需要LangChain的特定高级功能时（如复杂的工具链、特殊的数据处理流程等），
才考虑引入LangChain的额外复杂度。

================================================================================
✅ 改进演示完成!
================================================================================

==================================
✅ 演示完成！
==================================

💡 提示：
   - 要重新运行，请执行: ./quickstart.sh
   - 查看详细文档: cat README.md
   - 退出虚拟环境: deactivate
```