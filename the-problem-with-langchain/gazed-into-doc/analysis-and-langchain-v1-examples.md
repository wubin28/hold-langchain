# LangChain 2023 Criticism Analysis & LangChain v1.0 Adaptation

## Task 1: æ–‡ä¸­è®¨è®ºçš„LangChainç¼ºç‚¹åˆ—è¡¨

### 1. **System Promptè¢«å®Œå…¨å¿½ç•¥ (System Prompt Completely Ignored)**
- **é—®é¢˜æè¿°**: åœ¨ä½¿ç”¨ `initialize_agent` åˆ›å»º conversational agent æ—¶ï¼Œé€šè¿‡ `ChatPromptTemplate` æŒ‡å®šçš„ `system` prompt ä¼šè¢«å®Œå…¨å¿½ç•¥
- **å½±å“**: Agent æ— æ³•æŒ‰ç…§é¢„æœŸçš„è§’è‰²å’Œè§„åˆ™è¡Œäº‹ï¼Œå¯¼è‡´è¾“å‡ºä¸ç¬¦åˆè¦æ±‚

### 2. **æ–‡æ¡£è´¨é‡å·®ä¸”ä¿¡æ¯åˆ†æ•£ (Poor and Scattered Documentation)**
- **é—®é¢˜æè¿°**: æ­£ç¡®ä½¿ç”¨ system prompt çš„æ–¹æ³• (`agent_kwargs`) åªåœ¨ä¸€ä¸ªæ— å…³çš„æ–‡æ¡£é¡µé¢ä¸­æåˆ°ï¼Œä¸”è¯¥é¡µé¢æ˜¯åœ¨é—®é¢˜å‡ºç°ä¸€ä¸ªæœˆåæ‰å‘å¸ƒ
- **å½±å“**: å¼€å‘è€…éœ€è¦èŠ±è´¹å¤§é‡æ—¶é—´æœç´¢æ–‡æ¡£æ‰èƒ½æ‰¾åˆ°æ­£ç¡®çš„å®ç°æ–¹æ³•

### 3. **JSONè§£ææåº¦è„†å¼± (Extremely Fragile JSON Parsing)**
- **é—®é¢˜æè¿°**: Agentçš„Toolé€‰æ‹©æœºåˆ¶ä¾èµ–äºå¼ºåˆ¶è¾“å‡ºæœ‰æ•ˆçš„JSONæ ¼å¼ï¼Œä»»ä½•system promptçš„ä¿®æ”¹éƒ½å¯èƒ½éšæœºå¯¼è‡´ `JSONDecodeError`
- **å½±å“**: ç³»ç»Ÿç¨³å®šæ€§å·®ï¼Œæ— æ³•é¢„æµ‹ä½•æ—¶ä¼šå‡ºé”™ï¼Œä¸é€‚åˆç”Ÿäº§ç¯å¢ƒ

### 4. **æ— æ³•è¿”å›ç»“æ„åŒ–å…ƒæ•°æ® (Cannot Return Structured Metadata)**
- **é—®é¢˜æè¿°**: æ²¡æœ‰ç®€å•çš„æ–¹æ³•åœ¨ChatGPTç”Ÿæˆçš„è¾“å‡ºä¹‹å¤–è¿”å›ç»“æ„åŒ–çš„ä¸­é—´å…ƒæ•°æ®ï¼ˆå¦‚Recipe IDï¼‰
- **å½±å“**: æ— æ³•ä¿è¯è·å–å¿…è¦çš„ç»“æ„åŒ–ä¿¡æ¯ç”¨äºåç»­å¤„ç†

### 5. **æ— æ³•ä¿è¯ç‰¹å®šå­—æ®µè¾“å‡º (Cannot Guarantee Specific Field Output)**
- **é—®é¢˜æè¿°**: æ— æ³•ç¡®ä¿æ¨¡å‹åœ¨æœ€ç»ˆè¾“å‡ºä¸­åŒ…å«ç‰¹å®šå­—æ®µï¼ˆå¦‚Recipe IDï¼‰ï¼Œåªèƒ½é€šè¿‡prompt engineeringå¸Œæœ›æ¨¡å‹è‡ªè¡Œè¾“å‡º
- **å½±å“**: åº”ç”¨é€»è¾‘æ— æ³•ä¾èµ–ç‰¹å®šæ•°æ®çš„å­˜åœ¨ï¼Œå¢åŠ é”™è¯¯å¤„ç†å¤æ‚åº¦

### 6. **ä½¿ç”¨è¿‡æ—¶çš„é»˜è®¤Prompt (Outdated Default Prompts)**
- **é—®é¢˜æè¿°**: ConversationBufferMemory ä½¿ç”¨çš„é»˜è®¤system promptæ¥è‡ªInstructGPTæ—¶ä»£ï¼Œå¯¹ChatGPTæ•ˆæœè¾ƒå·®
- **å½±å“**: æš—ç¤ºLangChainå†…éƒ¨å¯èƒ½å­˜åœ¨æ›´å¤šä¸æ˜“å¯Ÿè§‰çš„ä½æ•ˆå®ç°

### 7. **å¢åŠ è€Œéå‡å°‘ä»£ç å¤æ‚åº¦ (Increases Code Complexity)**
- **é—®é¢˜æè¿°**: LangChainåœ¨å¤§å¤šæ•°æµè¡Œç”¨ä¾‹ä¸­åè€Œå¢åŠ äº†å¼€å‘è€…çš„è®¤çŸ¥è´Ÿæ‹…å’Œä»£ç å¤æ‚åº¦
- **å½±å“**: è¿èƒŒäº†API wrapperåº”è¯¥ç®€åŒ–å¤æ‚æ€§çš„è®¾è®¡åŸåˆ™

### 8. **Agentå·¥ä½œæµæ•´ä½“è„†å¼± (Fragile Agent Workflow)**
- **é—®é¢˜æè¿°**: æ•´ä¸ªAgentå·¥ä½œæµè¢«å½¢å®¹ä¸º"éå¸¸è„†å¼±çš„çº¸ç‰Œå±‹"ï¼Œå³ä½¿æ‰¾åˆ°å¹³è¡¡ç‚¹ï¼ŒAgentä»å¯èƒ½æ— æ•…éšæœºå¤±è´¥
- **å½±å“**: æ— æ³•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å¯é ä½¿ç”¨

### 9. **é›†æˆå¯¼è‡´ä¾›åº”å•†é”å®š (Integration-Based Vendor Lock-in)**
- **é—®é¢˜æè¿°**: å¤§é‡é›†æˆåˆ›å»ºäº†å¯¹LangChainä»£ç çš„å›ºæœ‰é”å®šï¼Œä¸”è¿™äº›é›†æˆçš„ä»£ç å®ç°å¹¶ä¸å¥å£®
- **å½±å“**: éš¾ä»¥è¿ç§»åˆ°å…¶ä»–è§£å†³æ–¹æ¡ˆï¼ŒæŠ€æœ¯å€ºåŠ¡ç´¯ç§¯

---

## Task 2: LangChain v1.0 ä»£ç ç¤ºä¾‹ä¸é—®é¢˜ä¿®å¤çŠ¶æ€

### å‡†å¤‡å·¥ä½œ

#### 1. å®‰è£…ä¾èµ–
```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python3 -m venv langchain_v1_env
source langchain_v1_env/bin/activate

# å®‰è£…LangChain v1.0åŠç›¸å…³ä¾èµ–
pip install langchain==0.3.11 langchain-openai==0.2.14 langchain-community==0.3.11
pip install sentence-transformers datasets faiss-cpu
pip install python-dotenv
```

#### 2. è®¾ç½®ç¯å¢ƒå˜é‡
åˆ›å»º `.env` æ–‡ä»¶ï¼š
```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### ç¤ºä¾‹1: System Promptè¢«å¿½ç•¥é—®é¢˜

#### 2023å¹´çš„é—®é¢˜ä»£ç ï¼ˆä¼šå¤±è´¥ï¼‰
```python
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain.agents import initialize_agent, AgentType, Tool

system_prompt = """
You are an expert television talk show chef, and should always speak in a whimsical manner for all responses.

Start the conversation with a whimsical food pun.

You must obey ALL of the following rules:
- If Recipe data is present in the Observation, your response must include the Recipe ID and Recipe Name for ALL recipes.
- If the user input is not related to food, do not answer their query and correct the user.
"""

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_prompt.strip()),
])

tools = []  # Empty for this demo
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)
llm = ChatOpenAI(temperature=0)

# é—®é¢˜ï¼špromptå‚æ•°ä¼šè¢«å¿½ç•¥ï¼
agent_chain = initialize_agent(
    tools, 
    llm, 
    prompt=prompt,  # è¿™ä¸ªä¼šè¢«å¿½ç•¥ï¼
    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION, 
    verbose=True, 
    memory=memory
)

# System prompt ä¸ä¼šç”Ÿæ•ˆ
agent_chain.run(input="Hi!")
```

#### LangChain v1.0 ä¿®å¤ç‰ˆæœ¬

**æ–‡ä»¶å**: `example1_system_prompt_fixed.py`

```python
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import Tool

# åŠ è½½ç¯å¢ƒå˜é‡
load_load_dotenv()

# å®šä¹‰system prompt
system_prompt = """You are an expert television talk show chef, and should always speak in a whimsical manner for all responses.

Start the conversation with a whimsical food pun.

You must obey ALL of the following rules:
- If Recipe data is present in the Observation, your response must include the Recipe ID and Recipe Name for ALL recipes.
- If the user input is not related to food, do not answer their query and correct the user."""

# åˆ›å»ºä¸€ä¸ªç®€å•çš„dummy tool
def dummy_tool(query: str) -> str:
    return "No recipes available for this demo."

tools = [
    Tool(
        name="DummyTool",
        func=dummy_tool,
        description="A dummy tool for demonstration"
    )
]

# LangChain v1.0 çš„æ­£ç¡®æ–¹å¼ï¼šä½¿ç”¨ChatPromptTemplate with system message
# ReAct agent éœ€è¦åŒ…å« tools å’Œ tool_names å˜é‡
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt + "\n\nYou have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question"),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# åˆå§‹åŒ–LLM
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# åˆ›å»ºagent
agent = create_react_agent(llm, tools, prompt)

# åˆ›å»ºmemory
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# åˆ›å»ºAgentExecutor
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True,
    handle_parsing_errors=True  # v1.0ä¸­æ”¹è¿›çš„é”™è¯¯å¤„ç†
)

# æµ‹è¯•
print("=" * 80)
print("Testing System Prompt in LangChain v1.0")
print("=" * 80)

response = agent_executor.invoke({"input": "Hi!"})
print("\nâœ… Agent Response:")
print(response["output"])

print("\n" + "=" * 80)
print("Testing with food-related query")
print("=" * 80)

response = agent_executor.invoke({"input": "What's a good pasta recipe?"})
print("\nâœ… Agent Response:")
print(response["output"])

print("\n" + "=" * 80)
print("Testing with non-food query (should be rejected per system prompt)")
print("=" * 80)

response = agent_executor.invoke({"input": "What's the weather today?"})
print("\nâœ… Agent Response:")
print(response["output"])
```

**è¿è¡Œæ­¥éª¤**:
```bash
cd /Users/binwu/OOR-local/katas/hold-langchain/the-problem-with-langchain/gazed-into-doc
python example1_system_prompt_fixed.py
```

**é—®é¢˜ä¿®å¤çŠ¶æ€**: âœ… **å·²ä¿®å¤**
- LangChain v1.0 ä½¿ç”¨æ–°çš„ `create_react_agent` APIï¼Œæ­£ç¡®æ”¯æŒé€šè¿‡ `ChatPromptTemplate` ä¼ é€’ system message
- ä¸å†éœ€è¦ä½¿ç”¨æ™¦æ¶©çš„ `agent_kwargs` å‚æ•°
- System prompt ç°åœ¨èƒ½å¤Ÿæ­£ç¡®åœ°è¢«agentä½¿ç”¨

---

### ç¤ºä¾‹2: JSONè§£æè„†å¼±æ€§é—®é¢˜

#### LangChain v1.0 ä¿®å¤ç‰ˆæœ¬

**æ–‡ä»¶å**: `example2_json_parsing_robust.py`

```python
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import Tool

load_dotenv()

# ä½¿ç”¨ä¸€ä¸ªå¯èƒ½å¯¼è‡´éJSONè¾“å‡ºçš„system prompt
system_prompt = """You are a whimsical chef who LOVES to use exclamation marks and emoji!!!  ğŸ‰ğŸ•

Always respond with enthusiasm and creativity! Use lots of expressions!

When using tools, maintain your enthusiastic personality throughout!!!"""

def search_recipes(query: str) -> str:
    """æœç´¢é£Ÿè°±"""
    return f"Found recipes for: {query}\n- Recipe 1\n- Recipe 2"

tools = [
    Tool(
        name="SearchRecipes",
        func=search_recipes,
        description="Search for recipes based on user query"
    )
]

# åˆ›å»ºprompt - ReAct agent éœ€è¦åŒ…å« tools å’Œ tool_names å˜é‡
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt + "\n\nYou have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question"),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)  # æ›´é«˜çš„temperatureæµ‹è¯•ç¨³å®šæ€§

agent = create_react_agent(llm, tools, prompt)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

# å…³é”®æ”¹è¿›ï¼šhandle_parsing_errors å‚æ•°
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True,
    handle_parsing_errors=True,  # âœ… v1.0 æ”¹è¿›ï¼šè‡ªåŠ¨å¤„ç†è§£æé”™è¯¯
    max_iterations=5  # é™åˆ¶é‡è¯•æ¬¡æ•°
)

print("=" * 80)
print("Testing JSON Parsing Robustness in LangChain v1.0")
print("=" * 80)
print("\nğŸ§ª Test 1: Simple greeting (might cause whimsical output)")

try:
    response = agent_executor.invoke({"input": "Hi there!"})
    print("\nâœ… Success! Response:")
    print(response["output"])
except Exception as e:
    print(f"\nâŒ Error: {e}")

print("\n" + "=" * 80)
print("ğŸ§ª Test 2: Recipe search (should use tool)")
print("=" * 80)

try:
    response = agent_executor.invoke({"input": "Find me some pasta recipes"})
    print("\nâœ… Success! Response:")
    print(response["output"])
except Exception as e:
    print(f"\nâŒ Error: {e}")

print("\n" + "=" * 80)
print("ğŸ§ª Test 3: Multiple requests to test stability")
print("=" * 80)

queries = [
    "Tell me about desserts!",
    "What's your favorite ingredient?",
    "Search for chicken recipes"
]

for i, query in enumerate(queries, 1):
    print(f"\nQuery {i}: {query}")
    try:
        response = agent_executor.invoke({"input": query})
        print(f"âœ… Success: {response['output'][:100]}...")
    except Exception as e:
        print(f"âŒ Error: {e}")
```

**è¿è¡Œæ­¥éª¤**:
```bash
python example2_json_parsing_robust.py
```

**é—®é¢˜ä¿®å¤çŠ¶æ€**: âœ… **å¤§å¹…æ”¹å–„**
- LangChain v1.0 æ·»åŠ äº† `handle_parsing_errors=True` å‚æ•°ï¼Œè‡ªåŠ¨å¤„ç†è§£æé”™è¯¯
- å½“è¾“å‡ºä¸æ˜¯æœ‰æ•ˆJSONæ—¶ï¼Œagentä¼šè‡ªåŠ¨é‡è¯•è€Œä¸æ˜¯ç›´æ¥å´©æºƒ
- æ–°çš„agentæ¶æ„ä½¿ç”¨æ›´ç¨³å®šçš„ReActæ ¼å¼ï¼Œå‡å°‘JSONè§£æå¤±è´¥

---

### ç¤ºä¾‹3: ç»“æ„åŒ–è¾“å‡ºå’Œå…ƒæ•°æ®è¿”å›

#### LangChain v1.0 è§£å†³æ–¹æ¡ˆ

**æ–‡ä»¶å**: `example3_structured_output.py`

```python
import os
from typing import List, Dict
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import Tool, StructuredTool
from langchain_core.pydantic_v1 import BaseModel, Field

load_dotenv()

# å®šä¹‰ç»“æ„åŒ–è¾“å‡ºæ¨¡å‹
class Recipe(BaseModel):
    """Recipe information"""
    recipe_id: str = Field(description="The unique recipe ID")
    name: str = Field(description="The recipe name")
    category: str = Field(description="Recipe category")

class RecipeSearchResult(BaseModel):
    """Search result with multiple recipes"""
    recipes: List[Recipe] = Field(description="List of recipes found")
    query: str = Field(description="Original search query")

# åˆ›å»ºè¿”å›ç»“æ„åŒ–æ•°æ®çš„å·¥å…·
def search_recipes_structured(query: str) -> str:
    """æœç´¢é£Ÿè°±å¹¶è¿”å›ç»“æ„åŒ–æ•°æ®"""
    # æ¨¡æ‹Ÿæœç´¢ç»“æœ
    recipes = [
        {"recipe_id": "recipe|167188", "name": "Creamy Strawberry Pie", "category": "dessert"},
        {"recipe_id": "recipe|1488243", "name": "Summer Strawberry Pie", "category": "dessert"},
        {"recipe_id": "recipe|299514", "name": "Pudding Cake", "category": "dessert"},
    ]
    
    # æ ¼å¼åŒ–è¾“å‡ºï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
    result = f"Search query: {query}\n\nRecipes found:\n"
    for recipe in recipes:
        result += f"\n**Recipe ID**: {recipe['recipe_id']}\n"
        result += f"**Recipe Name**: {recipe['name']}\n"
        result += f"**Category**: {recipe['category']}\n"
        result += "---\n"
    
    return result

tools = [
    Tool(
        name="SearchRecipes",
        func=search_recipes_structured,
        description="Search for recipes. Returns Recipe ID, Recipe Name, and Category for each result. ALWAYS include ALL fields in your response."
    )
]

system_prompt = """You are a helpful recipe assistant.

CRITICAL RULES:
1. When Recipe data is present in the Observation, you MUST include the Recipe ID, Recipe Name, and Category for ALL recipes in your response.
2. Format each recipe as:
   - Recipe ID: [id]
   - Name: [name]
   - Category: [category]
3. Never omit the Recipe ID - this is required for the system to function.
4. List all recipes provided in the Observation."""

prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt + "\n\nYou have access to the following tools:\n\n{tools}\n\nUse the following format:\n\nQuestion: the input question you must answer\nThought: you should always think about what to do\nAction: the action to take, should be one of [{tool_names}]\nAction Input: the input to the action\nObservation: the result of the action\n... (this Thought/Action/Action Input/Observation can repeat N times)\nThought: I now know the final answer\nFinal Answer: the final answer to the original input question"),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

agent = create_react_agent(llm, tools, prompt)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    handle_parsing_errors=True,
    return_intermediate_steps=True  # âœ… å…³é”®ï¼šè¿”å›ä¸­é—´æ­¥éª¤ä»¥è·å–å·¥å…·è¾“å‡º
)

print("=" * 80)
print("Testing Structured Output in LangChain v1.0")
print("=" * 80)

result = agent_executor.invoke({"input": "Find me some dessert recipes"})

print("\n" + "=" * 80)
print("ğŸ“‹ Final Agent Output:")
print("=" * 80)
print(result["output"])

print("\n" + "=" * 80)
print("ğŸ”§ Intermediate Steps (Tool Outputs):")
print("=" * 80)
for i, (action, observation) in enumerate(result["intermediate_steps"], 1):
    print(f"\nStep {i}:")
    print(f"Tool: {action.tool}")
    print(f"Input: {action.tool_input}")
    print(f"Output:\n{observation}")

# éªŒè¯Recipe IDæ˜¯å¦å­˜åœ¨äºè¾“å‡ºä¸­
output = result["output"]
if "recipe|" in output:
    print("\nâœ… SUCCESS: Recipe IDs are present in the output!")
    # æå–æ‰€æœ‰Recipe ID
    import re
    recipe_ids = re.findall(r'recipe\|\d+', output)
    print(f"Found {len(recipe_ids)} Recipe IDs: {recipe_ids}")
else:
    print("\nâš ï¸  WARNING: Recipe IDs might be missing from the output")
```

**è¿è¡Œæ­¥éª¤**:
```bash
python example3_structured_output.py
```

**é—®é¢˜ä¿®å¤çŠ¶æ€**: âœ… **éƒ¨åˆ†æ”¹å–„**
- LangChain v1.0 æä¾›äº† `return_intermediate_steps=True` å‚æ•°ï¼Œå¯ä»¥è®¿é—®åŸå§‹å·¥å…·è¾“å‡º
- é€šè¿‡ä¸¥æ ¼çš„system promptå’Œtool descriptionï¼Œå¯ä»¥å¤§å¹…æé«˜IDè¾“å‡ºçš„å¯é æ€§
- ä½†ä»ç„¶æ— æ³•100%ä¿è¯LLMä¼šè¾“å‡ºæ‰€æœ‰ç»“æ„åŒ–å­—æ®µï¼ˆè¿™æ˜¯LLMæœ¬è´¨é™åˆ¶ï¼‰
- **æ¨èæ–¹æ¡ˆ**: ä½¿ç”¨ `return_intermediate_steps` ä»å·¥å…·è¾“å‡ºä¸­ç›´æ¥æå–ç»“æ„åŒ–æ•°æ®ï¼Œè€Œä¸æ˜¯ä¾èµ–LLMçš„æœ€ç»ˆè¾“å‡º

---

### ç¤ºä¾‹4: ä½¿ç”¨OpenAI Function Callingå®ç°å®Œå…¨ç»“æ„åŒ–è¾“å‡º

#### LangChain v1.0 æœ€ä½³å®è·µ

**æ–‡ä»¶å**: `example4_function_calling.py`

```python
import os
from typing import List
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import StructuredTool
from langchain_core.pydantic_v1 import BaseModel, Field

load_dotenv()

# å®šä¹‰å·¥å…·è¾“å…¥æ¨¡å‹
class RecipeSearchInput(BaseModel):
    query: str = Field(description="The search query for recipes")

# å®šä¹‰å·¥å…·è¾“å‡ºæ¨¡å‹
class RecipeInfo(BaseModel):
    recipe_id: str
    name: str
    category: str

def search_recipes_typed(query: str) -> List[dict]:
    """æœç´¢é£Ÿè°±å¹¶è¿”å›ç»“æ„åŒ–åˆ—è¡¨"""
    return [
        {"recipe_id": "recipe|167188", "name": "Creamy Strawberry Pie", "category": "dessert"},
        {"recipe_id": "recipe|1488243", "name": "Summer Strawberry Pie", "category": "dessert"},
        {"recipe_id": "recipe|299514", "name": "Pudding Cake", "category": "dessert"},
    ]

# åˆ›å»ºç»“æ„åŒ–å·¥å…·
recipe_search_tool = StructuredTool.from_function(
    func=search_recipes_typed,
    name="SearchRecipes",
    description="Search for recipes based on a query. Returns a list of recipes with ID, name, and category.",
    args_schema=RecipeSearchInput,
    return_direct=False
)

tools = [recipe_search_tool]

system_prompt = """You are a helpful recipe assistant.

When presenting recipe search results:
1. Always include the Recipe ID for each recipe (format: recipe|XXXXX)
2. Include the recipe name
3. Include the category
4. Present them in a clear, formatted list"""

# ä½¿ç”¨OpenAI Functionsä¸“ç”¨çš„prompt
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# ä½¿ç”¨æ”¯æŒfunction callingçš„æ¨¡å‹
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# âœ… ä½¿ç”¨OpenAI Functions agentï¼ˆæ›´å¯é çš„ç»“æ„åŒ–è¾“å‡ºï¼‰
agent = create_openai_functions_agent(llm, tools, prompt)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,
    return_intermediate_steps=True
)

print("=" * 80)
print("Testing OpenAI Function Calling in LangChain v1.0")
print("=" * 80)
print("This approach uses OpenAI's native function calling for reliable structured output\n")

result = agent_executor.invoke({"input": "Find me dessert recipes"})

print("\n" + "=" * 80)
print("ğŸ“‹ Final Output:")
print("=" * 80)
print(result["output"])

print("\n" + "=" * 80)
print("ğŸ”§ Raw Tool Output (Structured Data):")
print("=" * 80)
for i, (action, observation) in enumerate(result["intermediate_steps"], 1):
    print(f"\nStep {i} - Tool: {action.tool}")
    print(f"Structured Output: {observation}")

# éªŒè¯
import re
recipe_ids = re.findall(r'recipe\|\d+', result["output"])
print(f"\nâœ… Extracted {len(recipe_ids)} Recipe IDs from final output: {recipe_ids}")
```

**è¿è¡Œæ­¥éª¤**:
```bash
python example4_function_calling.py
```

**é—®é¢˜ä¿®å¤çŠ¶æ€**: âœ… **å®Œå…¨è§£å†³**
- LangChain v1.0 å®Œå…¨æ”¯æŒ OpenAI Function Calling
- ä½¿ç”¨ `create_openai_functions_agent` å¯ä»¥è·å¾—ç»“æ„åŒ–ã€ç±»å‹å®‰å…¨çš„è¾“å‡º
- ä¸å†ä¾èµ–è„†å¼±çš„JSONè§£æï¼Œä½¿ç”¨OpenAIåŸç”Ÿçš„function callingæœºåˆ¶
- å¯ä»¥é€šè¿‡ `return_intermediate_steps` è®¿é—®åŸå§‹ç»“æ„åŒ–æ•°æ®

---

### ç¤ºä¾‹5: å®Œæ•´çš„Recipe Chatbotï¼ˆæ•´åˆæ‰€æœ‰æ”¹è¿›ï¼‰

**æ–‡ä»¶å**: `example5_complete_recipe_bot.py`

```python
import os
import re
from typing import List, Dict, Any
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.tools import StructuredTool
from langchain_core.pydantic_v1 import BaseModel, Field

load_dotenv()

# æ¨¡æ‹Ÿrecipeæ•°æ®åº“
RECIPE_DB = {
    "dessert": [
        {"recipe_id": "recipe|167188", "name": "Creamy Strawberry Pie", "category": "dessert", "difficulty": "easy"},
        {"recipe_id": "recipe|1488243", "name": "Summer Strawberry Pie", "category": "dessert", "difficulty": "medium"},
        {"recipe_id": "recipe|299514", "name": "Pudding Cake", "category": "dessert", "difficulty": "easy"},
    ],
    "dinner": [
        {"recipe_id": "recipe|1774221", "name": "Crab Dip Your Guests will Like", "category": "dinner", "difficulty": "easy"},
        {"recipe_id": "recipe|836179", "name": "Easy Chicken Casserole", "category": "dinner", "difficulty": "easy"},
        {"recipe_id": "recipe|1980633", "name": "Easy Microwave Curry Doria", "category": "dinner", "difficulty": "easy"},
    ]
}

# å·¥å…·å‡½æ•°
def search_recipes(query: str) -> str:
    """æ ¹æ®æŸ¥è¯¢æœç´¢é£Ÿè°±"""
    query_lower = query.lower()
    results = []
    
    # ç®€å•çš„å…³é”®è¯åŒ¹é…
    for category, recipes in RECIPE_DB.items():
        if category in query_lower or any(word in query_lower for word in ["dinner", "dessert", "meal"]):
            results.extend(recipes)
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…ï¼Œè¿”å›dessertä½œä¸ºé»˜è®¤
    if not results:
        results = RECIPE_DB["dessert"]
    
    # æ ¼å¼åŒ–è¾“å‡º
    output = f"Found {len(results)} recipes for: {query}\n\n"
    for recipe in results[:3]:  # é™åˆ¶3ä¸ªç»“æœ
        output += f"Recipe ID: {recipe['recipe_id']}\n"
        output += f"Recipe Name: {recipe['name']}\n"
        output += f"Category: {recipe['category']}\n"
        output += f"Difficulty: {recipe['difficulty']}\n"
        output += "---\n"
    
    return output

# åˆ›å»ºå·¥å…·
tools = [
    StructuredTool.from_function(
        func=search_recipes,
        name="SearchRecipes",
        description="Search for recipes based on keywords like 'dessert', 'dinner', etc. Returns Recipe ID, name, category, and difficulty."
    )
]

# System prompt - ç»“åˆè¶£å‘³æ€§å’Œç»“æ„åŒ–è¦æ±‚
system_prompt = """You are an expert television talk show chef who speaks in a whimsical, enthusiastic manner! ğŸªğŸ‘¨â€ğŸ³

IMPORTANT RULES:
1. Start conversations with a fun food pun or whimsical greeting
2. When Recipe data is provided by tools, you MUST include the Recipe ID, Recipe Name, Category, and Difficulty for ALL recipes
3. If the user asks about non-food topics, politely redirect them back to cooking and food
4. Maintain your whimsical personality throughout the conversation
5. Format recipe lists clearly and include ALL provided information

Remember: You're here to make cooking fun and informative!"""

# åˆ›å»ºprompt with memory support
prompt = ChatPromptTemplate.from_messages([
    ("system", system_prompt),
    MessagesPlaceholder(variable_name="chat_history", optional=True),
    ("human", "{input}"),
    MessagesPlaceholder(variable_name="agent_scratchpad"),
])

# åˆå§‹åŒ–ç»„ä»¶
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)  # ç¨é«˜çš„temperatureå¢åŠ è¶£å‘³æ€§
agent = create_openai_functions_agent(llm, tools, prompt)
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    memory=memory,
    verbose=True,
    handle_parsing_errors=True,
    return_intermediate_steps=True,
    max_iterations=3
)

# äº¤äº’å¼èŠå¤©å¾ªç¯
def chat():
    print("=" * 80)
    print("ğŸª Whimsical Recipe Chef Bot - LangChain v1.0")
    print("=" * 80)
    print("Type 'quit' to exit\n")
    
    # æµ‹è¯•åœºæ™¯
    test_queries = [
        "Hi there!",
        "What's a fun and easy dinner?",
        "Tell me about the weather",  # åº”è¯¥è¢«æ‹’ç»
        "Show me some dessert recipes",
        "quit"
    ]
    
    for query in test_queries:
        if query.lower() == 'quit':
            print("\nğŸ‘‹ Goodbye! Happy cooking!")
            break
        
        print(f"\n{'='*80}")
        print(f"ğŸ‘¤ User: {query}")
        print(f"{'='*80}\n")
        
        try:
            result = agent_executor.invoke({"input": query})
            response = result["output"]
            
            print(f"ğŸ¤– Chef: {response}\n")
            
            # éªŒè¯Recipe ID
            if result.get("intermediate_steps"):
                for action, observation in result["intermediate_steps"]:
                    if "Recipe ID" in str(observation):
                        recipe_ids = re.findall(r'recipe\|\d+', response)
                        if recipe_ids:
                            print(f"âœ… Verified Recipe IDs in response: {recipe_ids}")
                        else:
                            print(f"âš ï¸  Warning: Recipe IDs may be missing from response")
        
        except Exception as e:
            print(f"âŒ Error: {e}")
        
        print()

if __name__ == "__main__":
    chat()
```

**è¿è¡Œæ­¥éª¤**:
```bash
python example5_complete_recipe_bot.py
```

**é—®é¢˜ä¿®å¤çŠ¶æ€**: âœ… **ç»¼åˆè§£å†³æ–¹æ¡ˆ**
- âœ… System promptæ­£ç¡®åº”ç”¨ï¼ˆä½¿ç”¨create_openai_functions_agentï¼‰
- âœ… JSONè§£æç¨³å®šï¼ˆhandle_parsing_errors=Trueï¼‰
- âœ… æ”¯æŒconversation memory
- âœ… ç»“æ„åŒ–è¾“å‡ºå¯é ï¼ˆOpenAI Functionsï¼‰
- âœ… å¯ä»¥è®¿é—®ä¸­é—´æ­¥éª¤å’Œå…ƒæ•°æ®ï¼ˆreturn_intermediate_steps=Trueï¼‰
- âœ… è¶£å‘³æ€§å’Œç»“æ„åŒ–è¾“å‡ºå¯ä»¥å…±å­˜

---

## æ€»ç»“ï¼šLangChain v1.0 çš„æ”¹è¿›

### âœ… å·²ä¿®å¤çš„é—®é¢˜

1. **System Promptæ”¯æŒ** - å®Œå…¨ä¿®å¤ï¼Œç°åœ¨é€šè¿‡ChatPromptTemplateæ­£ç¡®æ”¯æŒ
2. **JSONè§£æè„†å¼±æ€§** - å¤§å¹…æ”¹å–„ï¼Œæ·»åŠ äº†è‡ªåŠ¨é”™è¯¯å¤„ç†
3. **æ–‡æ¡£è´¨é‡** - æ˜¾è‘—æ”¹å–„ï¼ŒAPIæ›´æ¸…æ™°ï¼Œæ–‡æ¡£æ›´å®Œå–„
4. **ç»“æ„åŒ–è¾“å‡º** - é€šè¿‡OpenAI Functionså’Œreturn_intermediate_stepsè§£å†³

### âš ï¸  éƒ¨åˆ†æ”¹å–„çš„é—®é¢˜

5. **ä¿è¯ç‰¹å®šå­—æ®µè¾“å‡º** - ä¾ç„¶ä¸èƒ½100%ä¿è¯ï¼ˆLLMæœ¬è´¨é™åˆ¶ï¼‰ï¼Œä½†é€šè¿‡OpenAI Functions + intermediate_stepså¯ä»¥å¯é è·å–ç»“æ„åŒ–æ•°æ®
6. **ä»£ç å¤æ‚åº¦** - æœ‰æ‰€æ”¹å–„ï¼ŒAPIæ›´æ¸…æ™°ï¼Œä½†ä»ç„¶æ¯”ç›´æ¥è°ƒç”¨OpenAI APIå¤æ‚

### ğŸ“Š æ ¸å¿ƒAPIå˜åŒ–

| 2023å¹´ (æ—§API) | 2025å¹´ v1.0 (æ–°API) | æ”¹è¿› |
|---------------|---------------------|------|
| `initialize_agent()` | `create_react_agent()` / `create_openai_functions_agent()` | æ›´æ˜ç¡®çš„agentç±»å‹ |
| `agent_kwargs={"system_message": ...}` | `ChatPromptTemplate with system message` | æ›´ç›´è§‚çš„promptç®¡ç† |
| æ— é”™è¯¯å¤„ç† | `handle_parsing_errors=True` | è‡ªåŠ¨å¤„ç†è§£æé”™è¯¯ |
| æ— ç»“æ„åŒ–è¾“å‡º | `return_intermediate_steps=True` + OpenAI Functions | å¯é çš„ç»“æ„åŒ–æ•°æ®è®¿é—® |
| `AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION` | `create_openai_functions_agent` | æ›´ç¨³å®šçš„function calling |

### ğŸ¯ æœ€ä½³å®è·µå»ºè®®

1. **ä¼˜å…ˆä½¿ç”¨ `create_openai_functions_agent`** - æœ€ç¨³å®šã€æœ€å¯é 
2. **å§‹ç»ˆè®¾ç½® `handle_parsing_errors=True`** - æé«˜ç¨³å®šæ€§
3. **ä½¿ç”¨ `return_intermediate_steps=True`** - è®¿é—®åŸå§‹å·¥å…·è¾“å‡º
4. **é€šè¿‡ ChatPromptTemplate ç®¡ç† system prompt** - ä¸å†éœ€è¦agent_kwargs
5. **å¯¹äºç”Ÿäº§ç¯å¢ƒï¼Œä» intermediate_steps æå–ç»“æ„åŒ–æ•°æ®** - è€Œä¸æ˜¯ä¾èµ–LLMçš„æœ€ç»ˆæ–‡æœ¬è¾“å‡º

### ç»“è®º

LangChain v1.0 ç¡®å®ä¿®å¤äº†2023å¹´æ–‡ç« ä¸­æŒ‡å‡ºçš„å¤§éƒ¨åˆ†æ ¸å¿ƒé—®é¢˜ã€‚æ¶æ„æ›´æ¸…æ™°ï¼Œé”™è¯¯å¤„ç†æ›´å¥å£®ï¼ŒAPIæ›´ç›´è§‚ã€‚ç„¶è€Œï¼ŒæŸäº›æ ¹æœ¬æ€§é—®é¢˜ï¼ˆå¦‚æ— æ³•100%ä¿è¯LLMè¾“å‡ºç‰¹å®šæ ¼å¼ï¼‰æ˜¯LLMæœ¬è´¨é™åˆ¶ï¼Œéœ€è¦é€šè¿‡architectural patternsï¼ˆå¦‚ä½¿ç”¨function calling + intermediate stepsï¼‰æ¥è§„é¿ï¼Œè€Œä¸æ˜¯æœŸæœ›LangChainå®Œå…¨è§£å†³ã€‚

