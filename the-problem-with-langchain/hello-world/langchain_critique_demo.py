#!/usr/bin/env python3
"""
LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º
æ¼”ç¤ºæ–‡ç« ä¸­æåˆ°çš„æ¯ä¸ªç¼ºç‚¹ï¼Œå¹¶ä¸OpenAIå®˜æ–¹åº“è¿›è¡Œå¯¹æ¯”
"""

import os
import sys
import time

# æ£€æŸ¥OpenAI APIå¯†é’¥
if not os.environ.get("OPENAI_API_KEY"):
    print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
    print("   export OPENAI_API_KEY='your-api-key-here'")
    sys.exit(1)

print("=" * 80)
print("LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º")
print("=" * 80)
print()

# ============================================================================
# ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿
# ============================================================================
print("ğŸ“Œ ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (ä½¿ç”¨å¤šä¸ªå¯¹è±¡ç±»):")
print("ä»£ç :")
print("""
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

chat = ChatOpenAI(temperature=0)
result = chat.predict_messages([HumanMessage(content="Translate: I love programming to French")])
print(result.content)
""")

try:
    from langchain.chat_models import ChatOpenAI
    from langchain.schema import HumanMessage
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    chat = ChatOpenAI(temperature=0)
    result = chat.predict_messages([HumanMessage(content="Translate this sentence from English to French. I love programming.")])
    elapsed = time.time() - start
    print(f"âœ… {result.content}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")
    print("æç¤º: è¯·ç¡®ä¿å·²å®‰è£… langchain å’Œ langchain-openai")

print("\n" + "=" * 80)
print("\nğŸŸ¢ OpenAIå®˜æ–¹åº“æ–¹å¼ (ç®€æ´ç›´æ¥):")
print("ä»£ç :")
print("""
import openai

messages = [{"role": "user", "content": "Translate: I love programming to French"}]
response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
print(response["choices"][0]["message"]["content"])
""")

try:
    import openai
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    messages = [{"role": "user", "content": "Translate this sentence from English to French. I love programming."}]
    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
    elapsed = time.time() - start
    print(f"âœ… {response['choices'][0]['message']['content']}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
except Exception as e:
    print(f"âŒ OpenAIæ‰§è¡Œå¤±è´¥: {e}")

print("\nğŸ’¡ åˆ†æ: ä¸¤ç§æ–¹å¼ä»£ç é‡ç›¸å½“ï¼Œä½†LangChainå¼•å…¥äº†é¢å¤–çš„å¯¹è±¡ç±»ï¼Œå¢åŠ äº†å¤æ‚åº¦")
print()

# ============================================================================
# ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Œ ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚ (å®é™…ä¸Šåªæ˜¯f-stringsçš„åŒ…è£…)")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (å¤šå±‚åµŒå¥—çš„æ¨¡æ¿ç±»):")
print("ä»£ç :")
print("""
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template = "You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template = "{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
messages = chat_prompt.format_messages(
    input_language="English", 
    output_language="French", 
    text="I love programming."
)
print(messages)
""")

try:
    from langchain.prompts.chat import (
        ChatPromptTemplate,
        SystemMessagePromptTemplate,
        HumanMessagePromptTemplate,
    )
    
    print("\næ‰§è¡Œç»“æœ:")
    template = "You are a helpful assistant that translates {input_language} to {output_language}."
    system_message_prompt = SystemMessagePromptTemplate.from_template(template)
    human_template = "{text}"
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    
    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    messages = chat_prompt.format_messages(
        input_language="English", 
        output_language="French", 
        text="I love programming."
    )
    print("âœ… ç”Ÿæˆçš„æ¶ˆæ¯:")
    for msg in messages:
        print(f"   - {type(msg).__name__}: {msg.content}")
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")

print("\n" + "=" * 80)
print("\nğŸŸ¢ PythonåŸç”Ÿf-stringsæ–¹å¼ (ç®€å•ç›´æ¥):")
print("ä»£ç :")
print("""
input_language = "English"
output_language = "French"
text = "I love programming."

system_content = f"You are a helpful assistant that translates {input_language} to {output_language}."
human_content = f"{text}"

messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": human_content}
]
print(messages)
""")

print("\næ‰§è¡Œç»“æœ:")
input_language = "English"
output_language = "French"
text = "I love programming."

system_content = f"You are a helpful assistant that translates {input_language} to {output_language}."
human_content = f"{text}"

messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": human_content}
]
print("âœ… ç”Ÿæˆçš„æ¶ˆæ¯:")
for msg in messages:
    print(f"   - {msg['role']}: {msg['content']}")

print("\nğŸ’¡ åˆ†æ: LangChainçš„promptæ¨¡æ¿åªæ˜¯f-stringsçš„åŒ…è£…ï¼Œä½†å¢åŠ äº†3ä¸ªé¢å¤–çš„ç±»å’Œå¤šè¡Œä»£ç ")
print()

# ============================================================================
# ç¼ºç‚¹3: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Œ ç¼ºç‚¹3: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (å¤šä¸ªæ¦‚å¿µ: ConversationBufferMemory, MessagesPlaceholderç­‰):")
print("ä»£ç :")
print("""
from langchain.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        "The following is a friendly conversation between a human and an AI."
    ),
    MessagesPlaceholder(variable_name="history"),
    HumanMessagePromptTemplate.from_template("{input}")
])

llm = ChatOpenAI(temperature=0)
memory = ConversationBufferMemory(return_messages=True)
conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)

response = conversation.predict(input="Hi there!")
print(response)
""")

try:
    from langchain.prompts import (
        ChatPromptTemplate,
        MessagesPlaceholder,
        SystemMessagePromptTemplate,
        HumanMessagePromptTemplate
    )
    from langchain.chains import ConversationChain
    from langchain.chat_models import ChatOpenAI
    from langchain.memory import ConversationBufferMemory
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(
            "The following is a friendly conversation between a human and an AI. "
            "The AI is talkative and provides lots of specific details from its context."
        ),
        MessagesPlaceholder(variable_name="history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    
    llm = ChatOpenAI(temperature=0)
    memory = ConversationBufferMemory(return_messages=True)
    conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)
    
    response = conversation.predict(input="Hi there!")
    elapsed = time.time() - start
    print(f"âœ… {response}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    # ç»§ç»­å¯¹è¯
    response2 = conversation.predict(input="What's 2+2?")
    print(f"âœ… {response2}")
    
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")

print("\n" + "=" * 80)
print("\nğŸŸ¢ OpenAIå®˜æ–¹åº“æ–¹å¼ (ä½¿ç”¨ç®€å•çš„åˆ—è¡¨):")
print("ä»£ç :")
print("""
import openai

messages = [{
    "role": "system", 
    "content": "The following is a friendly conversation between a human and an AI."
}]

# ç¬¬ä¸€è½®å¯¹è¯
user_message = "Hi there!"
messages.append({"role": "user", "content": user_message})
response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
assistant_message = response["choices"][0]["message"]["content"]
messages.append({"role": "assistant", "content": assistant_message})
print(assistant_message)

# ç¬¬äºŒè½®å¯¹è¯
user_message2 = "What's 2+2?"
messages.append({"role": "user", "content": user_message2})
response2 = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
assistant_message2 = response2["choices"][0]["message"]["content"]
messages.append({"role": "assistant", "content": assistant_message2})
print(assistant_message2)
""")

try:
    import openai
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    
    messages = [{
        "role": "system", 
        "content": "The following is a friendly conversation between a human and an AI. "
                   "The AI is talkative and provides lots of specific details from its context."
    }]
    
    # ç¬¬ä¸€è½®å¯¹è¯
    user_message = "Hi there!"
    messages.append({"role": "user", "content": user_message})
    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
    assistant_message = response["choices"][0]["message"]["content"]
    messages.append({"role": "assistant", "content": assistant_message})
    elapsed = time.time() - start
    print(f"âœ… {assistant_message}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    # ç¬¬äºŒè½®å¯¹è¯
    user_message2 = "What's 2+2?"
    messages.append({"role": "user", "content": user_message2})
    response2 = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
    assistant_message2 = response2["choices"][0]["message"]["content"]
    messages.append({"role": "assistant", "content": assistant_message2})
    print(f"âœ… {assistant_message2}")
    
    print(f"\nğŸ“ å½“å‰å¯¹è¯å†å² ({len(messages)} æ¡æ¶ˆæ¯):")
    for i, msg in enumerate(messages):
        print(f"   {i+1}. [{msg['role']}] {msg['content'][:50]}...")
    
except Exception as e:
    print(f"âŒ OpenAIæ‰§è¡Œå¤±è´¥: {e}")

print("\nğŸ’¡ åˆ†æ: OpenAIå®˜æ–¹åº“ä»£ç æ›´å°‘ï¼Œé€»è¾‘æ›´æ¸…æ™°ï¼Œèƒ½ç›´æ¥çœ‹åˆ°æ¶ˆæ¯çš„ä¿å­˜ä½ç½®å’Œæ—¶æœº")
print("   LangChainå¼•å…¥äº†ConversationBufferMemoryã€MessagesPlaceholderç­‰æ¦‚å¿µï¼Œå¢åŠ äº†å­¦ä¹ æˆæœ¬")

# ============================================================================
# æ€»ç»“
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š æ€»ç»“")
print("=" * 80)
print("""
æ–‡ç« ä½œè€…çš„æ ¸å¿ƒè§‚ç‚¹:

1. âŒ LangChainå¼•å…¥äº†å¤§é‡æŠ½è±¡å±‚ï¼ˆå¯¹è±¡ç±»ã€æ¨¡æ¿ç±»ã€è®°å¿†ç±»ç­‰ï¼‰
2. âŒ è¿™äº›æŠ½è±¡æ²¡æœ‰å¸¦æ¥æ˜æ˜¾çš„ä»£ç ä¼˜åŠ¿ï¼Œåè€Œå¢åŠ äº†å¤æ‚åº¦
3. âŒ å¾ˆå¤šåŠŸèƒ½ç”¨PythonåŸç”Ÿç‰¹æ€§ï¼ˆå¦‚f-stringsï¼‰æˆ–OpenAIå®˜æ–¹åº“å°±èƒ½ç®€å•å®ç°
4. âŒ æ–‡æ¡£ä¸å¤Ÿé€æ˜ï¼Œéšè—äº†é‡è¦çš„æ€§èƒ½ç»†èŠ‚ï¼ˆå¦‚Agentæ¯æ­¥éƒ½è°ƒç”¨APIï¼‰
5. âŒ å¦‚æœquickstartå°±è¿™ä¹ˆå¤æ‚ï¼Œå®é™…ä½¿ç”¨ä¼šæ›´ç—›è‹¦

ä½œè€…è®¤ä¸º: "å¦‚æœnitpicksï¼ˆå¹æ¯›æ±‚ç–µçš„é—®é¢˜ï¼‰æ¯”å®é™…å¥½å¤„è¿˜å¤šï¼Œè¿™ä¸ªåº“å°±ä¸å€¼å¾—ä½¿ç”¨"
""")

print("=" * 80)
print("æ¼”ç¤ºå®Œæˆ!")
print("=" * 80)
