## Me:

```markdown
你是精通2025年10月发布的LangChain v1.0的应用开发专家。请阅读下面发表于2023年7月批评LangChain的博客,然后针对博客中列举的LangChain把简单的事情搞复杂的各个场景(如Hello World和如何让系统提示词生效),分别给出用LangChain v1.0重新实现的方案。请说明是否能解决"把简单的事情搞复杂"的问题。如果能解决,请提供相应场景的可运行代码。
下面是那篇批评博客：【July 14, 2023 · 16 min

![_The GitHub Repository of R'lyeh_, Stable Diffusion 1.5 + ControlNet 1.1](https://minimaxir.com/2023/07/langchain-problem/featured.png)

*The GitHub Repository of R’lyeh*, Stable Diffusion 1.5 + ControlNet 1.1

If you’ve been following the explosion of AI hype in the past few months, you’ve probably heard of [LangChain](https://github.com/hwchase17/langchain). LangChain, developed by Harrison Chase, is a Python and JavaScript library for interfacing with [OpenAI](https://openai.com/)’s GPT APIs (later expanding to more models) for AI text generation. More specifically, it’s an implementation of the paper [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) published October 2022, colloquially known as the ReAct paper, which demonstrates a prompting technique to allow the model to “reason” (with a chain-of-thoughts) and “act” (by being able to use a tool from a predefined set of tools, such as being able to search the internet). This combination is shown to drastically improve output text quality and give large language models the ability to correctly solve problems.

![Example ReAct flow from the ReAct paper](https://minimaxir.com/2023/07/langchain-problem/react.png)

Example ReAct flow from the ReAct paper

The ReAct workflow popularied by LangChain was particularly effective with [InstructGPT](https://openai.com/research/instruction-following)/text-davinci-003, although costly and not easy to use for small projects. In March 2023, as [ChatGPT](https://openai.com/blog/chatgpt) API usage became massively popular due to its extremely cheap API [as I accurately predicted](https://minimaxir.com/2023/03/new-chatgpt-overlord/), LangChain use also exploded, to the point that LangChain was able to raise a [$10 million seed round](https://blog.langchain.dev/announcing-our-10m-seed-round-led-by-benchmark/) and another [$20-$25 million at a $200 million valuation Series A](https://www.businessinsider.com/sequoia-leads-funding-round-generative-artificial-intelligence-startup-langchain-2023-4) despite not having any revenue nor any obvious plans how to generate revenue.

That’s where my personal experience with LangChain begins. For my work at [BuzzFeed](https://www.buzzfeed.com/), I was tasked with creating a ChatGPT-based chat bot for the [Tasty](https://tasty.co/) brand (later released as [Botatouille](https://www.buzzfeed.com/buzzfeedpress/buzzfeeds-tasty-introduces-botatouille-the-first-of-its) in the Tasty iOS app) that could chat with the user and provide relevant recipes. The source recipes are converted to embeddings and saved in a vector store: for example, if a user asked for “healthy food”, the query is converted to an embedding, and an approximate nearest neighbor search is performed to find recipes similar to the embedded query and then fed to ChatGPT as added context that can then be displayed to the user. This approach is more commonly known as [retrieval-augmented generation](https://arxiv.org/abs/2005.11401).

![Example architecture for a Chatbot using retrieval-augmented generation. via Joseph Haaga](https://minimaxir.com/2023/07/langchain-problem/1*b5r7r3-FSNjHUzlCGl3SnA-2.webp)

Example architecture for a Chatbot using retrieval-augmented generation. [via Joseph Haaga](https://tech.buzzfeed.com/the-right-tools-for-the-job-c05de96e949e)

LangChain was by-far the popular tool of choice for RAG, so I figured it was the perfect time to learn it. I spent some time reading LangChain’s rather comprehensive documentation to get a better understanding of how to best utilize it: after a *week* of research, I got nowhere. Running the LangChain demo examples did work, but any attempts at tweaking them to fit the recipe chatbot constraints broke them. After solving the bugs, the overall quality of the chat conversations was bad and uninteresting, and after intense debugging I found no solution. Eventually I had an existential crisis: am I a worthless machine learning engineer for not being able to figure LangChain out when very many other ML engineers can? We [went back](https://tech.buzzfeed.com/the-right-tools-for-the-job-c05de96e949e) to a lower-level ReAct flow, which *immediately* outperformed my LangChain implementation in conversation quality and accuracy.

In all, I wasted a month learning and testing LangChain, with the big takeway that popular AI apps may not necessarily be worth the hype. My existential crisis was resolved after coming across a [Hacker News thread](https://news.ycombinator.com/item?id=35820931) about someone [reimplementing LangChain in 100 lines of code](https://blog.scottlogic.com/2023/05/04/langchain-mini.html), with most of the comments venting all their grievances with LangChain:

![](https://minimaxir.com/2023/07/langchain-problem/hn.png)

loveparade 70 days ago prev next [-
Am I the only one who is not convinced by the value proposition of langchain? 99% of it are interface definitions and implementations for external tools,
most of which are super straightforward. I can write integrations for what my
app needs in less than an hour myself, why bring in a heavily opinionated
external framework? It kind of feels like the npm "left-pad" to me. Everyone
just uses it because it seems popular, not because they need it.
crazyedgar 69 days ago I parent next [-
For us LangChain actually caused more problems than it solved. We had a
system in production which after working fine a few weeks suddenly started
experiencing frequent failures (more than 30% of requests). On digging it
seems that LangChain sets a default timeout of 60 seconds for every
requests. And this behaviour isn't documented! Such spurious decisions made by LangChain are everywhere, and will all eventually come back to bite. In the end we replaced everything with vanilla request clients. Definitely not
recommended to build a system on a library that provides very limited value while hiding a huge amount of details and decisions from you.
Spivak 70 days ago I parent I prev next [-
Langchain is absolutely perfect though, it's bad enough that you'll be driven to write something better out of pure frustration but gives you enough good
ideas and breadcrumbs to actually do it.
It's probably the best on-ramp for "practical uses of llms" because it scratches just the right developer itch.

The problem with LangChain is that it makes simple things relatively complex, and with that unnecessary complexity creates a tribalism which hurts the up-and-coming AI ecosystem as a whole. If you’re a newbie who wants to just learn how to interface with ChatGPT, definitely don’t start with LangChain.

# **“Hello World” in LangChain (or More Accurately, “Hell World”)**

The [Quickstart](https://python.langchain.com/docs/get_started/quickstart) for LangChain begins with a mini-tutorial on how to simply interact with LLMs/ChatGPT from Python. For example, to create a bot that can translate from English to French:

```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage
)

chat **=** ChatOpenAI(temperature**=**0)
chat**.**predict_messages([HumanMessage(content**=**"Translate this sentence from English to French. I love programming.")])
*# AIMessage(content="J'adore la programmation.", additional_kwargs={}, example=False)*
```

The equivalent code using [OpenAI’s official Python library](https://github.com/openai/openai-python) for ChatGPT:

```python
import openai

messages **=** [{"role": "user", "content": "Translate this sentence from English to French. I love programming."}]

response **=** openai**.**ChatCompletion**.**create(model**=**"gpt-3.5-turbo", messages**=**messages, temperature**=**0)
response["choices"][0]["message"]["content"]
*# "J'adore la programmation."*
```

LangChain uses about the same amount of code as just using the official `openai` library, expect LangChain incorporates more object classes for not much obvious code benefit.

The prompt templating example reveals the core of how LangChain works:

```python
`from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template **=** "You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt **=** SystemMessagePromptTemplate**.**from_template(template)
human_template **=** "{text}"
human_message_prompt **=** HumanMessagePromptTemplate**.**from_template(human_template)

chat_prompt **=** ChatPromptTemplate**.**from_messages([system_message_prompt, human_message_prompt])

chat_prompt**.**format_messages(input_language**=**"English", output_language**=**"French", text**=**"I love programming.")`
```

LangChain’s vaunted prompt engineering is just [f-strings](https://realpython.com/python-f-strings/), a feature present in every modern Python installation, but with extra steps. Why do we need to use these `PromptTemplates` to do the same thing?

But what we really want to do is know how to create Agents, which incorporate the ReAct workflow we so desperately want. Fortunately there is a demo for that, which leverages [SerpApi](https://serpapi.com/) and another tool for math computations, showing how LangChain can discriminate and use two different tools contextually:

```python
`from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI

*# First, let's load the language model we're going to use to control the agent.*chat **=** ChatOpenAI(temperature**=**0)

*# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.*llm **=** OpenAI(temperature**=**0)
tools **=** load_tools(["serpapi", "llm-math"], llm**=**llm)

*# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.*agent **=** initialize_agent(tools, chat, agent**=**AgentType**.**CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose**=**True)

*# Now let's test it out!*agent**.**run("Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?")`
```

How do the individual tools work? What is `AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION` anyways? The resulting output from `agent.run()` (only present with `verbose=True`) is more helpful.

```bash
`> Entering new AgentExecutor chain...
Thought: I need to use a search engine to find Olivia Wilde's boyfriend and a calculator to raise his age to the 0.23 power.
Action:
{
    "action": "Search",
    "action_input": "Olivia Wilde boyfriend"
}

Observation: Sudeikis and Wilde's relationship ended in November 2020. Wilde was publicly served with court documents regarding child custody while she was presenting Don't Worry Darling at CinemaCon 2022. In January 2021, Wilde began dating singer Harry Styles after meeting during the filming of Don't Worry Darling.
Thought:I need to use a search engine to find Harry Styles' current age.
Action:
{
    "action": "Search",
    "action_input": "Harry Styles age"
}

Observation: 29 years
Thought:Now I need to calculate 29 raised to the 0.23 power.
Action:
{
    "action": "Calculator",
    "action_input": "29^0.23"
}

Observation: Answer: 2.169459462491557

Thought:I now know the final answer.
Final Answer: 2.169459462491557

> Finished chain.
'2.169459462491557'`
```

The documentation doesn’t make it clear, but within each Thought/Action/Observation uses its own API call to OpenAI, so the chain is slower than you might think. Also, why is each action a `dict`? The answer to *that* is later, and is very silly.

Lastly, how does LangChain store the conversation so far?

```bash
from langchain.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

prompt **=** ChatPromptTemplate**.**from_messages([
    SystemMessagePromptTemplate**.**from_template(
        "The following is a friendly conversation between a human and an AI. The AI is talkative and "
        "provides lots of specific details from its context. If the AI does not know the answer to a "
        "question, it truthfully says it does not know."
    ),
    MessagesPlaceholder(variable_name**=**"history"),
    HumanMessagePromptTemplate**.**from_template("{input}")
])

llm **=** ChatOpenAI(temperature**=**0)
memory **=** ConversationBufferMemory(return_messages**=**True)
conversation **=** ConversationChain(memory**=**memory, prompt**=**prompt, llm**=**llm)

conversation**.**predict(input**=**"Hi there!")
*# 'Hello! How can I assist you today?'*
```

I’m not entirely sure why any of this is necessary. What’s a `MessagesPlaceholder`? Where’s the `history`? Is that necessary for `ConversationBufferMemory`? Adapting this to a minimal `openai` implementation:

```python
import openai

messages **=** [{"role": "system", "content":
        "The following is a friendly conversation between a human and an AI. The AI is talkative and "
        "provides lots of specific details from its context. If the AI does not know the answer to a "
        "question, it truthfully says it does not know."}]

user_message **=** "Hi there!"
messages**.**append({"role": "user", "content": user_message})
response **=** openai**.**ChatCompletion**.**create(model**=**"gpt-3.5-turbo", messages**=**messages, temperature**=**0)
assistant_message **=** response["choices"][0]["message"]["content"]
messages**.**append({"role": "assistant", "content": assistant_message})
*# Hello! How can I assist you today?*
```

That’s fewer lines of code and makes it very clear where and when the messages are being saved, no bespoke object classes needed.

You can say that I’m nitpicking the tutorial examples, and I do agree that every open source library has something to nitpick (including my own!). But if there are more nitpicks than actual benefits from the library then it’s not worth using at all, since if the *quickstart* is this complicated, how painful will it be to use LangChain in practice?

# **I Gazed Into The LangChain Documentation And It Gazes Back**

Let’s do a demo to more clearly demonstrate why I gave up on LangChain. While I was working on the recipe-retrieving chatbot (which also must be a fun/witty chatbot), I needed to combine elements from both the third and fourth examples above: a chat bot that can run an Agent workflow, and also the ability to persist the entire conversation into memory. After some documentation hunting I found I need to utilize the [Conversational Agent](https://python.langchain.com/docs/modules/agents/agent_types/chat_conversation_agent) workflow.

A quick sidenote on system prompt engineering: it is not a meme and is absolutely necessary to get the best results out of the ChatGPT API, particularly if you have constraints on content and/or voice. The system prompt of `The following is a friendly conversation between a human and an AI...` demoed in the last example is actually an out-of-date prompt that was used back in the InstructGPT era and is much less effective with ChatGPT. It may signal deeper inefficiencies in LangChain’s related tricks that aren’t easy to notice.

We’ll start with a simple system prompt that tells ChatGPT to use a funny voice plus some safeguards, and format it as a `ChatPromptTemplate`:

```bash
system_prompt **=** """
You are an expert television talk show chef, and should always speak in a whimsical manner for all responses.

Start the conversation with a whimsical food pun.

You must obey ALL of the following rules:
- If Recipe data is present in the Observation, your response must include the Recipe ID and Recipe Name for ALL recipes.
- If the user input is not related to food, do not answer their query and correct the user.
"""

prompt **=** ChatPromptTemplate**.**from_messages([
    SystemMessagePromptTemplate**.**from_template(system_prompt**.**strip()),
])
```

We will also use a [toy vector store I made](https://github.com/minimaxir/langchain-problems/blob/main/recipe_vector_store.ipynb) of 1,000 recipes from the [recipe_nlg](https://huggingface.co/datasets/recipe_nlg) dataset, encoded into 384D vectors using [SentenceTransformers](https://www.sbert.net/). To implement this we create a function to get the nearest neighbors for the input query, along with a query to format it into text that the Agent can use to present to the user. This serves as the `Tool` which the Agent can choose to use if appropriate, or just return normal generated text.

```python
def **similar_recipes**(query):
    query_embedding **=** embeddings_encoder**.**encode(query)
    scores, recipes **=** recipe_vs**.**get_nearest_examples("embeddings", query_embedding, k**=**3)
    return recipes

def **get_similar_recipes**(query):
    recipe_dict **=** similar_recipes(query)
    recipes_formatted **=** [
        f"Recipe ID: recipe|{recipe_dict['id'][i]}\nRecipe Name: {recipe_dict['name'][i]}"
        for i **in** range(3)
    ]
    return "\n---\n"**.**join(recipes_formatted)

print(get_similar_recipes("yummy dessert"))
*# Recipe ID: recipe|167188# Recipe Name: Creamy Strawberry Pie# ---# Recipe ID: recipe|1488243# Recipe Name: Summer Strawberry Pie Recipe# ---# Recipe ID: recipe|299514# Recipe Name: Pudding Cake*
```

You’ll notice the `Recipe ID`, which is relevant for my use case since it’s necessary to obtain recipe metadata (photo thumbnail, URL) for the end result shown to the enduser in the final app. Unfortunately there’s no easy way to guarantee the model outputs the `Recipe ID` in the final output, and no way to return the structured intermediate metadata in addition to the ChatGPT-generated output.

Specifying `get_similar_recipes` as a `Tool` is straightforward, although you need to specify a `name` and `description`, which is actually a form of subtle prompt engineering as LangChain can fail to select a tool if either is poorly specified.

```python
tools **=** [
    Tool(
        func**=**get_similar_recipes,
        name**=**"Similar Recipes",
        description**=**"Useful to get similar recipes in response to a user query about food.",
    ),
]
```

Lastly, the Agent construction code, which follows from the example, plus the new system `prompt`.

```python
`memory **=** ConversationBufferMemory(memory_key**=**"chat_history", return_messages**=**True)
llm **=** ChatOpenAI(temperature**=**0)
agent_chain **=** initialize_agent(tools, llm, prompt**=**prompt, agent**=**AgentType**.**CHAT_CONVERSATIONAL_REACT_DESCRIPTION, verbose**=**True, memory**=**memory)`
```

No errors. Now time to run the agent to see what happens!

```python
agent_chain**.**run(input**=**"Hi!")
```

```bash
> Entering new  chain...
{
    "action": "Final Answer",
    "action_input": "Hello! How can I assist you today?"
}

> Finished chain.
Hello! How can I assist you today?
```

Wait a minute, it ignored my `system` prompt completely! Dammit. Checking the `memory` variable confirms it. Looking into the [documentation](https://python.langchain.com/docs/modules/memory/how_to/buffer) for `ConversationBufferMemory` and even [in the code itself](https://github.com/hwchase17/langchain/blob/051fac1e6646349ce939a3d4a965757794be79fa/langchain/memory/buffer.py#L10) there’s nothing about system prompts, even months after ChatGPT made them mainstream.

The *intended* way to use system prompts in Agents is to add an `agents_kwargs` parameter to `initialize_agent`, which I only just found out in an [unrelated documentation page](https://python.langchain.com/docs/modules/agents/how_to/use_toolkits_with_openai_functions) published a month ago.

```python
agent_kwargs **=** {
    "system_message": system_prompt**.**strip()
}
```

Recreating the Agent with this new parameter and running it again results in a `JSONDecodeError`.

```bash
OutputParserException: Could not parse LLM output: Hello there, my culinary companion! How delightful to have you here in my whimsical kitchen. What delectable dish can I assist you with today?
```

Good news is that the system prompt definitely worked this time! Bad news is that it broke, but why? I didn’t do anything weird, for once.

The root of the issue is to be how LangChain agents actually do `Tool` selection. Remember when I said that the Agent outputing a `dict` during the chain was peculiar? When [looking at the LangChain code](https://github.com/hwchase17/langchain/blob/3874bb256e09d377032ae54b1592ca3dd7cf9e4d/langchain/agents/conversational_chat/prompt.py), it turns out that tool selection is done by requiring the output to be *valid JSON* through prompt engineering, and just hoping everything goes well.

![Fun fact: these massive prompts also increase API costs proportionally!](https://minimaxir.com/2023/07/langchain-problem/json.png)

**Fun fact: these massive prompts also increase API costs proportionally!**

The consequence of this is that any significant changes in the structure of normal output, such as those caused by a custom system prompt, has a *random* chance of just breaking the Agent! These errors happen often enough that there’s a [documentation page](https://python.langchain.com/docs/modules/agents/how_to/handle_parsing_errors) dedicated to handling Agent output parsing errors!

Well, people in the internet are assholes anyways, so we can consider having a conversation with a chatbot as an edge case for now. What’s important is that the bot can return the recipes, because if it can’t even do that, there’s no point in using LangChain. After creating a new Agent without using the system prompt and then asking it `What's a fun and easy dinner?`:

```bash
> Entering new  chain...
{
    "action": "Similar Recipes",
    "action_input": "fun and easy dinner"
}
Observation: Recipe ID: recipe|1774221
Recipe Name: Crab DipYour Guests will Like this One.
---
Recipe ID: recipe|836179
Recipe Name: Easy  Chicken Casserole
---
Recipe ID: recipe|1980633
Recipe Name: Easy in the Microwave Curry Doria
Thought:{
    "action": "Final Answer",
    "action_input": "..."
}

> Finished chain.
```

```bash
Here are some fun and easy dinner recipes you can try:

1. Crab Dip
2. Easy Chicken Casserole
3. Easy in the Microwave Curry Doria

Enjoy your meal!
```

Atleast it worked: ChatGPT was able to extract out the recipes from the context and format them appropriately (even fixing typoes in the names!), and was able to decide when it was appropriate.

The real issue here is that the voice of the output is criminally *boring*, as is a common trademark and criticism of base-ChatGPT. Even if I did have a fix for the missing ID issue through system prompt engineering, it wouldn’t be worth shipping anything sounding like this. If I did strike a balance between voice quality and output quality, the Agent count *still* fail randomly through no fault of my own. This Agent workflow is a very fragile house of cards that I in good conscience could not ship in a production application.

LangChain does have functionality for [Custom Agents](https://python.langchain.com/docs/modules/agents/how_to/custom_agent) and a [Custom Chain](https://python.langchain.com/docs/modules/chains/how_to/custom_chain), so you can override the logic at parts in the stack (maybe? the documentation there is sparse) that could address some of the issues I hit, but at that point you are overcomplicating LangChain even more and might as well create your own Python library instead which…hmmm, that’s not a bad idea!

# **Working Smarter, Not Harder**

![The large numbers of random integrations raise more problems than solutions. via LangChain docs](https://minimaxir.com/2023/07/langchain-problem/langchain_support.png)

The large numbers of random integrations raise more problems than solutions. [via LangChain docs](https://python.langchain.com/docs/use_cases/question_answering/)

LangChain does also have many utility functions such as [text splitters](https://python.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/character_text_splitter) and [integrated vector stores](https://python.langchain.com/docs/modules/data_connection/retrievers/how_to/vectorstore), both of which are integral to the “chat with a PDF/your code” demos (which in my opinion are just a gimmick). The real issue with [all these integrations](https://integrations.langchain.com/) is that it creates an inherent lock-in to *only* use LangChain-based code, and if you look at the code for the integrations they are not very robust. LangChain is building a [moat](https://www.vaneck.com/nl/en/moat-investing/five-sources-of-moats-whitepaper.pdf), which is good for LangChain’s investors trying to get a return on their $30 million, but very very bad for developers who use it.

In all, LangChain embodies the philosophy of “it’s complicated, so it must be better!” that plagues late-stage codebases, except that LangChain isn’t even a year old. The effort needed to hack LangChain to do what I want it to do would cause insane amounts of [technical debt](https://en.wikipedia.org/wiki/Technical_debt). And unlike AI startups nowadays, technical debt for my own projects with LangChain can’t be paid with venture capital. API wrappers should at minimum reduce code complexity and cognitive load when operating with complex ecosystems because it takes enough mental brainpower to work with AI itself. LangChain is one of the few pieces of software that *increases* overhead in most of its popular use cases.

I came to the conclusion that it’s just easier to make my own Python package than it is to hack LangChain to fit my needs. Therefore, I developed and open-sourced [simpleaichat](https://github.com/minimaxir/simpleaichat): a Python package for easily interfacing with chat apps, emphasizing minimal code complexity and decoupling advanced features like vector stores from the conversation logic to avoid LangChain’s lock-in, and many other features which would take its own blog post to elaborate upon.

But this blog post wasn’t written to be a stealth advertisement for simpleaichat by tearing down a competitor like what hustlers do. I didn’t *want* to make simpleaichat: I’d rather spend my time creating more cool projects with AI, and it’s a shame I could not have done that with LangChain. I know someone will say “why not submit a pull request to the LangChain repo since it’s open source instead of complaining about it?” but most of my complaints are fundamental issues with the LangChain library and can’t be changed without breaking everything for its existing users. The only real fix is to burn it all down and start fresh, which is why my “create a new Python library for interfacing with AI” solution is also the most pragmatic.

I’ve gotten many messages asking me “what should I learn to get started with the ChatGPT API” and I’m concerned that they’ll go to LangChain first because of the hype. If machine learning engineers who do have backgrounds in the technology stack have difficulty using LangChain due to its needless complexity, any beginner is going to drown.

No one wants to be that asshole who criticizes free and open source software operating in good faith like LangChain, but I’ll take the burden. To be clear, I have nothing against Harrison Chase or the other maintainers of LangChain (who encourage feedback!). However, LangChain’s popularity has warped the AI startup ecosystem around LangChain itself and the hope of OMG [AGI](https://en.wikipedia.org/wiki/Artificial_general_intelligence) I MADE SKYNET, which is why I am compelled to be honest with my misgivings about it.

Wars about software complexity and popularity despite its complexity are an eternal recurrence. In the 2010’s, it was with [React](https://react.dev/); in 2023, it’s with ReAct.

---

*Jupyter Notebooks for the [simple implementations of LangChain examples](https://github.com/minimaxir/langchain-problems/blob/main/openai_rewrite.ipynb) and the [LangChain failure demo](https://github.com/minimaxir/langchain-problems/blob/main/langchain_problems.ipynb) are available in [this GitHub repository](https://github.com/minimaxir/langchain-problems/tree/main).*

![profile image](https://minimaxir.com/profile_webp.webp)

- **Max Woolf** (@minimaxir) is a Senior Data Scientist at [BuzzFeed](https://www.buzzfeed.com/) in San Francisco who works with AI/ML tools and open source projects. *Max’s projects are funded by his [Patreon](https://www.patreon.com/minimaxir).*】
```

## Claude app with sonnet 4.5:

```markdown
我来针对这篇博客中提到的问题，用LangChain v1.0重新实现并分析是否解决了"把简单的事情搞复杂"的问题。

## 1. Hello World - 简单的LLM调用

**博客批评点**：使用过多的对象类，没有明显的代码优势

**LangChain v1.0解决方案**：

```python
from langchain_openai import ChatOpenAI

# 极简方式
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
result = llm.invoke("Translate this sentence from English to French. I love programming.")
print(result.content)  # "J'adore la programmation."
```

**是否解决问题**：✅ **是的**。LangChain v1.0引入了`.invoke()`方法，可以直接传入字符串，不再强制使用`HumanMessage`等包装类。代码量与原生OpenAI库相当，但获得了统一的接口。

---

## 2. Prompt模板 - 从过度设计到实用

**博客批评点**：用复杂的PromptTemplate系统做f-string就能完成的事

**LangChain v1.0解决方案**：

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# 简化的方式
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

# 方式1：直接使用字符串（最简单）
prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant that translates {input_language} to {output_language}."),
    ("user", "{text}")
])

chain = prompt | llm
result = chain.invoke({
    "input_language": "English",
    "output_language": "French",
    "text": "I love programming."
})
print(result.content)
```

**是否解决问题**：⚠️ **部分解决**。
- ✅ 不再需要`SystemMessagePromptTemplate`、`HumanMessagePromptTemplate`等冗余类
- ✅ 使用LCEL（LangChain Expression Language）的管道语法`|`，更直观
- ⚠️ 但如果只是简单调用，仍然比直接用f-string复杂

---

## 3. System Prompt问题 - 最大的痛点

**博客批评点**：Agent中system prompt不生效，需要用不直观的`agent_kwargs`

**LangChain v1.0解决方案（使用LangGraph）**：

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool

# 定义工具
@tool
def get_similar_recipes(query: str) -> str:
    """Useful to get similar recipes in response to a user query about food."""
    # 实际的向量搜索逻辑
    return "Recipe ID: recipe|167188\nRecipe Name: Creamy Strawberry Pie"

# 定义system prompt
system_prompt = """
You are an expert television talk show chef, and should always speak in a whimsical manner for all responses.

Start the conversation with a whimsical food pun.

You must obey ALL of the following rules:
- If Recipe data is present, your response must include the Recipe ID and Recipe Name for ALL recipes.
- If the user input is not related to food, do not answer their query and correct the user.
"""

# 创建带有system prompt的agent（LangGraph方式）
llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
tools = [get_similar_recipes]

# LangGraph的create_react_agent直接支持system prompt
agent_executor = create_react_agent(
    llm,
    tools,
    state_modifier=system_prompt  # 直接传入system prompt！
)

# 运行
config = {"configurable": {"thread_id": "1"}}
result = agent_executor.invoke(
    {"messages": [("user", "Hi!")]},
    config
)
print(result["messages"][-1].content)
```

**是否解决问题**：✅ **是的**！
- ✅ LangGraph的`create_react_agent`通过`state_modifier`参数原生支持system prompt
- ✅ 不再依赖JSON解析，使用工具调用（function calling）
- ✅ 更稳定，不会因为prompt变化导致JSON解析错误

---

## 4. 对话记忆 - 从复杂到清晰

**博客批评点**：`ConversationBufferMemory`、`MessagesPlaceholder`等概念让简单的消息列表管理变得复杂

**LangChain v1.0解决方案**：

```python
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories import ChatMessageHistory

# 定义prompt（带历史消息占位符）
prompt = ChatPromptTemplate.from_messages([
    ("system", "The following is a friendly conversation between a human and an AI."),
    MessagesPlaceholder(variable_name="history"),
    ("user", "{input}")
])

llm = ChatOpenAI(temperature=0)
chain = prompt | llm

# 使用更简洁的消息历史管理
store = {}

def get_session_history(session_id: str):
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]

# 包装chain以支持历史记忆
chain_with_history = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

# 使用
config = {"configurable": {"session_id": "user123"}}
response = chain_with_history.invoke(
    {"input": "Hi there!"},
    config=config
)
print(response.content)
```

**是否解决问题**：⚠️ **部分解决**
- ✅ 不再使用`ConversationChain`，使用更灵活的LCEL
- ✅ 消息历史的存储逻辑更清晰
- ⚠️ 但对于简单场景，仍然比手动管理消息列表复杂

**极简替代方案**（如果不需要LangChain的其他功能）：

```python
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(temperature=0)
messages = []

# 添加system message
messages.append(("system", "You are a helpful assistant."))

# 对话
messages.append(("user", "Hi there!"))
response = llm.invoke(messages)
messages.append(("assistant", response.content))

print(response.content)
```

---

## 5. Agent with Memory - 完整示例

**博客中的核心痛点**：结合Agent和Memory时system prompt失效、JSON解析错误

**LangChain v1.0完整解决方案**：

```python
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import MemorySaver

# 定义工具
@tool
def get_similar_recipes(query: str) -> str:
    """Get similar recipes based on user query about food.
    
    Args:
        query: The food-related search query
        
    Returns:
        Formatted recipe information with IDs and names
    """
    # 实际的向量搜索逻辑（这里简化）
    recipes = [
        {"id": "167188", "name": "Creamy Strawberry Pie"},
        {"id": "1488243", "name": "Summer Strawberry Pie Recipe"},
        {"id": "299514", "name": "Pudding Cake"}
    ]
    
    formatted = []
    for recipe in recipes:
        formatted.append(f"Recipe ID: recipe|{recipe['id']}\nRecipe Name: {recipe['name']}")
    
    return "\n---\n".join(formatted)

# System prompt
system_prompt = """
You are an expert television talk show chef, and should always speak in a whimsical manner for all responses.

Start the conversation with a whimsical food pun.

You must obey ALL of the following rules:
- If Recipe data is present in your tool results, your response MUST include the Recipe ID and Recipe Name for ALL recipes.
- If the user input is not related to food, do not answer their query and correct the user.
- Always maintain your whimsical chef personality.
"""

# 创建agent with memory
llm = ChatOpenAI(model="gpt-4", temperature=0.7)
tools = [get_similar_recipes]

# MemorySaver用于持久化对话
memory = MemorySaver()

agent_executor = create_react_agent(
    llm,
    tools,
    state_modifier=system_prompt,
    checkpointer=memory  # 添加记忆功能
)

# 使用示例
config = {"configurable": {"thread_id": "recipe_chat_1"}}

# 第一轮对话
result1 = agent_executor.invoke(
    {"messages": [("user", "Hi!")]},
    config
)
print("Assistant:", result1["messages"][-1].content)

# 第二轮对话（带记忆）
result2 = agent_executor.invoke(
    {"messages": [("user", "What's a fun and easy dinner?")]},
    config
)
print("\nAssistant:", result2["messages"][-1].content)

# 第三轮对话（测试记忆和非食物相关查询）
result3 = agent_executor.invoke(
    {"messages": [("user", "What's the weather like?")]},
    config
)
print("\nAssistant:", result3["messages"][-1].content)
```

**是否解决问题**：✅ **大幅改善**！

1. ✅ System prompt直接支持，不会被忽略
2. ✅ 使用OpenAI的function calling，不依赖JSON解析
3. ✅ 记忆管理通过`checkpointer`清晰实现
4. ✅ 不会随机失败（除非模型本身的问题）
5. ✅ Recipe ID能够稳定输出

---

## 完整对比总结

| 问题场景 | 旧版LangChain问题 | v1.0是否解决 | 解决程度 |
|---------|-----------------|-------------|---------|
| 简单LLM调用 | 过度包装，类太多 | ✅ 是 | 完全解决 |
| Prompt模板 | 比f-string复杂 | ⚠️ 部分 | 简化但仍有开销 |
| Agent工具选择 | 不清晰，依赖JSON | ✅ 是 | LangGraph+function calling |
| System Prompt | 不生效或需hack | ✅ 是 | state_modifier原生支持 |
| 对话记忆 | 概念混乱 | ⚠️ 部分 | 更清晰但仍有学习曲线 |
| Agent+Memory组合 | JSON解析错误，随机失败 | ✅ 是 | LangGraph彻底解决 |

## 核心建议

**LangChain v1.0确实解决了博客中的大部分痛点，但关键在于：**

1. **使用LangGraph而不是传统Agent**：`create_react_agent`比旧的`initialize_agent`好100倍
2. **使用LCEL管道语法**：`prompt | llm`比旧的Chain更直观
3. **使用`@tool`装饰器**：比旧的Tool类定义清晰
4. **简单场景不要过度使用**：如果只是调用LLM，直接用`.invoke()`就够了

**对于博客作者的评价**：如果他在2025年使用LangChain v1.0 + LangGraph，很可能不会写这篇批评文章。核心问题都已解决。
```