## Me:

```markdown
é˜…è¯»è¿™ç¯‡2023å¹´æ‰¹è¯„LangChainçš„hello worldä»£ç è¿‡äºå¤æ‚çš„æ–‡ç« ï¼Œç„¶åå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. å…¨é¢åˆ—å‡ºæ–‡ä¸­å…·ä½“è®¨è®ºäº†LangChainçš„hello worldç¨‹åºæœ‰å“ªäº›ç¼ºç‚¹
2. å°†æ¯ä¸ªç¼ºç‚¹çš„ç¤ºä¾‹ä»£ç æ”¹ç¼–ä¸ºå¯åœ¨macOSçš„iTerm2çš„zshä¸­è¿è¡Œçš„Pythonä»£ç ï¼Œç¡®ä¿èƒ½é€šè¿‡è¾“å‡ºçœ‹åˆ°è¿è¡Œè¿‡ç¨‹ï¼Œå¹¶æä¾›è¿è¡Œæ­¥éª¤
ä¸‹é¢æ˜¯è¿™ç¯‡æ–‡ç« ï¼šã€

## **â€œHello Worldâ€ in LangChain (or More Accurately, â€œHell Worldâ€)**

TheÂ [Quickstart](https://python.langchain.com/docs/get_started/quickstart)Â for LangChain begins with a mini-tutorial on how to simply interact with LLMs/ChatGPT from Python. For example, to create a bot that can translate from English to French:

```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import (
    AIMessage,
    HumanMessage,
    SystemMessage
)

chat **=** ChatOpenAI(temperature**=**0)
chat**.**predict_messages([HumanMessage(content**=**"Translate this sentence from English to French. I love programming.")])
*# AIMessage(content="J'adore la programmation.", additional_kwargs={}, example=False)*
```

The equivalent code usingÂ [OpenAIâ€™s official Python library](https://github.com/openai/openai-python)Â for ChatGPT:

```python
import openai

messages **=** [{"role": "user", "content": "Translate this sentence from English to French. I love programming."}]

response **=** openai**.**ChatCompletion**.**create(model**=**"gpt-3.5-turbo", messages**=**messages, temperature**=**0)
response["choices"][0]["message"]["content"]
*# "J'adore la programmation."*
```

LangChain uses about the same amount of code as just using the officialÂ `openai`Â library, expect LangChain incorporates more object classes for not much obvious code benefit.

The prompt templating example reveals the core of how LangChain works:

```python
`from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template **=** "You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt **=** SystemMessagePromptTemplate**.**from_template(template)
human_template **=** "{text}"
human_message_prompt **=** HumanMessagePromptTemplate**.**from_template(human_template)

chat_prompt **=** ChatPromptTemplate**.**from_messages([system_message_prompt, human_message_prompt])

chat_prompt**.**format_messages(input_language**=**"English", output_language**=**"French", text**=**"I love programming.")`
```

LangChainâ€™s vaunted prompt engineering is justÂ [f-strings](https://realpython.com/python-f-strings/), a feature present in every modern Python installation, but with extra steps. Why do we need to use theseÂ `PromptTemplates`Â to do the same thing?

But what we really want to do is know how to create Agents, which incorporate the ReAct workflow we so desperately want. Fortunately there is a demo for that, which leveragesÂ [SerpApi](https://serpapi.com/)Â and another tool for math computations, showing how LangChain can discriminate and use two different tools contextually:

```python
`from langchain.agents import load_tools
from langchain.agents import initialize_agent
from langchain.agents import AgentType
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI

*# First, let's load the language model we're going to use to control the agent.*chat **=** ChatOpenAI(temperature**=**0)

*# Next, let's load some tools to use. Note that the `llm-math` tool uses an LLM, so we need to pass that in.*llm **=** OpenAI(temperature**=**0)
tools **=** load_tools(["serpapi", "llm-math"], llm**=**llm)

*# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.*agent **=** initialize_agent(tools, chat, agent**=**AgentType**.**CHAT_ZERO_SHOT_REACT_DESCRIPTION, verbose**=**True)

*# Now let's test it out!*agent**.**run("Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?")`
```

How do the individual tools work? What isÂ `AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION`Â anyways? The resulting output fromÂ `agent.run()`Â (only present withÂ `verbose=True`) is more helpful.

```bash
`> Entering new AgentExecutor chain...
Thought: I need to use a search engine to find Olivia Wilde's boyfriend and a calculator to raise his age to the 0.23 power.
Action:
{
    "action": "Search",
    "action_input": "Olivia Wilde boyfriend"
}

Observation: Sudeikis and Wilde's relationship ended in November 2020. Wilde was publicly served with court documents regarding child custody while she was presenting Don't Worry Darling at CinemaCon 2022. In January 2021, Wilde began dating singer Harry Styles after meeting during the filming of Don't Worry Darling.
Thought:I need to use a search engine to find Harry Styles' current age.
Action:
{
    "action": "Search",
    "action_input": "Harry Styles age"
}

Observation: 29 years
Thought:Now I need to calculate 29 raised to the 0.23 power.
Action:
{
    "action": "Calculator",
    "action_input": "29^0.23"
}

Observation: Answer: 2.169459462491557

Thought:I now know the final answer.
Final Answer: 2.169459462491557

> Finished chain.
'2.169459462491557'`
```

The documentation doesnâ€™t make it clear, but within each Thought/Action/Observation uses its own API call to OpenAI, so the chain is slower than you might think. Also, why is each action aÂ `dict`? The answer toÂ *that*Â is later, and is very silly.

Lastly, how does LangChain store the conversation so far?

```bash
from langchain.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

prompt **=** ChatPromptTemplate**.**from_messages([
    SystemMessagePromptTemplate**.**from_template(
        "The following is a friendly conversation between a human and an AI. The AI is talkative and "
        "provides lots of specific details from its context. If the AI does not know the answer to a "
        "question, it truthfully says it does not know."
    ),
    MessagesPlaceholder(variable_name**=**"history"),
    HumanMessagePromptTemplate**.**from_template("{input}")
])

llm **=** ChatOpenAI(temperature**=**0)
memory **=** ConversationBufferMemory(return_messages**=**True)
conversation **=** ConversationChain(memory**=**memory, prompt**=**prompt, llm**=**llm)

conversation**.**predict(input**=**"Hi there!")
*# 'Hello! How can I assist you today?'*
```

Iâ€™m not entirely sure why any of this is necessary. Whatâ€™s aÂ `MessagesPlaceholder`? Whereâ€™s theÂ `history`? Is that necessary forÂ `ConversationBufferMemory`? Adapting this to a minimalÂ `openai`Â implementation:

```python
import openai

messages **=** [{"role": "system", "content":
        "The following is a friendly conversation between a human and an AI. The AI is talkative and "
        "provides lots of specific details from its context. If the AI does not know the answer to a "
        "question, it truthfully says it does not know."}]

user_message **=** "Hi there!"
messages**.**append({"role": "user", "content": user_message})
response **=** openai**.**ChatCompletion**.**create(model**=**"gpt-3.5-turbo", messages**=**messages, temperature**=**0)
assistant_message **=** response["choices"][0]["message"]["content"]
messages**.**append({"role": "assistant", "content": assistant_message})
*# Hello! How can I assist you today?*
```

Thatâ€™s fewer lines of code and makes it very clear where and when the messages are being saved, no bespoke object classes needed.

You can say that Iâ€™m nitpicking the tutorial examples, and I do agree that every open source library has something to nitpick (including my own!). But if there are more nitpicks than actual benefits from the library then itâ€™s not worth using at all, since if theÂ *quickstart*Â is this complicated, how painful will it be to use LangChain in practice?

ã€‘
```

## Claude app with sonnet 4.5:

```markdown
æˆ‘æ¥å¸®ä½ åˆ†æè¿™ç¯‡æ–‡ç« å¹¶åˆ›å»ºå¯è¿è¡Œçš„å¯¹æ¯”ä»£ç ã€‚

## ä»»åŠ¡1ï¼šLangChain Hello Worldç¨‹åºçš„ç¼ºç‚¹åˆ—è¡¨

æ ¹æ®æ–‡ç« å†…å®¹ï¼Œä½œè€…æ‰¹è¯„äº†ä»¥ä¸‹å‡ ä¸ªä¸»è¦ç¼ºç‚¹ï¼š

### 1. **è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿**
- LangChainå¼•å…¥äº†`ChatOpenAI`, `HumanMessage`, `SystemMessage`, `AIMessage`ç­‰å¤šä¸ªç±»
- ä»£ç é‡ä¸ç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹åº“ç›¸å½“ï¼Œä½†å¢åŠ äº†ä¸å¿…è¦çš„æŠ½è±¡å±‚

### 2. **Promptæ¨¡æ¿è¿‡äºå¤æ‚**
- `ChatPromptTemplate`, `SystemMessagePromptTemplate`, `HumanMessagePromptTemplate`ç­‰å¤šå±‚åµŒå¥—
- å®é™…ä¸Šåªæ˜¯Python f-stringsçš„åŒ…è£…ï¼Œä½†å¢åŠ äº†é¢å¤–æ­¥éª¤
- ä½œè€…è´¨é—®ï¼š"ä¸ºä»€ä¹ˆéœ€è¦ç”¨è¿™äº›PromptTemplatesæ¥åšåŒæ ·çš„äº‹ï¼Ÿ"

### 3. **Agentå®ç°ä¸é€æ˜**
- ä¸æ¸…æ¥šå„ä¸ªå·¥å…·å¦‚ä½•å·¥ä½œ
- `AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION`æ¦‚å¿µæ™¦æ¶©éš¾æ‡‚
- éœ€è¦è®¾ç½®`verbose=True`æ‰èƒ½çœ‹åˆ°æ‰§è¡Œè¿‡ç¨‹

### 4. **æ€§èƒ½é—®é¢˜éšè—**
- æ–‡æ¡£æœªæ˜ç¡®è¯´æ˜ï¼šæ¯ä¸ªThought/Action/Observationæ­¥éª¤éƒ½ä¼šå•ç‹¬è°ƒç”¨OpenAI API
- å¯¼è‡´é“¾å¼æ“ä½œæ¯”é¢„æœŸæ…¢å¾—å¤š

### 5. **ä¸åˆç†çš„æ•°æ®ç»“æ„è®¾è®¡**
- Actionä¸ºä»€ä¹ˆè¦ç”¨dictæ ¼å¼ï¼Ÿæ–‡ç« è¯´ç­”æ¡ˆ"éå¸¸silly"

### 6. **å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚**
- `ConversationBufferMemory`, `MessagesPlaceholder`, `ConversationChain`ç­‰æ¦‚å¿µ
- ä½œè€…è´¨ç–‘ï¼š`MessagesPlaceholder`æ˜¯ä»€ä¹ˆï¼Ÿ`history`åœ¨å“ªé‡Œï¼Ÿè¿™äº›çœŸçš„å¿…è¦å—ï¼Ÿ
- ä½¿ç”¨ç®€å•çš„messagesåˆ—è¡¨å°±èƒ½å®ç°ç›¸åŒåŠŸèƒ½ï¼Œä»£ç æ›´æ¸…æ™°

---

## ä»»åŠ¡2ï¼šå¯è¿è¡Œçš„å¯¹æ¯”ä»£ç ç¤ºä¾‹

è®©æˆ‘åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„Pythonè„šæœ¬ï¼Œå±•ç¤ºæ¯ä¸ªç¼ºç‚¹çš„å¯¹æ¯”ï¼šå®Œç¾ï¼æˆ‘å·²ç»å®Œæˆäº†æ‰€æœ‰ä»»åŠ¡ã€‚è®©æˆ‘ä¸ºä½ æ€»ç»“ä¸€ä¸‹ï¼š

## âœ… ä»»åŠ¡å®Œæˆæ€»ç»“

### ğŸ“‹ ä»»åŠ¡1ï¼šLangChainç¼ºç‚¹å…¨é¢åˆ—è¡¨

æˆ‘å·²ç»å…¨é¢åˆ†æäº†æ–‡ç« ä¸­çš„**6å¤§ç±»ç¼ºç‚¹**ï¼š

1. **è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»** - å¼•å…¥é¢å¤–æŠ½è±¡ä½†æ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿
2. **Promptæ¨¡æ¿è¿‡äºå¤æ‚** - åªæ˜¯f-stringsçš„åŒ…è£…ï¼Œå´å¢åŠ äº†å¤§é‡ç±»å’Œæ­¥éª¤
3. **Agentå®ç°ä¸é€æ˜** - å·¥å…·æœºåˆ¶ä¸æ¸…æ™°ï¼Œå‘½åæ™¦æ¶©ï¼ˆå¦‚`AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION`ï¼‰
4. **æ€§èƒ½é—®é¢˜è¢«éšè—** - æ¯ä¸ªThought/Action/Observationéƒ½è°ƒç”¨APIï¼Œä½†æ–‡æ¡£æœªè¯´æ˜
5. **å¯¹è¯è®°å¿†ç®¡ç†å¤æ‚** - å¼•å…¥ä¸å¿…è¦çš„`ConversationBufferMemory`ã€`MessagesPlaceholder`ç­‰æ¦‚å¿µ
6. **å…¶ä»–è®¾è®¡é—®é¢˜** - actionä¸ºä½•æ˜¯dictã€éœ€è¦ä¸¤ä¸ªLLMå®ä¾‹ç­‰

### ğŸ¯ ä»»åŠ¡2ï¼šå¯è¿è¡Œçš„å¯¹æ¯”ä»£ç 

æˆ‘åˆ›å»ºäº†**5ä¸ªæ–‡ä»¶**ä¾›ä½ ä¸‹è½½å’Œè¿è¡Œï¼š

#### 1. [**langchain_critique_demo.py**](computer:///mnt/user-data/outputs/langchain_critique_demo.py)
ä¸»æ¼”ç¤ºè„šæœ¬ï¼ŒåŒ…å«ç¼ºç‚¹1-3çš„è¯¦ç»†å¯¹æ¯”ï¼š
- å¯¹è±¡ç±»ä½¿ç”¨å¯¹æ¯”
- Promptæ¨¡æ¿å¯¹æ¯”
- å¯¹è¯è®°å¿†ç®¡ç†å¯¹æ¯”
- æ¯ä¸ªç¤ºä¾‹éƒ½æœ‰LangChainæ–¹å¼ vs OpenAIå®˜æ–¹åº“æ–¹å¼
- æ˜¾ç¤ºå®é™…è¿è¡Œç»“æœå’Œè€—æ—¶

#### 2. [**langchain_agent_performance_demo.py**](computer:///mnt/user-data/outputs/langchain_agent_performance_demo.py)
Agentæ€§èƒ½é—®é¢˜ä¸“é¡¹æ¼”ç¤ºï¼š
- å±•ç¤ºAgentçš„å¤šæ­¥æ‰§è¡Œè¿‡ç¨‹
- æ­ç¤ºæ¯ä¸ªThought/Action/Observationçš„APIè°ƒç”¨
- åˆ†ææ€§èƒ½å½±å“å’Œæˆæœ¬

#### 3. [**README.md**](computer:///mnt/user-data/outputs/README.md)
å®Œæ•´çš„è¿è¡ŒæŒ‡å—ï¼ŒåŒ…å«ï¼š
- ç¯å¢ƒå‡†å¤‡æ­¥éª¤
- ä¾èµ–å®‰è£…å‘½ä»¤
- APIå¯†é’¥é…ç½®
- å¸¸è§é—®é¢˜è§£å†³
- å­¦ä¹ è¦ç‚¹å’Œå»¶ä¼¸èµ„æº

#### 4. [**quickstart.sh**](computer:///mnt/user-data/outputs/quickstart.sh)
ä¸€é”®å¯åŠ¨è„šæœ¬ï¼š
- è‡ªåŠ¨æ£€æŸ¥Pythonç¯å¢ƒ
- è‡ªåŠ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
- è‡ªåŠ¨å®‰è£…æ‰€æœ‰ä¾èµ–
- äº¤äº’å¼APIå¯†é’¥è®¾ç½®
- èœå•é€‰æ‹©è¦è¿è¡Œçš„æ¼”ç¤º

#### 5. [**ç¼ºç‚¹è¯¦ç»†åˆ†æ.md**](computer:///mnt/user-data/outputs/ç¼ºç‚¹è¯¦ç»†åˆ†æ.md)
è¯¦ç»†çš„ç¼ºç‚¹åˆ†ææ–‡æ¡£ï¼š
- æ¯ä¸ªç¼ºç‚¹çš„è¯¦ç»†è¯´æ˜
- å®Œæ•´çš„ä»£ç å¯¹æ¯”
- æ·±å…¥åˆ†æå’Œè¯„ä¼°
- å®è·µå»ºè®®

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆåœ¨macOS iTerm2ä¸­ï¼‰

```bash
# 1. ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•
cd ~/Downloads
mkdir langchain-critique-demo
cd langchain-critique-demo

# 2. è¿è¡Œå¿«é€Ÿå¯åŠ¨è„šæœ¬
chmod +x quickstart.sh
./quickstart.sh

# 3. è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
#    - æ£€æŸ¥Pythonç¯å¢ƒ
#    - åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
#    - å®‰è£…ä¾èµ–
#    - è®¾ç½®APIå¯†é’¥
#    - è¿è¡Œæ¼”ç¤º
```

### æˆ–è€…æ‰‹åŠ¨è¿è¡Œï¼š

```bash
# è®¾ç½®ç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install openai==0.28.1 langchain==0.0.350 langchain-openai==0.0.2

# è®¾ç½®APIå¯†é’¥
export OPENAI_API_KEY='your-key-here'

# è¿è¡Œæ¼”ç¤º
python3 langchain_critique_demo.py
python3 langchain_agent_performance_demo.py
```

---

## ğŸ“ æ ¸å¿ƒä»·å€¼

é€šè¿‡è¿™äº›æ¼”ç¤ºä»£ç ï¼Œä½ å°†èƒ½å¤Ÿï¼š

1. **äº²çœ¼çœ‹åˆ°**æ–‡ç« ä¸­æ‰¹è¯„çš„æ¯ä¸ªé—®é¢˜
2. **å¯¹æ¯”è¿è¡Œ**LangChain vs OpenAIå®˜æ–¹åº“
3. **ç†è§£æ€§èƒ½å·®å¼‚**ï¼ˆç‰¹åˆ«æ˜¯Agentçš„å¤šæ¬¡APIè°ƒç”¨ï¼‰
4. **å­¦ä¹ æœ€ä½³å®è·µ**ï¼ˆä½•æ—¶è¯¥ç”¨æ¡†æ¶ï¼Œä½•æ—¶è¯¥ç”¨åŸç”ŸAPIï¼‰

æ‰€æœ‰ä»£ç éƒ½åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šå’Œè¾“å‡ºè¯´æ˜ï¼Œç¡®ä¿ä½ èƒ½æ¸…æ¥šçœ‹åˆ°æ¯ä¸ªæ­¥éª¤çš„æ‰§è¡Œè¿‡ç¨‹ï¼ğŸ‰
```

### langchain_critique_demo.py

```python
#!/usr/bin/env python3
"""
LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º
æ¼”ç¤ºæ–‡ç« ä¸­æåˆ°çš„æ¯ä¸ªç¼ºç‚¹ï¼Œå¹¶ä¸OpenAIå®˜æ–¹åº“è¿›è¡Œå¯¹æ¯”
"""

import os
import sys
import time

# æ£€æŸ¥OpenAI APIå¯†é’¥
if not os.environ.get("OPENAI_API_KEY"):
    print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
    print("   export OPENAI_API_KEY='your-api-key-here'")
    sys.exit(1)

print("=" * 80)
print("LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º")
print("=" * 80)
print()

# ============================================================================
# ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿
# ============================================================================
print("ğŸ“Œ ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (ä½¿ç”¨å¤šä¸ªå¯¹è±¡ç±»):")
print("ä»£ç :")
print("""
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

chat = ChatOpenAI(temperature=0)
result = chat.predict_messages([HumanMessage(content="Translate: I love programming to French")])
print(result.content)
""")

try:
    from langchain.chat_models import ChatOpenAI
    from langchain.schema import HumanMessage
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    chat = ChatOpenAI(temperature=0)
    result = chat.predict_messages([HumanMessage(content="Translate this sentence from English to French. I love programming.")])
    elapsed = time.time() - start
    print(f"âœ… {result.content}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")
    print("æç¤º: è¯·ç¡®ä¿å·²å®‰è£… langchain å’Œ langchain-openai")

print("\n" + "=" * 80)
print("\nğŸŸ¢ OpenAIå®˜æ–¹åº“æ–¹å¼ (ç®€æ´ç›´æ¥):")
print("ä»£ç :")
print("""
import openai

messages = [{"role": "user", "content": "Translate: I love programming to French"}]
response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
print(response["choices"][0]["message"]["content"])
""")

try:
    import openai
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    messages = [{"role": "user", "content": "Translate this sentence from English to French. I love programming."}]
    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
    elapsed = time.time() - start
    print(f"âœ… {response['choices'][0]['message']['content']}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
except Exception as e:
    print(f"âŒ OpenAIæ‰§è¡Œå¤±è´¥: {e}")

print("\nğŸ’¡ åˆ†æ: ä¸¤ç§æ–¹å¼ä»£ç é‡ç›¸å½“ï¼Œä½†LangChainå¼•å…¥äº†é¢å¤–çš„å¯¹è±¡ç±»ï¼Œå¢åŠ äº†å¤æ‚åº¦")
print()

# ============================================================================
# ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Œ ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚ (å®é™…ä¸Šåªæ˜¯f-stringsçš„åŒ…è£…)")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (å¤šå±‚åµŒå¥—çš„æ¨¡æ¿ç±»):")
print("ä»£ç :")
print("""
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template = "You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template = "{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
messages = chat_prompt.format_messages(
    input_language="English", 
    output_language="French", 
    text="I love programming."
)
print(messages)
""")

try:
    from langchain.prompts.chat import (
        ChatPromptTemplate,
        SystemMessagePromptTemplate,
        HumanMessagePromptTemplate,
    )
    
    print("\næ‰§è¡Œç»“æœ:")
    template = "You are a helpful assistant that translates {input_language} to {output_language}."
    system_message_prompt = SystemMessagePromptTemplate.from_template(template)
    human_template = "{text}"
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    
    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    messages = chat_prompt.format_messages(
        input_language="English", 
        output_language="French", 
        text="I love programming."
    )
    print("âœ… ç”Ÿæˆçš„æ¶ˆæ¯:")
    for msg in messages:
        print(f"   - {type(msg).__name__}: {msg.content}")
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")

print("\n" + "=" * 80)
print("\nğŸŸ¢ PythonåŸç”Ÿf-stringsæ–¹å¼ (ç®€å•ç›´æ¥):")
print("ä»£ç :")
print("""
input_language = "English"
output_language = "French"
text = "I love programming."

system_content = f"You are a helpful assistant that translates {input_language} to {output_language}."
human_content = f"{text}"

messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": human_content}
]
print(messages)
""")

print("\næ‰§è¡Œç»“æœ:")
input_language = "English"
output_language = "French"
text = "I love programming."

system_content = f"You are a helpful assistant that translates {input_language} to {output_language}."
human_content = f"{text}"

messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": human_content}
]
print("âœ… ç”Ÿæˆçš„æ¶ˆæ¯:")
for msg in messages:
    print(f"   - {msg['role']}: {msg['content']}")

print("\nğŸ’¡ åˆ†æ: LangChainçš„promptæ¨¡æ¿åªæ˜¯f-stringsçš„åŒ…è£…ï¼Œä½†å¢åŠ äº†3ä¸ªé¢å¤–çš„ç±»å’Œå¤šè¡Œä»£ç ")
print()

# ============================================================================
# ç¼ºç‚¹3: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Œ ç¼ºç‚¹3: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (å¤šä¸ªæ¦‚å¿µ: ConversationBufferMemory, MessagesPlaceholderç­‰):")
print("ä»£ç :")
print("""
from langchain.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        "The following is a friendly conversation between a human and an AI."
    ),
    MessagesPlaceholder(variable_name="history"),
    HumanMessagePromptTemplate.from_template("{input}")
])

llm = ChatOpenAI(temperature=0)
memory = ConversationBufferMemory(return_messages=True)
conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)

response = conversation.predict(input="Hi there!")
print(response)
""")

try:
    from langchain.prompts import (
        ChatPromptTemplate,
        MessagesPlaceholder,
        SystemMessagePromptTemplate,
        HumanMessagePromptTemplate
    )
    from langchain.chains import ConversationChain
    from langchain.chat_models import ChatOpenAI
    from langchain.memory import ConversationBufferMemory
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    
    prompt = ChatPromptTemplate.from_messages([
        SystemMessagePromptTemplate.from_template(
            "The following is a friendly conversation between a human and an AI. "
            "The AI is talkative and provides lots of specific details from its context."
        ),
        MessagesPlaceholder(variable_name="history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    
    llm = ChatOpenAI(temperature=0)
    memory = ConversationBufferMemory(return_messages=True)
    conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)
    
    response = conversation.predict(input="Hi there!")
    elapsed = time.time() - start
    print(f"âœ… {response}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    # ç»§ç»­å¯¹è¯
    response2 = conversation.predict(input="What's 2+2?")
    print(f"âœ… {response2}")
    
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")

print("\n" + "=" * 80)
print("\nğŸŸ¢ OpenAIå®˜æ–¹åº“æ–¹å¼ (ä½¿ç”¨ç®€å•çš„åˆ—è¡¨):")
print("ä»£ç :")
print("""
import openai

messages = [{
    "role": "system", 
    "content": "The following is a friendly conversation between a human and an AI."
}]

# ç¬¬ä¸€è½®å¯¹è¯
user_message = "Hi there!"
messages.append({"role": "user", "content": user_message})
response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
assistant_message = response["choices"][0]["message"]["content"]
messages.append({"role": "assistant", "content": assistant_message})
print(assistant_message)

# ç¬¬äºŒè½®å¯¹è¯
user_message2 = "What's 2+2?"
messages.append({"role": "user", "content": user_message2})
response2 = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
assistant_message2 = response2["choices"][0]["message"]["content"]
messages.append({"role": "assistant", "content": assistant_message2})
print(assistant_message2)
""")

try:
    import openai
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    
    messages = [{
        "role": "system", 
        "content": "The following is a friendly conversation between a human and an AI. "
                   "The AI is talkative and provides lots of specific details from its context."
    }]
    
    # ç¬¬ä¸€è½®å¯¹è¯
    user_message = "Hi there!"
    messages.append({"role": "user", "content": user_message})
    response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
    assistant_message = response["choices"][0]["message"]["content"]
    messages.append({"role": "assistant", "content": assistant_message})
    elapsed = time.time() - start
    print(f"âœ… {assistant_message}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    # ç¬¬äºŒè½®å¯¹è¯
    user_message2 = "What's 2+2?"
    messages.append({"role": "user", "content": user_message2})
    response2 = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages, temperature=0)
    assistant_message2 = response2["choices"][0]["message"]["content"]
    messages.append({"role": "assistant", "content": assistant_message2})
    print(f"âœ… {assistant_message2}")
    
    print(f"\nğŸ“ å½“å‰å¯¹è¯å†å² ({len(messages)} æ¡æ¶ˆæ¯):")
    for i, msg in enumerate(messages):
        print(f"   {i+1}. [{msg['role']}] {msg['content'][:50]}...")
    
except Exception as e:
    print(f"âŒ OpenAIæ‰§è¡Œå¤±è´¥: {e}")

print("\nğŸ’¡ åˆ†æ: OpenAIå®˜æ–¹åº“ä»£ç æ›´å°‘ï¼Œé€»è¾‘æ›´æ¸…æ™°ï¼Œèƒ½ç›´æ¥çœ‹åˆ°æ¶ˆæ¯çš„ä¿å­˜ä½ç½®å’Œæ—¶æœº")
print("   LangChainå¼•å…¥äº†ConversationBufferMemoryã€MessagesPlaceholderç­‰æ¦‚å¿µï¼Œå¢åŠ äº†å­¦ä¹ æˆæœ¬")

# ============================================================================
# æ€»ç»“
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š æ€»ç»“")
print("=" * 80)
print("""
æ–‡ç« ä½œè€…çš„æ ¸å¿ƒè§‚ç‚¹:

1. âŒ LangChainå¼•å…¥äº†å¤§é‡æŠ½è±¡å±‚ï¼ˆå¯¹è±¡ç±»ã€æ¨¡æ¿ç±»ã€è®°å¿†ç±»ç­‰ï¼‰
2. âŒ è¿™äº›æŠ½è±¡æ²¡æœ‰å¸¦æ¥æ˜æ˜¾çš„ä»£ç ä¼˜åŠ¿ï¼Œåè€Œå¢åŠ äº†å¤æ‚åº¦
3. âŒ å¾ˆå¤šåŠŸèƒ½ç”¨PythonåŸç”Ÿç‰¹æ€§ï¼ˆå¦‚f-stringsï¼‰æˆ–OpenAIå®˜æ–¹åº“å°±èƒ½ç®€å•å®ç°
4. âŒ æ–‡æ¡£ä¸å¤Ÿé€æ˜ï¼Œéšè—äº†é‡è¦çš„æ€§èƒ½ç»†èŠ‚ï¼ˆå¦‚Agentæ¯æ­¥éƒ½è°ƒç”¨APIï¼‰
5. âŒ å¦‚æœquickstartå°±è¿™ä¹ˆå¤æ‚ï¼Œå®é™…ä½¿ç”¨ä¼šæ›´ç—›è‹¦

ä½œè€…è®¤ä¸º: "å¦‚æœnitpicksï¼ˆå¹æ¯›æ±‚ç–µçš„é—®é¢˜ï¼‰æ¯”å®é™…å¥½å¤„è¿˜å¤šï¼Œè¿™ä¸ªåº“å°±ä¸å€¼å¾—ä½¿ç”¨"
""")

print("=" * 80)
print("æ¼”ç¤ºå®Œæˆ!")
print("=" * 80)

```

### langchain_agent_performance_demo.py

```python
#!/usr/bin/env python3
"""
LangChain Agent æ€§èƒ½é—®é¢˜æ¼”ç¤º
æ¼”ç¤ºæ–‡ç« ä¸­æåˆ°çš„ç¼ºç‚¹4: æ¯ä¸ªThought/Action/Observationæ­¥éª¤éƒ½å•ç‹¬è°ƒç”¨APIï¼Œå¯¼è‡´æ€§èƒ½é—®é¢˜
"""

import os
import sys
import time

# æ£€æŸ¥APIå¯†é’¥
if not os.environ.get("OPENAI_API_KEY"):
    print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
    sys.exit(1)

if not os.environ.get("SERPAPI_API_KEY"):
    print("âš ï¸  è­¦å‘Šï¼šæœªè®¾ç½®SERPAPI_API_KEYç¯å¢ƒå˜é‡")
    print("   Agentæ¼”ç¤ºéœ€è¦SerpAPIå¯†é’¥ï¼Œå¯ä»¥ä» https://serpapi.com è·å–")
    print("   export SERPAPI_API_KEY='your-serpapi-key-here'")
    print()

print("=" * 80)
print("LangChain Agent æ€§èƒ½é—®é¢˜æ¼”ç¤º")
print("=" * 80)
print()

print("ğŸ“Œ ç¼ºç‚¹4: Agentæ¯ä¸ªæ­¥éª¤éƒ½å•ç‹¬è°ƒç”¨APIï¼Œä½†æ–‡æ¡£æœªæ˜ç¡®è¯´æ˜")
print("-" * 80)
print()

print("ğŸ”´ LangChain Agentæ–¹å¼:")
print("ä»£ç :")
print("""
from langchain.agents import load_tools, initialize_agent, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI

chat = ChatOpenAI(temperature=0)
llm = OpenAI(temperature=0)
tools = load_tools(["serpapi", "llm-math"], llm=llm)

agent = initialize_agent(
    tools, 
    chat, 
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, 
    verbose=True
)

# æ³¨æ„ï¼šè¿™ä¸ªæŸ¥è¯¢ä¼šäº§ç”Ÿå¤šæ¬¡APIè°ƒç”¨ï¼
result = agent.run("Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?")
""")

if os.environ.get("SERPAPI_API_KEY"):
    try:
        from langchain.agents import load_tools, initialize_agent, AgentType
        from langchain.chat_models import ChatOpenAI
        from langchain.llms import OpenAI
        
        print("\næ‰§è¡Œç»“æœ:")
        print("â±ï¸  å¼€å§‹è®¡æ—¶...")
        start = time.time()
        
        chat = ChatOpenAI(temperature=0)
        llm = OpenAI(temperature=0)
        tools = load_tools(["serpapi", "llm-math"], llm=llm)
        
        agent = initialize_agent(
            tools, 
            chat, 
            agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION, 
            verbose=True
        )
        
        print("\nğŸ¤– Agentå¼€å§‹æ‰§è¡Œ...")
        print("-" * 80)
        result = agent.run("Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?")
        print("-" * 80)
        
        elapsed = time.time() - start
        print(f"\nâœ… æœ€ç»ˆç­”æ¡ˆ: {result}")
        print(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.2f}ç§’")
        
        print("\nğŸ’¡ åˆ†æ:")
        print("   ä»verbose=Trueçš„è¾“å‡ºå¯ä»¥çœ‹åˆ°:")
        print("   1. æ¯ä¸ª Thought -> Action -> Observation éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å¾ªç¯")
        print("   2. æ¯ä¸ªå¾ªç¯éƒ½ä¼šè°ƒç”¨ä¸€æ¬¡OpenAI API")
        print("   3. è¿™ä¸ªä¾‹å­ä¸­è‡³å°‘è¿›è¡Œäº†3-4æ¬¡APIè°ƒç”¨:")
        print("      - ç¬¬1æ¬¡: å†³å®šæœç´¢Olivia Wildeçš„ç”·å‹")
        print("      - ç¬¬2æ¬¡: æœç´¢åˆ°Harry Stylesåï¼Œå†³å®šæŸ¥å¹´é¾„")
        print("      - ç¬¬3æ¬¡: å¾—åˆ°å¹´é¾„åï¼Œå†³å®šè®¡ç®—29^0.23")
        print("      - ç¬¬4æ¬¡: å¾—åˆ°è®¡ç®—ç»“æœåï¼Œç»™å‡ºæœ€ç»ˆç­”æ¡ˆ")
        print("   4. ä½†LangChainæ–‡æ¡£å¹¶æœªæ˜ç¡®è¯´æ˜è¿™ä¸€ç‚¹ï¼")
        
    except Exception as e:
        print(f"âŒ LangChain Agentæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
else:
    print("\nâš ï¸  è·³è¿‡Agentæ¼”ç¤ºï¼ˆéœ€è¦SERPAPI_API_KEYï¼‰")
    print("\nğŸ’¡ å¦‚æœè¿è¡Œæ­¤æ¼”ç¤ºï¼Œä½ ä¼šçœ‹åˆ°:")
    print("   - Agentä¼šæ‰§è¡Œå¤šä¸ª Thought -> Action -> Observation å¾ªç¯")
    print("   - æ¯ä¸ªå¾ªç¯éƒ½ä¼šè°ƒç”¨ä¸€æ¬¡OpenAI API")
    print("   - æ€»è€—æ—¶ä¼šæ¯”ä½ é¢„æœŸçš„é•¿å¾ˆå¤š")
    print("   - ä½†æ–‡æ¡£ä¸­å¹¶æœªæ˜ç¡®è¯´æ˜è¿™ä¸ªæ€§èƒ½ç‰¹å¾ï¼")

print("\n" + "=" * 80)
print("\nğŸŸ¢ å¦‚æœç”¨OpenAIå®˜æ–¹åº“å®ç°ç±»ä¼¼åŠŸèƒ½:")
print("ä»£ç æ€è·¯:")
print("""
import openai
import requests

# ä¸€æ¬¡æ€§æ„é€ å®Œæ•´çš„æç¤ºè¯ï¼ŒåŒ…å«å·¥å…·æè¿°
system_prompt = '''
You are a helpful assistant with access to these tools:
1. Search: Search the web for information
2. Calculator: Perform mathematical calculations

When you need to use a tool, respond with JSON: {"tool": "tool_name", "input": "..."}
Otherwise, provide the final answer.
'''

# ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šè®©AIå†³å®šéœ€è¦ä»€ä¹ˆå·¥å…·
messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": "Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?"}
]

response1 = openai.ChatCompletion.create(model="gpt-4", messages=messages)
# AIå¯èƒ½å“åº”: {"tool": "Search", "input": "Olivia Wilde boyfriend"}

# æ‰§è¡Œæœç´¢ï¼Œè·å–ç»“æœ

# ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šæä¾›æœç´¢ç»“æœï¼Œè®©AIç»§ç»­
messages.append({"role": "assistant", "content": response1["choices"][0]["message"]["content"]})
messages.append({"role": "user", "content": "Search result: Harry Styles, 29 years old"})

response2 = openai.ChatCompletion.create(model="gpt-4", messages=messages)
# AIå¯èƒ½å“åº”: {"tool": "Calculator", "input": "29^0.23"}

# æ‰§è¡Œè®¡ç®—

# ç¬¬ä¸‰æ¬¡è°ƒç”¨ï¼šæä¾›è®¡ç®—ç»“æœï¼Œè®©AIç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
messages.append({"role": "assistant", "content": response2["choices"][0]["message"]["content"]})
messages.append({"role": "user", "content": "Calculation result: 2.169459462491557"})

response3 = openai.ChatCompletion.create(model="gpt-4", messages=messages)
# AIç»™å‡ºæœ€ç»ˆç­”æ¡ˆ
""")

print("\nğŸ’¡ åˆ†æ:")
print("   - ä½¿ç”¨OpenAIå®˜æ–¹åº“æ—¶ï¼Œä½ éœ€è¦æ‰‹åŠ¨å®ç°Agentå¾ªç¯")
print("   - ä½†ä½ ä¼šæ¸…æ¥šåœ°çŸ¥é“æ¯æ¬¡APIè°ƒç”¨çš„æ—¶æœºå’Œæˆæœ¬")
print("   - LangChainéšè—äº†è¿™äº›ç»†èŠ‚ï¼Œå¯èƒ½å¯¼è‡´æ„å¤–çš„é«˜æˆæœ¬å’Œæ…¢å“åº”")

print("\n" + "=" * 80)
print("ğŸ“Š å…³é”®é—®é¢˜æ€»ç»“")
print("=" * 80)
print("""
âŒ LangChainçš„é—®é¢˜:
   1. Agentçš„æ¯ä¸ªæ¨ç†æ­¥éª¤éƒ½ä¼šè°ƒç”¨API
   2. ä¸€ä¸ªç®€å•æŸ¥è¯¢å¯èƒ½äº§ç”Ÿ3-5æ¬¡APIè°ƒç”¨
   3. æ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®è¯´æ˜è¿™ä¸€ç‚¹
   4. ç”¨æˆ·å¯èƒ½ä¼šæƒŠè®¶äºé«˜æ˜‚çš„APIè´¹ç”¨å’Œé•¿æ—¶é—´çš„å“åº”å»¶è¿Ÿ
   5. AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION è¿™æ ·çš„å‘½åå¾ˆæ™¦æ¶©

âœ… é€æ˜åº¦çš„é‡è¦æ€§:
   - å¼€å‘è€…åº”è¯¥æ˜ç¡®çŸ¥é“ä½•æ—¶ã€ä¸ºä½•è°ƒç”¨API
   - æˆæœ¬å’Œæ€§èƒ½å½±å“åº”è¯¥æ˜¯å¯é¢„æµ‹çš„
   - æŠ½è±¡ä¸åº”è¯¥éšè—å…³é”®çš„æ€§èƒ½ç‰¹å¾
""")

print("\n" + "=" * 80)
print("æ¼”ç¤ºå®Œæˆ!")
print("=" * 80)

```

### README.md

```python
# LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º - è¿è¡ŒæŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®åŒ…å«ä¸¤ä¸ªPythonè„šæœ¬ï¼Œç”¨äºæ¼”ç¤º2023å¹´é‚£ç¯‡æ‰¹è¯„LangChainæ–‡ç« ä¸­æåˆ°çš„æ‰€æœ‰ç¼ºç‚¹ï¼Œå¹¶ä¸OpenAIå®˜æ–¹åº“è¿›è¡Œå¯¹æ¯”ã€‚

### è„šæœ¬è¯´æ˜

1. **langchain_critique_demo.py** - ä¸»æ¼”ç¤ºè„šæœ¬
   - ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»
   - ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚
   - ç¼ºç‚¹3: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚

2. **langchain_agent_performance_demo.py** - Agentæ€§èƒ½é—®é¢˜æ¼”ç¤º
   - ç¼ºç‚¹4: æ¯ä¸ªThought/Action/Observationæ­¥éª¤éƒ½å•ç‹¬è°ƒç”¨API
   - ç¼ºç‚¹5: Agentå®ç°ä¸é€æ˜

## ğŸš€ åœ¨macOS iTerm2ä¸­è¿è¡Œçš„å®Œæ•´æ­¥éª¤

### æ­¥éª¤1: ç¯å¢ƒå‡†å¤‡

```bash
# 1. æ‰“å¼€iTerm2ç»ˆç«¯

# 2. æ£€æŸ¥Pythonç‰ˆæœ¬ï¼ˆéœ€è¦Python 3.8+ï¼‰
python3 --version

# 3. åˆ›å»ºé¡¹ç›®ç›®å½•
mkdir ~/langchain-critique-demo
cd ~/langchain-critique-demo

# 4. åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
python3 -m venv venv

# 5. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# æ¿€æ´»åï¼Œä½ çš„ç»ˆç«¯æç¤ºç¬¦å‰é¢ä¼šå‡ºç° (venv)
```

### æ­¥éª¤2: å®‰è£…ä¾èµ–

```bash
# å®‰è£…OpenAIå®˜æ–¹åº“
pip install openai==0.28.1

# å®‰è£…LangChainç›¸å…³åº“
pip install langchain==0.0.350
pip install langchain-openai==0.0.2

# å¦‚æœè¦è¿è¡ŒAgentæ¼”ç¤ºï¼Œè¿˜éœ€è¦å®‰è£…ï¼ˆå¯é€‰ï¼‰
pip install google-search-results  # SerpAPIçš„Pythonåº“

# éªŒè¯å®‰è£…
pip list | grep -E "openai|langchain"
```

### æ­¥éª¤3: é…ç½®APIå¯†é’¥

```bash
# è®¾ç½®OpenAI APIå¯†é’¥ï¼ˆå¿…éœ€ï¼‰
export OPENAI_API_KEY='your-openai-api-key-here'

# è®¾ç½®SerpAPIå¯†é’¥ï¼ˆå¯é€‰ï¼Œä»…Agentæ¼”ç¤ºéœ€è¦ï¼‰
# å¯ä»¥ä» https://serpapi.com æ³¨å†Œè·å–å…è´¹å¯†é’¥
export SERPAPI_API_KEY='your-serpapi-key-here'

# éªŒè¯ç¯å¢ƒå˜é‡
echo $OPENAI_API_KEY
```

**æ°¸ä¹…è®¾ç½®ï¼ˆå¯é€‰ï¼‰ï¼š**

```bash
# å°†APIå¯†é’¥æ·»åŠ åˆ° ~/.zshrc æ–‡ä»¶
echo 'export OPENAI_API_KEY="your-openai-api-key-here"' >> ~/.zshrc
echo 'export SERPAPI_API_KEY="your-serpapi-key-here"' >> ~/.zshrc

# é‡æ–°åŠ è½½é…ç½®
source ~/.zshrc
```

### æ­¥éª¤4: ä¸‹è½½è„šæœ¬æ–‡ä»¶

å°†ä»¥ä¸‹ä¸¤ä¸ªæ–‡ä»¶ä¿å­˜åˆ° `~/langchain-critique-demo/` ç›®å½•ï¼š
- `langchain_critique_demo.py`
- `langchain_agent_performance_demo.py`

```bash
# ç¡®ä¿æ–‡ä»¶å…·æœ‰æ‰§è¡Œæƒé™
chmod +x langchain_critique_demo.py
chmod +x langchain_agent_performance_demo.py
```

### æ­¥éª¤5: è¿è¡Œæ¼”ç¤º

#### è¿è¡Œä¸»æ¼”ç¤ºï¼ˆç¼ºç‚¹1-3ï¼‰

```bash
# ç¡®ä¿è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»
source venv/bin/activate

# è¿è¡Œä¸»æ¼”ç¤ºè„šæœ¬
python3 langchain_critique_demo.py
```

**é¢„æœŸè¾“å‡ºï¼š**
- ä½ ä¼šçœ‹åˆ°æ¯ä¸ªç¼ºç‚¹çš„è¯¦ç»†å¯¹æ¯”
- LangChainæ–¹å¼ vs OpenAIå®˜æ–¹åº“æ–¹å¼
- å®é™…è¿è¡Œç»“æœå’Œè€—æ—¶
- è¯¦ç»†çš„åˆ†æè¯´æ˜

#### è¿è¡ŒAgentæ€§èƒ½æ¼”ç¤ºï¼ˆç¼ºç‚¹4-5ï¼‰

```bash
# è¿è¡ŒAgentæ¼”ç¤ºè„šæœ¬ï¼ˆéœ€è¦SERPAPI_API_KEYï¼‰
python3 langchain_agent_performance_demo.py
```

**é¢„æœŸè¾“å‡ºï¼š**
- Agentçš„è¯¦ç»†æ‰§è¡Œè¿‡ç¨‹ï¼ˆverbose=Trueï¼‰
- æ¯ä¸ªThought/Action/Observationæ­¥éª¤
- æ€»è€—æ—¶å’ŒAPIè°ƒç”¨æ¬¡æ•°åˆ†æ

## ğŸ“ è¿è¡Œç¤ºä¾‹æˆªå›¾

### ä¸»æ¼”ç¤ºè¾“å‡ºç¤ºä¾‹

```
================================================================================
LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º
================================================================================

ğŸ“Œ ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿
--------------------------------------------------------------------------------

ğŸ”´ LangChainæ–¹å¼ (ä½¿ç”¨å¤šä¸ªå¯¹è±¡ç±»):
ä»£ç :
...
æ‰§è¡Œç»“æœ:
âœ… J'adore la programmation.
â±ï¸  è€—æ—¶: 1.23ç§’

================================================================================

ğŸŸ¢ OpenAIå®˜æ–¹åº“æ–¹å¼ (ç®€æ´ç›´æ¥):
ä»£ç :
...
æ‰§è¡Œç»“æœ:
âœ… J'adore la programmation.
â±ï¸  è€—æ—¶: 1.18ç§’

ğŸ’¡ åˆ†æ: ä¸¤ç§æ–¹å¼ä»£ç é‡ç›¸å½“ï¼Œä½†LangChainå¼•å…¥äº†é¢å¤–çš„å¯¹è±¡ç±»ï¼Œå¢åŠ äº†å¤æ‚åº¦
```

## âš ï¸ å¸¸è§é—®é¢˜

### é—®é¢˜1: ImportError: cannot import name 'ChatOpenAI'

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# LangChainæœ€è¿‘ç‰ˆæœ¬ç»“æ„æœ‰å˜åŒ–ï¼Œéœ€è¦ä»langchain-openaiå¯¼å…¥
pip install langchain-openai
```

å¦‚æœè¿˜æ˜¯æœ‰é—®é¢˜ï¼Œä¿®æ”¹å¯¼å…¥ï¼š
```python
# æ—§ç‰ˆæœ¬
from langchain.chat_models import ChatOpenAI

# æ–°ç‰ˆæœ¬
from langchain_openai import ChatOpenAI
```

### é—®é¢˜2: openai.error.RateLimitError

**è§£å†³æ–¹æ¡ˆï¼š**
- æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
- æ£€æŸ¥è´¦æˆ·ä½™é¢
- æ·»åŠ å»¶æ—¶æˆ–é‡è¯•æœºåˆ¶

### é—®é¢˜3: SSLè¯ä¹¦é”™è¯¯

**è§£å†³æ–¹æ¡ˆï¼š**
```bash
# æ›´æ–°è¯ä¹¦
pip install --upgrade certifi

# æˆ–è€…ä½¿ç”¨ä»£ç†
export https_proxy=http://127.0.0.1:7890
```

### é—®é¢˜4: Agentæ¼”ç¤ºæ— æ³•è¿è¡Œ

**åŸå› ï¼š** ç¼ºå°‘SERPAPI_API_KEY

**è§£å†³æ–¹æ¡ˆï¼š**
1. è®¿é—® https://serpapi.com æ³¨å†Œè´¦å·
2. è·å–å…è´¹APIå¯†é’¥ï¼ˆæ¯æœˆ100æ¬¡å…è´¹æŸ¥è¯¢ï¼‰
3. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š`export SERPAPI_API_KEY='your-key'`

## ğŸ¯ å­¦ä¹ è¦ç‚¹

é€šè¿‡è¿™äº›æ¼”ç¤ºï¼Œä½ å°†ç†è§£ï¼š

1. **æŠ½è±¡çš„ä»£ä»·**
   - LangChainå¼•å…¥çš„æŠ½è±¡å±‚å¹¶ä¸æ€»æ˜¯å¸¦æ¥ä»·å€¼
   - æœ‰æ—¶ç®€å•çš„åŸç”ŸPythonä»£ç æ›´æ¸…æ™°

2. **é€æ˜åº¦çš„é‡è¦æ€§**
   - Agentæ¯æ­¥éƒ½è°ƒç”¨APIè¿™ä¸ªå…³é”®ä¿¡æ¯åº”è¯¥æ˜ç¡®å‘ŠçŸ¥
   - éšè—çš„æ€§èƒ½ç‰¹å¾ä¼šå¯¼è‡´æ„å¤–æˆæœ¬

3. **é€‰æ‹©å·¥å…·çš„åŸåˆ™**
   - è¯„ä¼°åº“æ˜¯å¦è§£å†³å®é™…é—®é¢˜
   - é¿å…"ä¸ºäº†ç”¨è€Œç”¨"

4. **Hello Worldçš„é‡è¦æ€§**
   - å¦‚æœHello Worldéƒ½å¾ˆå¤æ‚ï¼Œå®é™…ä½¿ç”¨ä¼šæ›´ç—›è‹¦
   - å¥½çš„åº“åº”è¯¥é™ä½è€Œéæé«˜å­¦ä¹ æ›²çº¿

## ğŸ“š ç›¸å…³èµ„æº

- [OpenAIå®˜æ–¹æ–‡æ¡£](https://platform.openai.com/docs)
- [LangChainå®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/get_started/introduction)
- [åŸæ–‡ç« è®¨è®º](https://news.ycombinator.com/item?id=36645575)

## ğŸ”§ è°ƒè¯•æŠ€å·§

### æ‰“å°è¯¦ç»†æ—¥å¿—

```bash
# å¯ç”¨LangChainçš„è¯¦ç»†æ—¥å¿—
export LANGCHAIN_VERBOSE=true
python3 langchain_critique_demo.py
```

### ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹æµ‹è¯•

ä¿®æ”¹è„šæœ¬ä¸­çš„æ¨¡å‹ï¼š
```python
# ä» gpt-4 æ”¹ä¸º gpt-3.5-turbo
model="gpt-3.5-turbo"
```

### ç›‘æ§APIè°ƒç”¨æ¬¡æ•°

```python
# åœ¨è„šæœ¬ä¸­æ·»åŠ è®¡æ•°å™¨
api_call_count = 0

# åœ¨æ¯æ¬¡APIè°ƒç”¨å
api_call_count += 1
print(f"APIè°ƒç”¨æ¬¡æ•°: {api_call_count}")
```

## ğŸ“ å»¶ä¼¸å­¦ä¹ 

å®Œæˆè¿™äº›æ¼”ç¤ºåï¼Œå»ºè®®å°è¯•ï¼š

1. ç”¨OpenAIå®˜æ–¹åº“å®ç°ä¸€ä¸ªç®€å•çš„Agent
2. å¯¹æ¯”ä¸åŒæ¨¡å‹ï¼ˆGPT-3.5 vs GPT-4ï¼‰çš„æ€§èƒ½
3. æµ‹è¯•ä¸åŒpromptç­–ç•¥çš„æ•ˆæœ
4. è¯„ä¼°å…¶ä»–AIæ¡†æ¶ï¼ˆå¦‚LlamaIndexã€Haystackï¼‰

## ğŸ“ é—®é¢˜åé¦ˆ

å¦‚æœé‡åˆ°ä»»ä½•é—®é¢˜ï¼š
1. æ£€æŸ¥Pythonå’Œä¾èµ–ç‰ˆæœ¬
2. éªŒè¯APIå¯†é’¥æ˜¯å¦æ­£ç¡®
3. æŸ¥çœ‹å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯
4. å‚è€ƒå¸¸è§é—®é¢˜éƒ¨åˆ†

---

**ç¥ä½ å­¦ä¹ æ„‰å¿«ï¼ğŸš€**

```

### quickstart_1.sh

```python
#!/bin/bash
# LangChainæ‰¹è¯„æ¼”ç¤º - å¿«é€Ÿå¯åŠ¨è„šæœ¬
# é€‚ç”¨äºmacOS iTerm2/zshç¯å¢ƒ

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

echo "=================================="
echo "LangChainæ‰¹è¯„æ¼”ç¤º - å¿«é€Ÿå¯åŠ¨å‘å¯¼"
echo "=================================="
echo ""

# æ£€æŸ¥Python
echo "ğŸ“ æ­¥éª¤1: æ£€æŸ¥Pythonç¯å¢ƒ..."
if command -v python3 &> /dev/null; then
    PYTHON_VERSION=$(python3 --version)
    echo "âœ… æ‰¾åˆ°Python: $PYTHON_VERSION"
else
    echo "âŒ æœªæ‰¾åˆ°Python3ï¼Œè¯·å…ˆå®‰è£…Python 3.8+"
    exit 1
fi

# æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
echo ""
echo "ğŸ“ æ­¥éª¤2: è®¾ç½®è™šæ‹Ÿç¯å¢ƒ..."
if [ ! -d "venv" ]; then
    echo "åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ..."
    python3 -m venv venv
    echo "âœ… è™šæ‹Ÿç¯å¢ƒåˆ›å»ºæˆåŠŸ"
else
    echo "âœ… è™šæ‹Ÿç¯å¢ƒå·²å­˜åœ¨"
fi

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
echo "æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ..."
source venv/bin/activate
echo "âœ… è™šæ‹Ÿç¯å¢ƒå·²æ¿€æ´»"

# å®‰è£…ä¾èµ–
echo ""
echo "ğŸ“ æ­¥éª¤3: å®‰è£…ä¾èµ–åŒ…..."
echo "æ­£åœ¨å®‰è£…OpenAIåº“..."
pip install -q openai==0.28.1

echo "æ­£åœ¨å®‰è£…LangChain..."
pip install -q langchain==0.0.350 langchain-openai==0.0.2

echo "æ­£åœ¨å®‰è£…SerpAPIï¼ˆAgentæ¼”ç¤ºéœ€è¦ï¼‰..."
pip install -q google-search-results

echo "âœ… ä¾èµ–å®‰è£…å®Œæˆ"

# æ£€æŸ¥APIå¯†é’¥
echo ""
echo "ğŸ“ æ­¥éª¤4: æ£€æŸ¥APIå¯†é’¥..."

if [ -z "$OPENAI_API_KEY" ]; then
    echo "âš ï¸  æœªæ£€æµ‹åˆ°OPENAI_API_KEYç¯å¢ƒå˜é‡"
    echo ""
    echo "è¯·è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥ï¼ˆå¯ä»¥ä» https://platform.openai.com/api-keys è·å–ï¼‰ï¼š"
    read -s OPENAI_API_KEY
    export OPENAI_API_KEY
    echo ""
    echo "âœ… APIå¯†é’¥å·²è®¾ç½®ï¼ˆå½“å‰ä¼šè¯æœ‰æ•ˆï¼‰"
    echo ""
    echo "ğŸ’¡ æç¤ºï¼šå¦‚æœæƒ³æ°¸ä¹…ä¿å­˜ï¼Œè¯·è¿è¡Œï¼š"
    echo "   echo 'export OPENAI_API_KEY=\"$OPENAI_API_KEY\"' >> ~/.zshrc"
else
    echo "âœ… æ£€æµ‹åˆ°OPENAI_API_KEY"
fi

if [ -z "$SERPAPI_API_KEY" ]; then
    echo "âš ï¸  æœªæ£€æµ‹åˆ°SERPAPI_API_KEYï¼ˆAgentæ¼”ç¤ºéœ€è¦ï¼‰"
    echo ""
    echo "æ˜¯å¦ç°åœ¨è®¾ç½®SERPAPI_API_KEYï¼Ÿ(y/n)"
    echo "ï¼ˆå¯ä»¥ä» https://serpapi.com æ³¨å†Œè·å–å…è´¹å¯†é’¥ï¼Œè·³è¿‡åˆ™æ— æ³•è¿è¡ŒAgentæ¼”ç¤ºï¼‰"
    read -r answer
    if [ "$answer" = "y" ] || [ "$answer" = "Y" ]; then
        echo "è¯·è¾“å…¥ä½ çš„SerpAPIå¯†é’¥ï¼š"
        read -s SERPAPI_API_KEY
        export SERPAPI_API_KEY
        echo ""
        echo "âœ… SerpAPIå¯†é’¥å·²è®¾ç½®"
    else
        echo "â­ï¸  è·³è¿‡SerpAPIè®¾ç½®ï¼ˆAgentæ¼”ç¤ºå°†æ— æ³•è¿è¡Œï¼‰"
    fi
else
    echo "âœ… æ£€æµ‹åˆ°SERPAPI_API_KEY"
fi

# æ˜¾ç¤ºèœå•
echo ""
echo "=================================="
echo "ğŸ¯ å‡†å¤‡å®Œæˆï¼è¯·é€‰æ‹©è¦è¿è¡Œçš„æ¼”ç¤ºï¼š"
echo "=================================="
echo ""
echo "1. è¿è¡Œä¸»æ¼”ç¤º - ç¼ºç‚¹1-3å¯¹æ¯”"
echo "   ï¼ˆè¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ã€Promptæ¨¡æ¿å¤æ‚ã€å¯¹è¯è®°å¿†å¤æ‚ï¼‰"
echo ""
echo "2. è¿è¡ŒAgentæ¼”ç¤º - ç¼ºç‚¹4-5å¯¹æ¯”"
echo "   ï¼ˆAgentæ€§èƒ½é—®é¢˜ã€å®ç°ä¸é€æ˜ï¼‰"
echo ""
echo "3. è¿è¡Œå…¨éƒ¨æ¼”ç¤º"
echo ""
echo "4. é€€å‡º"
echo ""
echo -n "è¯·è¾“å…¥é€‰é¡¹ (1-4): "
read -r choice

case $choice in
    1)
        echo ""
        echo "ğŸš€ è¿è¡Œä¸»æ¼”ç¤º..."
        echo ""
        python3 langchain_critique_demo.py
        ;;
    2)
        echo ""
        echo "ğŸš€ è¿è¡ŒAgentæ¼”ç¤º..."
        echo ""
        python3 langchain_agent_performance_demo.py
        ;;
    3)
        echo ""
        echo "ğŸš€ è¿è¡Œå…¨éƒ¨æ¼”ç¤º..."
        echo ""
        python3 langchain_critique_demo.py
        echo ""
        echo "=================================="
        echo "æŒ‰Enterç»§ç»­è¿è¡ŒAgentæ¼”ç¤º..."
        read -r
        python3 langchain_agent_performance_demo.py
        ;;
    4)
        echo "ğŸ‘‹ å†è§ï¼"
        exit 0
        ;;
    *)
        echo "âŒ æ— æ•ˆé€‰é¡¹"
        exit 1
        ;;
esac

echo ""
echo "=================================="
echo "âœ… æ¼”ç¤ºå®Œæˆï¼"
echo "=================================="
echo ""
echo "ğŸ’¡ æç¤ºï¼š"
echo "   - è¦é‡æ–°è¿è¡Œï¼Œè¯·æ‰§è¡Œ: ./quickstart.sh"
echo "   - æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: cat README.md"
echo "   - é€€å‡ºè™šæ‹Ÿç¯å¢ƒ: deactivate"
echo ""
```

### Detailed-analysis-of-the-disadvantagesï¼š

```markdown
# LangChain Hello World ç¼ºç‚¹å…¨é¢åˆ†æ

## ğŸ“‹ æ–‡ç« ä¸­è®¨è®ºçš„æ‰€æœ‰ç¼ºç‚¹

æ ¹æ®2023å¹´çš„æ‰¹è¯„æ–‡ç« ï¼ŒLangChainçš„Hello Worldç¨‹åºå­˜åœ¨ä»¥ä¸‹å…·ä½“ç¼ºç‚¹ï¼š

---

## ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿

### é—®é¢˜æè¿°
LangChainå¼•å…¥äº†å¤§é‡çš„å¯¹è±¡ç±»ï¼ˆ`ChatOpenAI`, `HumanMessage`, `SystemMessage`, `AIMessage`ç­‰ï¼‰ï¼Œä½†å®ç°çš„åŠŸèƒ½ä¸ç›´æ¥ä½¿ç”¨OpenAIå®˜æ–¹åº“ç›¸æ¯”ï¼Œä»£ç é‡ç›¸å½“ï¼Œæ²¡æœ‰å¸¦æ¥æ˜æ˜¾çš„å¥½å¤„ã€‚

### LangChainä»£ç ç¤ºä¾‹
```python
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

chat = ChatOpenAI(temperature=0)
result = chat.predict_messages([
    HumanMessage(content="Translate this sentence from English to French. I love programming.")
])
# AIMessage(content="J'adore la programmation.", additional_kwargs={}, example=False)
```

**ä»£ç è¡Œæ•°**: 5è¡Œï¼ˆä¸å«å¯¼å…¥ï¼‰

### OpenAIå®˜æ–¹åº“å¯¹æ¯”
```python
import openai

messages = [{
    "role": "user", 
    "content": "Translate this sentence from English to French. I love programming."
}]
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo", 
    messages=messages, 
    temperature=0
)
print(response["choices"][0]["message"]["content"])
# "J'adore la programmation."
```

**ä»£ç è¡Œæ•°**: 5è¡Œï¼ˆä¸å«å¯¼å…¥ï¼‰

### åˆ†æ
- âŒ LangChainå¼•å…¥äº†é¢å¤–çš„ç±»æŠ½è±¡ä½†æ²¡æœ‰å‡å°‘ä»£ç é‡
- âŒ è¿”å›çš„`AIMessage`å¯¹è±¡åè€Œå¢åŠ äº†ä½¿ç”¨å¤æ‚åº¦
- âœ… OpenAIå®˜æ–¹åº“ä½¿ç”¨ç®€å•çš„å­—å…¸å’Œå­—ç¬¦ä¸²ï¼Œæ›´ç›´è§‚

---

## ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚ï¼ˆå®é™…åªæ˜¯f-stringsçš„åŒ…è£…ï¼‰

### é—®é¢˜æè¿°
LangChainçš„"vaunted prompt engineering"ï¼ˆè‡ªè±ªçš„æç¤ºè¯å·¥ç¨‹ï¼‰å®é™…ä¸Šåªæ˜¯Python f-stringsçš„åŒ…è£…ï¼Œä½†å¼•å…¥äº†`ChatPromptTemplate`, `SystemMessagePromptTemplate`, `HumanMessagePromptTemplate`ç­‰å¤šä¸ªæ¨¡æ¿ç±»ï¼Œå¢åŠ äº†ä¸å¿…è¦çš„å¤æ‚åº¦ã€‚

ä½œè€…è´¨é—®ï¼š"Why do we need to use these `PromptTemplates` to do the same thing?"

### LangChainä»£ç ç¤ºä¾‹
```python
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

# åˆ›å»ºç³»ç»Ÿæ¶ˆæ¯æ¨¡æ¿
template = "You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)

# åˆ›å»ºç”¨æˆ·æ¶ˆæ¯æ¨¡æ¿
human_template = "{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

# ç»„åˆæ¨¡æ¿
chat_prompt = ChatPromptTemplate.from_messages([
    system_message_prompt, 
    human_message_prompt
])

# æ ¼å¼åŒ–æ¶ˆæ¯
messages = chat_prompt.format_messages(
    input_language="English", 
    output_language="French", 
    text="I love programming."
)
```

**ä»£ç è¡Œæ•°**: 12è¡Œï¼ˆä¸å«å¯¼å…¥ï¼‰

### PythonåŸç”Ÿf-stringså¯¹æ¯”
```python
# å®šä¹‰å˜é‡
input_language = "English"
output_language = "French"
text = "I love programming."

# ä½¿ç”¨f-stringsæ„é€ æ¶ˆæ¯
system_content = f"You are a helpful assistant that translates {input_language} to {output_language}."
human_content = f"{text}"

# æ„é€ æ¶ˆæ¯åˆ—è¡¨
messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": human_content}
]
```

**ä»£ç è¡Œæ•°**: 7è¡Œ

### åˆ†æ
- âŒ LangChainå¼•å…¥äº†3ä¸ªé¢å¤–çš„æ¨¡æ¿ç±»
- âŒ éœ€è¦ç†è§£`from_template()`, `from_messages()`, `format_messages()`ç­‰å¤šä¸ªæ–¹æ³•
- âŒ ä»£ç é‡æ›´å¤šï¼Œä½†åŠŸèƒ½å®Œå…¨ç›¸åŒ
- âœ… f-stringsæ˜¯Pythonå†…ç½®ç‰¹æ€§ï¼Œæ‰€æœ‰å¼€å‘è€…éƒ½ç†Ÿæ‚‰
- âœ… åŸç”Ÿæ–¹å¼ä»£ç æ›´å°‘ï¼Œé€»è¾‘æ›´æ¸…æ™°

---

## ç¼ºç‚¹3: Agentå®ç°ä¸é€æ˜ï¼Œæ¦‚å¿µæ™¦æ¶©

### é—®é¢˜æè¿°
æ–‡ç« æŒ‡å‡ºAgentç¤ºä¾‹ä»£ç å­˜åœ¨å¤šä¸ªé—®é¢˜ï¼š
1. "How do the individual tools work?"ï¼ˆå•ä¸ªå·¥å…·å¦‚ä½•å·¥ä½œï¼Ÿï¼‰
2. "What is `AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION` anyways?"ï¼ˆè¿™åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿï¼‰
3. éœ€è¦è®¾ç½®`verbose=True`æ‰èƒ½çœ‹åˆ°æ‰§è¡Œè¿‡ç¨‹
4. "why is each action a `dict`?"ï¼ˆä¸ºä»€ä¹ˆæ¯ä¸ªactionæ˜¯å­—å…¸ï¼Ÿï¼‰ä½œè€…è¯´ç­”æ¡ˆ"very silly"

### LangChainä»£ç ç¤ºä¾‹
```python
from langchain.agents import load_tools, initialize_agent, AgentType
from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI

# åŠ è½½è¯­è¨€æ¨¡å‹
chat = ChatOpenAI(temperature=0)

# åŠ è½½å·¥å…·ï¼ˆéœ€è¦å¦ä¸€ä¸ªLLMå®ä¾‹ï¼Ÿï¼‰
llm = OpenAI(temperature=0)
tools = load_tools(["serpapi", "llm-math"], llm=llm)

# åˆå§‹åŒ–agent
agent = initialize_agent(
    tools, 
    chat, 
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,  # è¿™æ˜¯ä»€ä¹ˆï¼Ÿ
    verbose=True  # ä¸è®¾ç½®å°±çœ‹ä¸åˆ°æ‰§è¡Œè¿‡ç¨‹
)

# è¿è¡Œ
result = agent.run("Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?")
```

### é—®é¢˜åˆ—è¡¨
1. **ä¸é€æ˜æ€§**: ä¸æ¸…æ¥šå·¥å…·å¦‚ä½•è¢«è°ƒç”¨
2. **æ™¦æ¶©å‘½å**: `AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION`éš¾ä»¥ç†è§£
3. **ä¾èµ–verbose**: å¿…é¡»è®¾ç½®`verbose=True`æ‰èƒ½çœ‹åˆ°æ‰§è¡Œç»†èŠ‚
4. **ä¸å¿…è¦çš„æŠ½è±¡**: ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªLLMå®ä¾‹ï¼ˆchatå’Œllmï¼‰ï¼Ÿ
5. **dictæ ¼å¼**: Actionä¸ºä½•æ˜¯å­—å…¸æ ¼å¼ï¼Ÿæ–‡æ¡£æœªè§£é‡Š

### è¾“å‡ºç¤ºä¾‹åˆ†æ
```bash
> Entering new AgentExecutor chain...
Thought: I need to use a search engine...
Action:
{
    "action": "Search",           # ä¸ºä»€ä¹ˆæ˜¯dictï¼Ÿ
    "action_input": "Olivia Wilde boyfriend"
}
Observation: ...Harry Styles...
Thought: I need to find Harry Styles' age...
Action:
{
    "action": "Search",
    "action_input": "Harry Styles age"
}
Observation: 29 years
Thought: Now I need to calculate...
Action:
{
    "action": "Calculator",
    "action_input": "29^0.23"
}
Observation: Answer: 2.169459462491557
Thought: I now know the final answer.
Final Answer: 2.169459462491557
```

### åˆ†æ
- âŒ å·¥å…·è°ƒç”¨æœºåˆ¶ä¸æ¸…æ™°
- âŒ å‘½åçº¦å®šæ™¦æ¶©éš¾æ‡‚
- âŒ éœ€è¦æ·±å…¥æ–‡æ¡£æ‰èƒ½ç†è§£è¿è¡Œæœºåˆ¶
- âœ… å¦‚æœç”¨OpenAIå®˜æ–¹åº“ï¼Œå¼€å‘è€…å®Œå…¨æŒæ§æ¯ä¸ªæ­¥éª¤

---

## ç¼ºç‚¹4: æ€§èƒ½é—®é¢˜è¢«éšè—ï¼ˆæ¯æ­¥éƒ½è°ƒç”¨APIï¼‰

### é—®é¢˜æè¿°
**è¿™æ˜¯ä¸€ä¸ªå…³é”®ä½†è¢«éšè—çš„é—®é¢˜**ï¼šæ–‡ç« æŒ‡å‡º"The documentation doesn't make it clear, but within each Thought/Action/Observation uses its own API call to OpenAI"

è¿™æ„å‘³ç€ï¼š
- æ¯ä¸ªThought/Action/Observationå¾ªç¯éƒ½ä¼šå•ç‹¬è°ƒç”¨OpenAI API
- ä¸€ä¸ªç®€å•æŸ¥è¯¢å¯èƒ½äº§ç”Ÿ3-5æ¬¡APIè°ƒç”¨
- **æ–‡æ¡£ä¸­æ²¡æœ‰æ˜ç¡®è¯´æ˜è¿™ä¸€ç‚¹**
- ç”¨æˆ·å¯èƒ½æƒŠè®¶äºé«˜æ˜‚çš„APIè´¹ç”¨å’Œç¼“æ…¢çš„å“åº”æ—¶é—´

### å®é™…APIè°ƒç”¨åˆ†æ

å¯¹äºè¿™ä¸ªæŸ¥è¯¢ï¼š"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?"

Agentä¼šè¿›è¡Œè‡³å°‘4æ¬¡APIè°ƒç”¨ï¼š

```
ç¬¬1æ¬¡ APIè°ƒç”¨:
è¾“å…¥: "Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?"
è¾“å‡º: {"action": "Search", "action_input": "Olivia Wilde boyfriend"}

ç¬¬2æ¬¡ APIè°ƒç”¨:
è¾“å…¥: [å¯¹è¯å†å² + æœç´¢ç»“æœ: "Harry Styles"]
è¾“å‡º: {"action": "Search", "action_input": "Harry Styles age"}

ç¬¬3æ¬¡ APIè°ƒç”¨:
è¾“å…¥: [å¯¹è¯å†å² + å¹´é¾„ç»“æœ: "29 years"]
è¾“å‡º: {"action": "Calculator", "action_input": "29^0.23"}

ç¬¬4æ¬¡ APIè°ƒç”¨:
è¾“å…¥: [å¯¹è¯å†å² + è®¡ç®—ç»“æœ: "2.169459462491557"]
è¾“å‡º: "Final Answer: 2.169459462491557"
```

### æ€§èƒ½å½±å“
```
å•æ¬¡APIè°ƒç”¨å¹³å‡è€—æ—¶: ~1ç§’
Agentæ€»è€—æ—¶: 4-5ç§’

APIæˆæœ¬ï¼ˆå‡è®¾ä½¿ç”¨GPT-4ï¼‰:
- å•æ¬¡æŸ¥è¯¢: ~$0.01
- AgentæŸ¥è¯¢: ~$0.04-0.05ï¼ˆ4-5å€ï¼‰
```

### åˆ†æ
- âŒ **é€æ˜åº¦é—®é¢˜**: æ–‡æ¡£æœªæ˜ç¡®è¯´æ˜è¿™ä¸ªé‡è¦çš„æ€§èƒ½ç‰¹å¾
- âŒ **æˆæœ¬æ„å¤–**: ç”¨æˆ·å¯èƒ½æƒŠè®¶äºé«˜æ˜‚çš„APIè´¹ç”¨
- âŒ **å»¶è¿Ÿé—®é¢˜**: å“åº”æ—¶é—´æ¯”é¢„æœŸé•¿å¾ˆå¤š
- âœ… å¦‚æœç”¨OpenAIå®˜æ–¹åº“ï¼Œå¼€å‘è€…æ¸…æ¥šçŸ¥é“æ¯æ¬¡è°ƒç”¨çš„æ—¶æœº

---

## ç¼ºç‚¹5: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚

### é—®é¢˜æè¿°
ä½œè€…è¡¨ç¤ºï¼š"I'm not entirely sure why any of this is necessary."ï¼ˆæˆ‘å®Œå…¨ä¸ç¡®å®šä¸ºä»€ä¹ˆéœ€è¦è¿™äº›ï¼‰

å…·ä½“é—®é¢˜ï¼š
- "What's a `MessagesPlaceholder`?"ï¼ˆMessagesPlaceholderæ˜¯ä»€ä¹ˆï¼Ÿï¼‰
- "Where's the `history`?"ï¼ˆhistoryåœ¨å“ªé‡Œï¼Ÿï¼‰
- "Is that necessary for `ConversationBufferMemory`?"ï¼ˆConversationBufferMemoryçœŸçš„éœ€è¦å—ï¼Ÿï¼‰

### LangChainä»£ç ç¤ºä¾‹
```python
from langchain.prompts import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate
)
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

# åˆ›å»ºå¤æ‚çš„æç¤ºæ¨¡æ¿
prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(
        "The following is a friendly conversation between a human and an AI. "
        "The AI is talkative and provides lots of specific details from its context. "
        "If the AI does not know the answer to a question, it truthfully says it does not know."
    ),
    MessagesPlaceholder(variable_name="history"),  # historyåœ¨å“ªé‡Œï¼Ÿ
    HumanMessagePromptTemplate.from_template("{input}")
])

# åˆ›å»ºLLMå’Œè®°å¿†å¯¹è±¡
llm = ChatOpenAI(temperature=0)
memory = ConversationBufferMemory(return_messages=True)

# åˆ›å»ºå¯¹è¯é“¾
conversation = ConversationChain(memory=memory, prompt=prompt, llm=llm)

# ä½¿ç”¨
response = conversation.predict(input="Hi there!")
# 'Hello! How can I assist you today?'
```

**ä»£ç è¡Œæ•°**: 13è¡Œï¼ˆä¸å«å¯¼å…¥ï¼‰
**å¼•å…¥çš„æ¦‚å¿µ**: 6ä¸ªï¼ˆChatPromptTemplate, MessagesPlaceholder, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ConversationChain, ConversationBufferMemoryï¼‰

### OpenAIå®˜æ–¹åº“å¯¹æ¯”
```python
import openai

# åˆå§‹åŒ–æ¶ˆæ¯å†å²
messages = [{
    "role": "system", 
    "content": 
        "The following is a friendly conversation between a human and an AI. "
        "The AI is talkative and provides lots of specific details from its context. "
        "If the AI does not know the answer to a question, it truthfully says it does not know."
}]

# ç¬¬ä¸€è½®å¯¹è¯
user_message = "Hi there!"
messages.append({"role": "user", "content": user_message})

response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo", 
    messages=messages, 
    temperature=0
)

assistant_message = response["choices"][0]["message"]["content"]
messages.append({"role": "assistant", "content": assistant_message})
print(assistant_message)
# 'Hello! How can I assist you today?'

# ç»§ç»­å¯¹è¯ - åªéœ€è¦ç»§ç»­appendåˆ°messagesåˆ—è¡¨
user_message2 = "What's 2+2?"
messages.append({"role": "user", "content": user_message2})
response2 = openai.ChatCompletion.create(
    model="gpt-3.5-turbo", 
    messages=messages, 
    temperature=0
)
# ...
```

**ä»£ç è¡Œæ•°**: 11è¡Œï¼ˆä¸å«å¯¼å…¥ï¼‰
**å¼•å…¥çš„æ¦‚å¿µ**: 0ä¸ªï¼ˆåªç”¨æ ‡å‡†Pythonæ•°æ®ç»“æ„ï¼‰

### åˆ†æ
- âŒ LangChainå¼•å…¥äº†6ä¸ªæ–°æ¦‚å¿µï¼Œå­¦ä¹ æ›²çº¿é™¡å³­
- âŒ `MessagesPlaceholder`çš„ä½œç”¨ä¸æ¸…æ™°
- âŒ `history`çš„å­˜å‚¨ä½ç½®å’Œç®¡ç†æ–¹å¼ä¸é€æ˜
- âŒ `ConversationBufferMemory`çš„å¿…è¦æ€§å­˜ç–‘
- âœ… OpenAIå®˜æ–¹åº“ä»£ç æ›´ç®€æ´ï¼Œé€»è¾‘æ›´æ¸…æ™°
- âœ… ä½¿ç”¨æ ‡å‡†Pythonåˆ—è¡¨ï¼Œä¸€ç›®äº†ç„¶åœ°çœ‹åˆ°æ¶ˆæ¯å¦‚ä½•ä¿å­˜
- âœ… æ²¡æœ‰éšè—çš„çŠ¶æ€ç®¡ç†ï¼Œå®Œå…¨é€æ˜

---

## ç¼ºç‚¹6: æ›´å¤šé›¶æ•£çš„è®¾è®¡é—®é¢˜

### 1. Actionä¸ºä½•æ˜¯dictæ ¼å¼ï¼Ÿ
æ–‡ç« æåˆ°ï¼š"Also, why is each action a `dict`? The answer to *that* is later, and is very silly."

è™½ç„¶æ–‡ç« æ²¡æœ‰è¯¦ç»†è§£é‡Šï¼Œä½†æš—ç¤ºè¿™æ˜¯ä¸€ä¸ªä¸åˆç†çš„è®¾è®¡å†³ç­–ã€‚

### 2. éœ€è¦ä¸¤ä¸ªLLMå®ä¾‹
```python
chat = ChatOpenAI(temperature=0)  # ä¸ºAgent
llm = OpenAI(temperature=0)       # ä¸ºllm-mathå·¥å…·
```
ä¸ºä»€ä¹ˆéœ€è¦ä¸¤ä¸ªä¸åŒçš„LLMå®ä¾‹ï¼Ÿè¿™å¢åŠ äº†å›°æƒ‘ã€‚

### 3. è¿‡åº¦ä¾èµ–verbose
```python
agent = initialize_agent(..., verbose=True)
```
é»˜è®¤æƒ…å†µä¸‹çœ‹ä¸åˆ°æ‰§è¡Œè¿‡ç¨‹ï¼Œå¿…é¡»è®¾ç½®`verbose=True`æ‰èƒ½ç†è§£Agentåœ¨åšä»€ä¹ˆã€‚

---

## ğŸ“Š æ€»ä½“è¯„ä¼°

### LangChainçš„é—®é¢˜æ€»ç»“

| ç¼ºç‚¹ | ä¸¥é‡ç¨‹åº¦ | å½±å“ |
|------|---------|------|
| 1. è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±» | ä¸­ | å¢åŠ å­¦ä¹ æˆæœ¬ï¼Œæ— æ˜æ˜¾æ”¶ç›Š |
| 2. Promptæ¨¡æ¿å¤æ‚ | é«˜ | ç”¨å¤æ‚æ–¹å¼å®ç°ç®€å•åŠŸèƒ½ |
| 3. Agentä¸é€æ˜ | é«˜ | éš¾ä»¥ç†è§£å’Œè°ƒè¯• |
| 4. æ€§èƒ½é—®é¢˜éšè— | **æé«˜** | å¯èƒ½å¯¼è‡´æ„å¤–çš„é«˜æˆæœ¬å’Œæ…¢å“åº” |
| 5. è®°å¿†ç®¡ç†å¤æ‚ | ä¸­ | å¼•å…¥ä¸å¿…è¦çš„æ¦‚å¿µ |
| 6. å…¶ä»–è®¾è®¡é—®é¢˜ | ä½-ä¸­ | ç»†èŠ‚ä¸Šçš„ä¸åˆç† |

### æ ¸å¿ƒè®ºç‚¹

ä½œè€…çš„æ ¸å¿ƒè®ºç‚¹æ˜¯ï¼š

> "You can say that I'm nitpicking the tutorial examples, and I do agree that every open source library has something to nitpick (including my own!). But if there are more nitpicks than actual benefits from the library then it's not worth using at all, since if the *quickstart* is this complicated, how painful will it be to use LangChain in practice?"

**ç¿»è¯‘**ï¼šä½ å¯ä»¥è¯´æˆ‘åœ¨å¹æ¯›æ±‚ç–µï¼Œæˆ‘ä¹Ÿæ‰¿è®¤æ¯ä¸ªå¼€æºåº“éƒ½æœ‰å¯ä»¥æŒ‘å‰”çš„åœ°æ–¹ï¼ˆåŒ…æ‹¬æˆ‘è‡ªå·±çš„ï¼ï¼‰ã€‚ä½†æ˜¯ï¼Œ**å¦‚æœnitpicksï¼ˆé—®é¢˜ï¼‰æ¯”åº“çš„å®é™…å¥½å¤„è¿˜å¤šï¼Œé‚£è¿™ä¸ªåº“æ ¹æœ¬ä¸å€¼å¾—ä½¿ç”¨**ã€‚å› ä¸ºå¦‚æœè¿quickstartéƒ½è¿™ä¹ˆå¤æ‚ï¼Œå®é™…ä½¿ç”¨LangChainä¼šæœ‰å¤šç—›è‹¦ï¼Ÿ

### å…³é”®å¯ç¤º

1. **æŠ½è±¡ä¸æ€»æ˜¯å¥½çš„**: æœ‰æ—¶ç®€å•çš„ä»£ç æ¯”å¤æ‚çš„æŠ½è±¡æ›´å¥½
2. **é€æ˜åº¦å¾ˆé‡è¦**: éšè—æ€§èƒ½ç‰¹å¾æ˜¯ä¸¥é‡é—®é¢˜
3. **Hello Worldå¾ˆé‡è¦**: å¦‚æœå…¥é—¨ç¤ºä¾‹å°±å¾ˆå¤æ‚ï¼Œè¯´æ˜åº“æœ‰æ ¹æœ¬æ€§é—®é¢˜
4. **å­¦ä¹ æˆæœ¬ vs æ”¶ç›Š**: å¼•å…¥æ–°æ¦‚å¿µå¿…é¡»æœ‰ç›¸åº”çš„ä»·å€¼å›æŠ¥

---

## ğŸ¯ å®è·µå»ºè®®

åŸºäºè¿™äº›ç¼ºç‚¹åˆ†æï¼Œå»ºè®®ï¼š

### å¯¹äºå­¦ä¹ è€…
1. âœ… å…ˆæŒæ¡OpenAIå®˜æ–¹APIçš„åŸºç¡€ç”¨æ³•
2. âœ… ç†è§£Prompt Engineeringçš„æœ¬è´¨ï¼ˆf-strings + å¯¹è¯å†å²ï¼‰
3. âš ï¸ æ‰¹åˆ¤æ€§å­¦ä¹ LangChainï¼Œä¸è¦ç›²ç›®æ¥å—
4. âœ… åŠ¨æ‰‹å®ç°ç®€å•çš„Agentï¼Œç†è§£åº•å±‚åŸç†

### å¯¹äºå¼€å‘è€…
1. âœ… è¯„ä¼°æ˜¯å¦çœŸçš„éœ€è¦LangChain
2. âœ… å¯¹äºç®€å•åœºæ™¯ï¼Œç›´æ¥ç”¨OpenAI APIå¯èƒ½æ›´å¥½
3. âš ï¸ å¦‚æœä½¿ç”¨LangChainï¼Œè­¦æƒ•éšè—çš„APIè°ƒç”¨æ¬¡æ•°
4. âœ… ç›‘æ§APIæˆæœ¬å’Œæ€§èƒ½

### å¯¹äºæ¶æ„å¸ˆ
1. âœ… ä¼˜å…ˆé€‰æ‹©é€æ˜ã€ç®€å•çš„æ–¹æ¡ˆ
2. âœ… é¿å…è¿‡åº¦å·¥ç¨‹åŒ–
3. âœ… åœ¨é‡‡ç”¨æ¡†æ¶å‰è¿›è¡Œå……åˆ†çš„POCæµ‹è¯•
4. âœ… è€ƒè™‘å›¢é˜Ÿçš„å­¦ä¹ æˆæœ¬

---

**æ–‡æ¡£åˆ›å»ºæ—¶é—´**: 2024å¹´
**åŸºäºæ–‡ç« **: "Hello World" in LangChain (or More Accurately, "Hell World") (2023)

```