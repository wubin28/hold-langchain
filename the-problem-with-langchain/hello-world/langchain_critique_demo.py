#!/usr/bin/env python3
"""
LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º
æ¼”ç¤ºæ–‡ç« ä¸­æåˆ°çš„æ¯ä¸ªç¼ºç‚¹ï¼Œå¹¶ä¸DeepSeek APIè¿›è¡Œå¯¹æ¯”
"""

import os
import sys
import time

# æ£€æŸ¥DeepSeek APIå¯†é’¥
if not os.environ.get("DEEPSEEK_API_KEY"):
    print("âŒ é”™è¯¯ï¼šè¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡")
    print("   export DEEPSEEK_API_KEY='your-api-key-here'")
    sys.exit(1)

# è®¾ç½®ä¸ºDeepSeek API
os.environ["OPENAI_API_KEY"] = os.environ["DEEPSEEK_API_KEY"]
os.environ["OPENAI_API_BASE"] = "https://api.deepseek.com"

print("=" * 80)
print("LangChain Hello World ç¼ºç‚¹å¯¹æ¯”æ¼”ç¤º")
print("=" * 80)
print()

# ============================================================================
# ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿
# ============================================================================
print("ğŸ“Œ ç¼ºç‚¹1: è¿‡åº¦ä½¿ç”¨å¯¹è±¡ç±»ï¼Œæ— æ˜æ˜¾ä»£ç ä¼˜åŠ¿")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (ä½¿ç”¨å¤šä¸ªå¯¹è±¡ç±»):")
print("ä»£ç :")
print("""
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

chat = ChatOpenAI(temperature=0)
result = chat.invoke([HumanMessage(content="Translate: I love programming to French")])
print(result.content)
""")

try:
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    chat = ChatOpenAI(
        temperature=0,
        model="deepseek-chat"
    )
    result = chat.invoke([HumanMessage(content="Translate this sentence from English to French. I love programming.")])
    elapsed = time.time() - start
    print(f"âœ… {result.content}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")
    print("æç¤º: è¯·ç¡®ä¿å·²å®‰è£… langchain å’Œ langchain-openai")

print("\n" + "=" * 80)
print("\nğŸŸ¢ DeepSeekå®˜æ–¹åº“æ–¹å¼ (ç®€æ´ç›´æ¥):")
print("ä»£ç :")
print("""
from openai import OpenAI

client = OpenAI(
    api_key=os.environ.get("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)
messages = [{"role": "user", "content": "Translate: I love programming to French"}]
response = client.chat.completions.create(model="deepseek-chat", messages=messages, temperature=0)
print(response.choices[0].message.content)
""")

try:
    from openai import OpenAI
    
    client = OpenAI(
        api_key=os.environ.get("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com"
    )
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    messages = [{"role": "user", "content": "Translate this sentence from English to French. I love programming."}]
    response = client.chat.completions.create(model="deepseek-chat", messages=messages, temperature=0)
    elapsed = time.time() - start
    print(f"âœ… {response.choices[0].message.content}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
except Exception as e:
    print(f"âŒ DeepSeekæ‰§è¡Œå¤±è´¥: {e}")

print("\nğŸ’¡ åˆ†æ: ä¸¤ç§æ–¹å¼ä»£ç é‡ç›¸å½“ï¼Œä½†LangChainå¼•å…¥äº†é¢å¤–çš„å¯¹è±¡ç±»ï¼Œå¢åŠ äº†å¤æ‚åº¦")
print()

# ============================================================================
# ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Œ ç¼ºç‚¹2: Promptæ¨¡æ¿è¿‡äºå¤æ‚ (å®é™…ä¸Šåªæ˜¯f-stringsçš„åŒ…è£…)")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (å¤šå±‚åµŒå¥—çš„æ¨¡æ¿ç±»):")
print("ä»£ç :")
print("""
from langchain_core.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)

template = "You are a helpful assistant that translates {input_language} to {output_language}."
system_message_prompt = SystemMessagePromptTemplate.from_template(template)
human_template = "{text}"
human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)

chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
messages = chat_prompt.format_messages(
    input_language="English", 
    output_language="French", 
    text="I love programming."
)
print(messages)
""")

try:
    from langchain_core.prompts.chat import (
        ChatPromptTemplate,
        SystemMessagePromptTemplate,
        HumanMessagePromptTemplate,
    )
    
    print("\næ‰§è¡Œç»“æœ:")
    template = "You are a helpful assistant that translates {input_language} to {output_language}."
    system_message_prompt = SystemMessagePromptTemplate.from_template(template)
    human_template = "{text}"
    human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)
    
    chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])
    messages = chat_prompt.format_messages(
        input_language="English", 
        output_language="French", 
        text="I love programming."
    )
    print("âœ… ç”Ÿæˆçš„æ¶ˆæ¯:")
    for msg in messages:
        print(f"   - {type(msg).__name__}: {msg.content}")
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")

print("\n" + "=" * 80)
print("\nğŸŸ¢ PythonåŸç”Ÿf-stringsæ–¹å¼ (ç®€å•ç›´æ¥):")
print("ä»£ç :")
print("""
input_language = "English"
output_language = "French"
text = "I love programming."

system_content = f"You are a helpful assistant that translates {input_language} to {output_language}."
human_content = f"{text}"

messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": human_content}
]
print(messages)
""")

print("\næ‰§è¡Œç»“æœ:")
input_language = "English"
output_language = "French"
text = "I love programming."

system_content = f"You are a helpful assistant that translates {input_language} to {output_language}."
human_content = f"{text}"

messages = [
    {"role": "system", "content": system_content},
    {"role": "user", "content": human_content}
]
print("âœ… ç”Ÿæˆçš„æ¶ˆæ¯:")
for msg in messages:
    print(f"   - {msg['role']}: {msg['content']}")

print("\nğŸ’¡ åˆ†æ: LangChainçš„promptæ¨¡æ¿åªæ˜¯f-stringsçš„åŒ…è£…ï¼Œä½†å¢åŠ äº†3ä¸ªé¢å¤–çš„ç±»å’Œå¤šè¡Œä»£ç ")
print()

# ============================================================================
# ç¼ºç‚¹3: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Œ ç¼ºç‚¹3: å¯¹è¯è®°å¿†ç®¡ç†è¿‡äºå¤æ‚")
print("-" * 80)

print("\nğŸ”´ LangChainæ–¹å¼ (å¤šä¸ªæ¦‚å¿µ: RunnableWithMessageHistory, MessagesPlaceholderç­‰):")
print("ä»£ç :")
print("""
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_core.chat_history import InMemoryChatMessageHistory

llm = ChatOpenAI(temperature=0)
store = {}
def get_session_history(session_id):
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]

prompt = ChatPromptTemplate.from_messages([
    ("system", "The following is a friendly conversation between a human and an AI."),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

chain = prompt | llm
with_message_history = RunnableWithMessageHistory(
    chain, get_session_history, input_messages_key="input", history_messages_key="history"
)

response = with_message_history.invoke(
    {"input": "Hi there!"}, config={"configurable": {"session_id": "demo"}}
)
print(response.content)
""")

try:
    # æ³¨æ„ï¼šConversationChain å’Œ ConversationBufferMemory åœ¨LangChain 1.xä¸­å·²è¢«ç§»é™¤
    # è¿™æ­£å¥½è¯´æ˜äº†LangChain APIçš„ä¸ç¨³å®šæ€§ï¼
    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
    from langchain_core.runnables.history import RunnableWithMessageHistory
    from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    
    # ä½¿ç”¨æ–°çš„APIæ–¹å¼
    llm = ChatOpenAI(
        temperature=0,
        model="deepseek-chat",
        openai_api_key=os.environ.get("DEEPSEEK_API_KEY"),
        openai_api_base="https://api.deepseek.com"
    )
    
    # ç®€å•çš„å¯¹è¯å†å²å­˜å‚¨
    store = {}
    def get_session_history(session_id: str) -> BaseChatMessageHistory:
        if session_id not in store:
            store[session_id] = InMemoryChatMessageHistory()
        return store[session_id]
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", "The following is a friendly conversation between a human and an AI. "
                   "The AI is talkative and provides lots of specific details from its context."),
        MessagesPlaceholder(variable_name="history"),
        ("human", "{input}")
    ])
    
    chain = prompt | llm
    with_message_history = RunnableWithMessageHistory(
        chain,
        get_session_history,
        input_messages_key="input",
        history_messages_key="history",
    )
    
    response = with_message_history.invoke(
        {"input": "Hi there!"},
        config={"configurable": {"session_id": "demo"}}
    )
    elapsed = time.time() - start
    print(f"âœ… {response.content}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    # ç»§ç»­å¯¹è¯
    response2 = with_message_history.invoke(
        {"input": "What's 2+2?"},
        config={"configurable": {"session_id": "demo"}}
    )
    print(f"âœ… {response2.content}")
    
    print("\nğŸ’¡ é¢å¤–è¯´æ˜:")
    print("   æ³¨æ„ï¼šLangChain 1.xå·²ç»ç§»é™¤äº†ConversationChainå’ŒConversationBufferMemory")
    print("   éœ€è¦ä½¿ç”¨æ–°çš„RunnableWithMessageHistory APIï¼Œè¿™è¿›ä¸€æ­¥è¯æ˜äº†APIä¸ç¨³å®šçš„é—®é¢˜ï¼")
    
except Exception as e:
    print(f"âŒ LangChainæ‰§è¡Œå¤±è´¥: {e}")
    print("\nğŸ’¡ è¯´æ˜:")
    print("   LangChainçš„APIç»å¸¸å˜åŒ–ï¼ŒConversationChainåœ¨æ–°ç‰ˆæœ¬ä¸­å·²è¢«ç§»é™¤")
    print("   è¿™æ­£å¥½å°è¯äº†æ–‡ç« çš„è§‚ç‚¹ - APIä¸ç¨³å®šï¼Œå­¦ä¹ æˆæœ¬é«˜ï¼")

print("\n" + "=" * 80)
print("\nğŸŸ¢ DeepSeekå®˜æ–¹åº“æ–¹å¼ (ä½¿ç”¨ç®€å•çš„åˆ—è¡¨):")
print("ä»£ç :")
print("""
from openai import OpenAI

client = OpenAI(
    api_key=os.environ.get("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)
messages = [{
    "role": "system", 
    "content": "The following is a friendly conversation between a human and an AI."
}]

# ç¬¬ä¸€è½®å¯¹è¯
user_message = "Hi there!"
messages.append({"role": "user", "content": user_message})
response = client.chat.completions.create(model="deepseek-chat", messages=messages, temperature=0)
assistant_message = response.choices[0].message.content
messages.append({"role": "assistant", "content": assistant_message})
print(assistant_message)

# ç¬¬äºŒè½®å¯¹è¯
user_message2 = "What's 2+2?"
messages.append({"role": "user", "content": user_message2})
response2 = client.chat.completions.create(model="deepseek-chat", messages=messages, temperature=0)
assistant_message2 = response2.choices[0].message.content
messages.append({"role": "assistant", "content": assistant_message2})
print(assistant_message2)
""")

try:
    from openai import OpenAI
    
    client = OpenAI(
        api_key=os.environ.get("DEEPSEEK_API_KEY"),
        base_url="https://api.deepseek.com"
    )
    
    print("\næ‰§è¡Œç»“æœ:")
    start = time.time()
    
    messages = [{
        "role": "system", 
        "content": "The following is a friendly conversation between a human and an AI. "
                   "The AI is talkative and provides lots of specific details from its context."
    }]
    
    # ç¬¬ä¸€è½®å¯¹è¯
    user_message = "Hi there!"
    messages.append({"role": "user", "content": user_message})
    response = client.chat.completions.create(model="deepseek-chat", messages=messages, temperature=0)
    assistant_message = response.choices[0].message.content
    messages.append({"role": "assistant", "content": assistant_message})
    elapsed = time.time() - start
    print(f"âœ… {assistant_message}")
    print(f"â±ï¸  è€—æ—¶: {elapsed:.2f}ç§’")
    
    # ç¬¬äºŒè½®å¯¹è¯
    user_message2 = "What's 2+2?"
    messages.append({"role": "user", "content": user_message2})
    response2 = client.chat.completions.create(model="deepseek-chat", messages=messages, temperature=0)
    assistant_message2 = response2.choices[0].message.content
    messages.append({"role": "assistant", "content": assistant_message2})
    print(f"âœ… {assistant_message2}")
    
    print(f"\nğŸ“ å½“å‰å¯¹è¯å†å² ({len(messages)} æ¡æ¶ˆæ¯):")
    for i, msg in enumerate(messages):
        print(f"   {i+1}. [{msg['role']}] {msg['content'][:50]}...")
    
except Exception as e:
    print(f"âŒ DeepSeekæ‰§è¡Œå¤±è´¥: {e}")

print("\nğŸ’¡ åˆ†æ: DeepSeekå®˜æ–¹åº“ä»£ç æ›´å°‘ï¼Œé€»è¾‘æ›´æ¸…æ™°ï¼Œèƒ½ç›´æ¥çœ‹åˆ°æ¶ˆæ¯çš„ä¿å­˜ä½ç½®å’Œæ—¶æœº")
print("   LangChainå¼•å…¥äº†ConversationBufferMemoryã€MessagesPlaceholderç­‰æ¦‚å¿µï¼Œå¢åŠ äº†å­¦ä¹ æˆæœ¬")

# ============================================================================
# æ€»ç»“
# ============================================================================
print("\n" + "=" * 80)
print("ğŸ“Š æ€»ç»“")
print("=" * 80)
print("""
æ–‡ç« ä½œè€…çš„æ ¸å¿ƒè§‚ç‚¹:

1. âŒ LangChainå¼•å…¥äº†å¤§é‡æŠ½è±¡å±‚ï¼ˆå¯¹è±¡ç±»ã€æ¨¡æ¿ç±»ã€è®°å¿†ç±»ç­‰ï¼‰
2. âŒ è¿™äº›æŠ½è±¡æ²¡æœ‰å¸¦æ¥æ˜æ˜¾çš„ä»£ç ä¼˜åŠ¿ï¼Œåè€Œå¢åŠ äº†å¤æ‚åº¦
3. âŒ å¾ˆå¤šåŠŸèƒ½ç”¨PythonåŸç”Ÿç‰¹æ€§ï¼ˆå¦‚f-stringsï¼‰æˆ–ç›´æ¥ä½¿ç”¨APIå°±èƒ½ç®€å•å®ç°
4. âŒ æ–‡æ¡£ä¸å¤Ÿé€æ˜ï¼Œéšè—äº†é‡è¦çš„æ€§èƒ½ç»†èŠ‚ï¼ˆå¦‚Agentæ¯æ­¥éƒ½è°ƒç”¨APIï¼‰
5. âŒ å¦‚æœquickstartå°±è¿™ä¹ˆå¤æ‚ï¼Œå®é™…ä½¿ç”¨ä¼šæ›´ç—›è‹¦

ä½œè€…è®¤ä¸º: "å¦‚æœnitpicksï¼ˆå¹æ¯›æ±‚ç–µçš„é—®é¢˜ï¼‰æ¯”å®é™…å¥½å¤„è¿˜å¤šï¼Œè¿™ä¸ªåº“å°±ä¸å€¼å¾—ä½¿ç”¨"
""")

print("=" * 80)
print("æ¼”ç¤ºå®Œæˆ!")
print("=" * 80)
