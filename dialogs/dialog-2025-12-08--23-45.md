## Me:

```
è¯·é˜…è¯» @langchain_critique_demo.py å’Œ @langchain_agent_performance_demo.py ï¼Œç„¶åå†é˜…è¯»åé¢çš„langchain v1.0çš„what's newã€‚ä¹‹åè§£é‡Šæ—¢ç„¶è°ƒç”¨LLMç”¨deepseek apiæ¯”ç”¨langchainæ›´åŠ ç®€å•å’Œç›´æ¥ï¼Œé‚£ä¹ˆåœ¨langchain v1.0ä¸­ç”¨â€œllm.invoke()â€åˆ›å»ºagentçš„ä¼˜åŠ¿åœ¨å“ªé‡Œï¼Ÿè¯·ä½ å…¨é¢è§£é‡Šä½¿ç”¨langchain v1.0è¿›è¡Œagentåº”ç”¨å¼€å‘çš„ä¼˜åŠ¿ã€åŠ£åŠ¿å’Œé€‚ç”¨åœºæ™¯ã€‚ä¸‹é¢æ˜¯langchain v1.0çš„what's new:ã€# What's new in LangChain v1

**LangChain v1 is a focused, production-ready foundation for building agents.** We've streamlined the framework around three core improvements:

<CardGroup cols={1}>
  <Card title="create_agent" icon="robot" href="#create-agent" arrow>
    The new standard for building agents in LangChain, replacing `langgraph.prebuilt.create_react_agent`.
  </Card>

  <Card title="Standard content blocks" icon="cube" href="#standard-content-blocks" arrow>
    A new `content_blocks` property that provides unified access to modern LLM features across providers.
  </Card>

  <Card title="Simplified namespace" icon="sitemap" href="#simplified-package" arrow>
    The `langchain` namespace has been streamlined to focus on essential building blocks for agents, with legacy functionality moved to `langchain-classic`.
  </Card>
</CardGroup>

To upgrade,

<CodeGroup>
  ```bash pip theme={null}
  pip install -U langchain
  ```

  ```bash uv theme={null}
  uv add langchain
  ```
</CodeGroup>

For a complete list of changes, see the [migration guide](/oss/python/migrate/langchain-v1).

## `create_agent`

[`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) is the standard way to build agents in LangChain 1.0. It provides a simpler interface than [`langgraph.prebuilt.create_react_agent`](https://reference.langchain.com/python/langgraph/agents/#langgraph.prebuilt.chat_agent_executor.create_react_agent) while offering greater customization potential by using [middleware](#middleware).

```python  theme={null}
from langchain.agents import create_agent

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[search_web, analyze_data, send_email],
    system_prompt="You are a helpful research assistant."
)

result = agent.invoke({
    "messages": [
        {"role": "user", "content": "Research AI safety trends"}
    ]
})
```

Under the hood, [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) is built on the basic agent loop -- calling a model, letting it choose tools to execute, and then finishing when it calls no more tools:

<div style={{ display: "flex", justifyContent: "center" }}>
  <img src="https://mintcdn.com/langchain-5e9cc07a/Tazq8zGc0yYUYrDl/oss/images/core_agent_loop.png?fit=max&auto=format&n=Tazq8zGc0yYUYrDl&q=85&s=ac72e48317a9ced68fd1be64e89ec063" alt="Core agent loop diagram" className="rounded-lg" data-og-width="300" width="300" data-og-height="268" height="268" data-path="oss/images/core_agent_loop.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/langchain-5e9cc07a/Tazq8zGc0yYUYrDl/oss/images/core_agent_loop.png?w=280&fit=max&auto=format&n=Tazq8zGc0yYUYrDl&q=85&s=a4c4b766b6678ef52a6ed556b1a0b032 280w, https://mintcdn.com/langchain-5e9cc07a/Tazq8zGc0yYUYrDl/oss/images/core_agent_loop.png?w=560&fit=max&auto=format&n=Tazq8zGc0yYUYrDl&q=85&s=111869e6e99a52c0eff60a1ef7ddc49c 560w, https://mintcdn.com/langchain-5e9cc07a/Tazq8zGc0yYUYrDl/oss/images/core_agent_loop.png?w=840&fit=max&auto=format&n=Tazq8zGc0yYUYrDl&q=85&s=6c1e21de7b53bd0a29683aca09c6f86e 840w, https://mintcdn.com/langchain-5e9cc07a/Tazq8zGc0yYUYrDl/oss/images/core_agent_loop.png?w=1100&fit=max&auto=format&n=Tazq8zGc0yYUYrDl&q=85&s=88bef556edba9869b759551c610c60f4 1100w, https://mintcdn.com/langchain-5e9cc07a/Tazq8zGc0yYUYrDl/oss/images/core_agent_loop.png?w=1650&fit=max&auto=format&n=Tazq8zGc0yYUYrDl&q=85&s=9b0bdd138e9548eeb5056dc0ed2d4a4b 1650w, https://mintcdn.com/langchain-5e9cc07a/Tazq8zGc0yYUYrDl/oss/images/core_agent_loop.png?w=2500&fit=max&auto=format&n=Tazq8zGc0yYUYrDl&q=85&s=41eb4f053ed5e6b0ba5bad2badf6d755 2500w" />
</div>

For more information, see [Agents](/oss/python/langchain/agents).

### Middleware

Middleware is the defining feature of [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent). It offers a highly customizable entry-point, raising the ceiling for what you can build.

Great agents require [context engineering](/oss/python/langchain/context-engineering): getting the right information to the model at the right time. Middleware helps you control dynamic prompts, conversation summarization, selective tool access, state management, and guardrails through a composable abstraction.

#### Prebuilt middleware

LangChain provides a few [prebuilt middlewares](/oss/python/langchain/middleware#built-in-middleware) for common patterns, including:

* [`PIIMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.PIIMiddleware): Redact sensitive information before sending to the model
* [`SummarizationMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.SummarizationMiddleware): Condense conversation history when it gets too long
* [`HumanInTheLoopMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.HumanInTheLoopMiddleware): Require approval for sensitive tool calls

```python  theme={null}
from langchain.agents import create_agent
from langchain.agents.middleware import (
    PIIMiddleware,
    SummarizationMiddleware,
    HumanInTheLoopMiddleware
)


agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[read_email, send_email],
    middleware=[
        PIIMiddleware("email", strategy="redact", apply_to_input=True),
        PIIMiddleware(
            "phone_number",
            detector=(
                r"(?:\+?\d{1,3}[\s.-]?)?"
                r"(?:\(?\d{2,4}\)?[\s.-]?)?"
                r"\d{3,4}[\s.-]?\d{4}"
			),
			strategy="block"
        ),
        SummarizationMiddleware(
            model="claude-sonnet-4-5-20250929",
            trigger={"tokens": 500}
        ),
        HumanInTheLoopMiddleware(
            interrupt_on={
                "send_email": {
                    "allowed_decisions": ["approve", "edit", "reject"]
                }
            }
        ),
    ]
)
```

#### Custom middleware

You can also build custom middleware to fit your needs. Middleware exposes hooks at each step in an agent's execution:

<div style={{ display: "flex", justifyContent: "center" }}>
  <img src="https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=eb4404b137edec6f6f0c8ccb8323eaf1" alt="Middleware flow diagram" className="rounded-lg" data-og-width="500" width="500" data-og-height="560" height="560" data-path="oss/images/middleware_final.png" data-optimize="true" data-opv="3" srcset="https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=280&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=483413aa87cf93323b0f47c0dd5528e8 280w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=560&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=41b7dd647447978ff776edafe5f42499 560w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=840&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=e9b14e264f68345de08ae76f032c52d4 840w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=1100&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=ec45e1932d1279b1beee4a4b016b473f 1100w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=1650&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=3bca5ebf8aa56632b8a9826f7f112e57 1650w, https://mintcdn.com/langchain-5e9cc07a/RAP6mjwE5G00xYsA/oss/images/middleware_final.png?w=2500&fit=max&auto=format&n=RAP6mjwE5G00xYsA&q=85&s=437f141d1266f08a95f030c2804691d9 2500w" />
</div>

Build custom middleware by implementing any of these hooks on a subclass of the [`AgentMiddleware`](https://reference.langchain.com/python/langchain/middleware/#langchain.agents.middleware.AgentMiddleware) class:

| Hook              | When it runs             | Use cases                               |
| ----------------- | ------------------------ | --------------------------------------- |
| `before_agent`    | Before calling the agent | Load memory, validate input             |
| `before_model`    | Before each LLM call     | Update prompts, trim messages           |
| `wrap_model_call` | Around each LLM call     | Intercept and modify requests/responses |
| `wrap_tool_call`  | Around each tool call    | Intercept and modify tool execution     |
| `after_model`     | After each LLM response  | Validate output, apply guardrails       |
| `after_agent`     | After agent completes    | Save results, cleanup                   |

Example custom middleware:

```python expandable theme={null}
from dataclasses import dataclass
from typing import Callable

from langchain_openai import ChatOpenAI

from langchain.agents.middleware import (
    AgentMiddleware,
    ModelRequest
)
from langchain.agents.middleware.types import ModelResponse

@dataclass
class Context:
    user_expertise: str = "beginner"

class ExpertiseBasedToolMiddleware(AgentMiddleware):
    def wrap_model_call(
        self,
        request: ModelRequest,
        handler: Callable[[ModelRequest], ModelResponse]
    ) -> ModelResponse:
        user_level = request.runtime.context.user_expertise

        if user_level == "expert":
            # More powerful model
            model = ChatOpenAI(model="gpt-5")
            tools = [advanced_search, data_analysis]
        else:
            # Less powerful model
            model = ChatOpenAI(model="gpt-5-nano")
            tools = [simple_search, basic_calculator]

        return handler(request.override(model=model, tools=tools))

agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[
        simple_search,
        advanced_search,
        basic_calculator,
        data_analysis
    ],
    middleware=[ExpertiseBasedToolMiddleware()],
    context_schema=Context
)
```

For more information, see [the complete middleware guide](/oss/python/langchain/middleware).

### Built on LangGraph

Because [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) is built on [LangGraph](/oss/python/langgraph), you automatically get built in support for long running and reliable agents via:

<CardGroup cols={2}>
  <Card title="Persistence" icon="database">
    Conversations automatically persist across sessions with built-in checkpointing
  </Card>

  <Card title="Streaming" icon="water">
    Stream tokens, tool calls, and reasoning traces in real-time
  </Card>

  <Card title="Human-in-the-loop" icon="hand">
    Pause agent execution for human approval before sensitive actions
  </Card>

  <Card title="Time travel" icon="clock-rotate-left">
    Rewind conversations to any point and explore alternate paths and prompts
  </Card>
</CardGroup>

You don't need to learn LangGraph to use these featuresâ€”they work out of the box.

### Structured output

[`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent) has improved structured output generation:

* **Main loop integration**: Structured output is now generated in the main loop instead of requiring an additional LLM call
* **Structured output strategy**: Models can choose between calling tools or using provider-side structured output generation
* **Cost reduction**: Eliminates extra expense from additional LLM calls

```python  theme={null}
from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy
from pydantic import BaseModel


class Weather(BaseModel):
    temperature: float
    condition: str

def weather_tool(city: str) -> str:
    """Get the weather for a city."""
    return f"it's sunny and 70 degrees in {city}"

agent = create_agent(
    "gpt-4o-mini",
    tools=[weather_tool],
    response_format=ToolStrategy(Weather)
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "What's the weather in SF?"}]
})

print(repr(result["structured_response"]))
# results in `Weather(temperature=70.0, condition='sunny')`
```

**Error handling**: Control error handling via the `handle_errors` parameter to `ToolStrategy`:

* **Parsing errors**: Model generates data that doesn't match desired structure
* **Multiple tool calls**: Model generates 2+ tool calls for structured output schemas

***

## Standard content blocks

<Note>
  Content block support is currently only available for the following integrations:

  * [`langchain-anthropic`](https://pypi.org/project/langchain-anthropic/)
  * [`langchain-aws`](https://pypi.org/project/langchain-aws/)
  * [`langchain-openai`](https://pypi.org/project/langchain-openai/)
  * [`langchain-google-genai`](https://pypi.org/project/langchain-google-genai/)
  * [`langchain-ollama`](https://pypi.org/project/langchain-ollama/)

  Broader support for content blocks will be rolled out gradually across more providers.
</Note>

The new [`content_blocks`](https://reference.langchain.com/python/langchain_core/language_models/#langchain_core.messages.BaseMessage.content_blocks) property introduces a standard representation for message content that works across providers:

```python  theme={null}
from langchain_anthropic import ChatAnthropic

model = ChatAnthropic(model="claude-sonnet-4-5-20250929")
response = model.invoke("What's the capital of France?")

# Unified access to content blocks
for block in response.content_blocks:
    if block["type"] == "reasoning":
        print(f"Model reasoning: {block['reasoning']}")
    elif block["type"] == "text":
        print(f"Response: {block['text']}")
    elif block["type"] == "tool_call":
        print(f"Tool call: {block['name']}({block['args']})")
```

### Benefits

* **Provider agnostic**: Access reasoning traces, citations, built-in tools (web search, code interpreters, etc.), and other features using the same API regardless of provider
* **Type safe**: Full type hints for all content block types
* **Backward compatible**: Standard content can be [loaded lazily](/oss/python/langchain/messages#standard-content-blocks), so there are no associated breaking changes

For more information, see our guide on [content blocks](/oss/python/langchain/messages#standard-content-blocks).

***

## Simplified package

LangChain v1 streamlines the [`langchain`](https://pypi.org/project/langchain/) package namespace to focus on essential building blocks for agents. The refined namespace exposes the most useful and relevant functionality:

### Namespace

| Module                                                                                | What's available                                                                                                                                                                                                                                                          | Notes                                                                                       |
| ------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- |
| [`langchain.agents`](https://reference.langchain.com/python/langchain/agents)         | [`create_agent`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.create_agent), [`AgentState`](https://reference.langchain.com/python/langchain/agents/#langchain.agents.AgentState)                                                            | Core agent creation functionality                                                           |
| [`langchain.messages`](https://reference.langchain.com/python/langchain/messages)     | Message types, [content blocks](https://reference.langchain.com/python/langchain/messages/#langchain.messages.ContentBlock), [`trim_messages`](https://reference.langchain.com/python/langchain/messages/#langchain.messages.trim_messages)                               | Re-exported from [`langchain-core`](https://reference.langchain.com/python/langchain_core/) |
| [`langchain.tools`](https://reference.langchain.com/python/langchain/tools)           | [`@tool`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.tool), [`BaseTool`](https://reference.langchain.com/python/langchain/tools/#langchain.tools.BaseTool), injection helpers                                                                | Re-exported from [`langchain-core`](https://reference.langchain.com/python/langchain_core/) |
| [`langchain.chat_models`](https://reference.langchain.com/python/langchain/models)    | [`init_chat_model`](https://reference.langchain.com/python/langchain/models/#langchain.chat_models.init_chat_model), [`BaseChatModel`](https://reference.langchain.com/python/langchain_core/language_models/#langchain_core.language_models.chat_models.BaseChatModel)   | Unified model initialization                                                                |
| [`langchain.embeddings`](https://reference.langchain.com/python/langchain/embeddings) | [`Embeddings`](https://reference.langchain.com/python/langchain_core/embeddings/#langchain_core.embeddings.embeddings.Embeddings), [`init_embeddings`](https://reference.langchain.com/python/langchain_core/embeddings/#langchain_core.embeddings.embeddings.Embeddings) | Embedding models                                                                            |

Most of these are re-exported from `langchain-core` for convenience, which gives you a focused API surface for building agents.

```python  theme={null}
# Agent building
from langchain.agents import create_agent

# Messages and content
from langchain.messages import AIMessage, HumanMessage

# Tools
from langchain.tools import tool

# Model initialization
from langchain.chat_models import init_chat_model
from langchain.embeddings import init_embeddings
```

### `langchain-classic`

Legacy functionality has moved to [`langchain-classic`](https://pypi.org/project/langchain-classic) to keep the core packages lean and focused.

**What's in `langchain-classic`:**

* Legacy chains and chain implementations
* Retrievers (e.g. `MultiQueryRetriever` or anything from the previous `langchain.retrievers` module)
* The indexing API
* The hub module (for managing prompts programmatically)
* [`langchain-community`](https://pypi.org/project/langchain-community) exports
* Other deprecated functionality

If you use any of this functionality, install [`langchain-classic`](https://pypi.org/project/langchain-classic):

<CodeGroup>
  ```bash pip theme={null}
  pip install langchain-classic
  ```

  ```bash uv theme={null}
  uv add langchain-classic
  ```
</CodeGroup>

Then update your imports:

```python  theme={null}
from langchain import ...  # [!code --]
from langchain_classic import ...  # [!code ++]

from langchain.chains import ...  # [!code --]
from langchain_classic.chains import ...  # [!code ++]

from langchain.retrievers import ...  # [!code --]
from langchain_classic.retrievers import ...  # [!code ++]

from langchain import hub  # [!code --]
from langchain_classic import hub  # [!code ++]
```

## Migration guide

See our [migration guide](/oss/python/migrate/langchain-v1) for help updating your code to LangChain v1.

## Reporting issues

Please report any issues discovered with 1.0 on [GitHub](https://github.com/langchain-ai/langchain/issues) using the `'v1'` [label](https://github.com/langchain-ai/langchain/issues?q=state%3Aopen%20label%3Av1).

## Additional resources

<CardGroup cols={3}>
  <Card title="LangChain 1.0" icon="rocket" href="https://blog.langchain.com/langchain-langchain-1-0-alpha-releases/">
    Read the announcement
  </Card>

  <Card title="Middleware guide" icon="puzzle-piece" href="https://blog.langchain.com/agent-middleware/">
    Deep dive into middleware
  </Card>

  <Card title="Agents Documentation" icon="book" href="/oss/python/langchain/agents" arrow>
    Full agent documentation
  </Card>

  <Card title="Message Content" icon="message" href="/oss/python/langchain/messages#message-content" arrow>
    New content blocks API
  </Card>

  <Card title="Migration guide" icon="arrow-right-arrow-left" href="/oss/python/migrate/langchain-v1" arrow>
    How to migrate to LangChain v1
  </Card>

  <Card title="GitHub" icon="github" href="https://github.com/langchain-ai/langchain">
    Report issues or contribute
  </Card>
</CardGroup>

## See also

* [Versioning](/oss/python/versioning) â€“ Understanding version numbers
* [Release policy](/oss/python/release-policy) â€“ Detailed release policies

***

<Callout icon="pen-to-square" iconType="regular">
  [Edit the source of this page on GitHub.](https://github.com/langchain-ai/docs/edit/main/src/oss/python/releases/langchain-v1.mdx)
</Callout>

<Tip icon="terminal" iconType="regular">
  [Connect these docs programmatically](/use-these-docs) to Claude, VSCode, and more via MCP for real-time answers.
</Tip>


---

> To find navigation and other pages in this documentation, fetch the llms.txt file at: https://docs.langchain.com/llms.txtã€‘
```

## Cursor with claude sonnet 4.5:

```
æˆ‘æ¥å¸®ä½ åˆ†æè¿™ä¸¤ä¸ªæ–‡ä»¶ä»¥åŠ LangChain v1.0 çš„ä¼˜åŠ¿ã€‚è®©æˆ‘å…ˆè¯»å–è¿™ä¸¤ä¸ªæ¼”ç¤ºæ–‡ä»¶ã€‚

[2 tools called]

ç°åœ¨æˆ‘æ¥å…¨é¢åˆ†æ LangChain v1.0 åœ¨ agent å¼€å‘ä¸­çš„ä¼˜åŠ¿ã€åŠ£åŠ¿å’Œé€‚ç”¨åœºæ™¯ã€‚

## ğŸ“Š ç»¼åˆåˆ†æï¼šLangChain v1.0 vs ç›´æ¥ä½¿ç”¨ DeepSeek API

### ğŸ¯ æ ¸å¿ƒé—®é¢˜ï¼šä¸ºä»€ä¹ˆä¸ç›´æ¥ç”¨ DeepSeek APIï¼Ÿ

ä»ä½ çš„ä¸¤ä¸ªæ¼”ç¤ºæ–‡ä»¶æ¥çœ‹ï¼Œæ ¸å¿ƒæ‰¹è¯„æ˜¯ï¼š
- **ç®€å•åœºæ™¯**ï¼ˆç¿»è¯‘ã€å•è½®å¯¹è¯ï¼‰ï¼šLangChain å¼•å…¥äº†å¤§é‡æŠ½è±¡ç±»ä½†æ²¡æœ‰æ˜æ˜¾ä¼˜åŠ¿
- **é€æ˜åº¦**ï¼šæ—§ç‰ˆ Agent API éšè—äº†å¤šæ¬¡ API è°ƒç”¨

ä½† **LangChain v1.0 çš„ `create_agent` ç¡®å®è§£å†³äº†ä¸€äº›å®é™…é—®é¢˜**ã€‚

---

## âœ… LangChain v1.0 çš„çœŸæ­£ä¼˜åŠ¿

### 1. **Agent å¾ªç¯çš„ç”Ÿäº§çº§å®ç°**

**ç›´æ¥ç”¨ DeepSeek API æ—¶çš„é—®é¢˜ï¼š**

```python
# ä½ éœ€è¦æ‰‹åŠ¨å®ç°æ•´ä¸ª ReAct å¾ªç¯
def manual_agent_loop(user_input):
    max_iterations = 10
    messages = [system_prompt, user_input]
    
    for i in range(max_iterations):
        # è°ƒç”¨ LLM
        response = client.chat.completions.create(...)
        
        # è§£æå“åº”ï¼ˆå¯èƒ½æ˜¯å·¥å…·è°ƒç”¨æˆ–æœ€ç»ˆç­”æ¡ˆï¼‰
        if is_tool_call(response):
            # æ‰§è¡Œå·¥å…·
            tool_result = execute_tool(...)
            # æ ¼å¼åŒ–å·¥å…·ç»“æœ
            messages.append(...)
        elif is_final_answer(response):
            return response
        else:
            # é”™è¯¯å¤„ç†ï¼Ÿé‡è¯•ï¼Ÿ
            ...
    
    # è¶…è¿‡æœ€å¤§è¿­ä»£æ¬¡æ•°æ€ä¹ˆåŠï¼Ÿ
    return handle_timeout()
```

**æ‰‹åŠ¨å®ç°éœ€è¦å¤„ç†ï¼š**
- âŒ å·¥å…·è°ƒç”¨çš„è§£æå’Œé”™è¯¯å¤„ç†
- âŒ å¾ªç¯ç»ˆæ­¢æ¡ä»¶
- âŒ è¶…æ—¶å’Œé‡è¯•é€»è¾‘
- âŒ æ¶ˆæ¯å†å²çš„æ ¼å¼åŒ–
- âŒ å·¥å…·ç»“æœçš„åºåˆ—åŒ–
- âŒ å¼‚å¸¸æƒ…å†µï¼ˆLLM ä¸æŒ‰æ ¼å¼è¾“å‡ºã€å·¥å…·æ‰§è¡Œå¤±è´¥ç­‰ï¼‰

**LangChain v1.0 çš„ `create_agent`ï¼š**

```python
agent = create_agent(
    model="claude-sonnet-4-5-20250929",
    tools=[search_web, analyze_data, send_email],
    system_prompt="You are a helpful research assistant."
)

result = agent.invoke({
    "messages": [{"role": "user", "content": "Research AI safety trends"}]
})
```

âœ… **å¼€ç®±å³ç”¨çš„ç”Ÿäº§çº§ Agent å¾ªç¯**
- æ ‡å‡†åŒ–çš„ tool calling æ ¼å¼ï¼ˆæ”¯æŒå¤šç§æ¨¡å‹ï¼‰
- å®Œå–„çš„é”™è¯¯å¤„ç†
- å¾ªç¯æ§åˆ¶å’Œç»ˆæ­¢æ¡ä»¶
- è‡ªåŠ¨çš„æ¶ˆæ¯å†å²ç®¡ç†

---

### 2. **Middlewareï¼šè¿™æ˜¯å…³é”®åˆ›æ–°ï¼**

**è¿™æ˜¯ç›´æ¥ç”¨ API å¾ˆéš¾å®ç°çš„æ ¸å¿ƒä¼˜åŠ¿ã€‚**

#### åœºæ™¯ 1ï¼šè‡ªåŠ¨è„±æ•å¤„ç†ï¼ˆPII Middlewareï¼‰

```python
agent = create_agent(
    model="deepseek-chat",
    tools=[send_email, database_query],
    middleware=[
        PIIMiddleware("email", strategy="redact", apply_to_input=True),
        PIIMiddleware("phone_number", strategy="block")
    ]
)
```

**æ‰‹åŠ¨å®ç°æ—¶ï¼š**
```python
# ä½ éœ€è¦åœ¨æ¯æ¬¡è°ƒç”¨å‰æ‰‹åŠ¨æ£€æŸ¥
def manual_pii_check(message):
    if contains_email(message):
        message = redact_email(message)
    if contains_phone(message):
        raise BlockedException()
    return message

# åœ¨æ¯æ¬¡ API è°ƒç”¨å‰éƒ½è¦è®°å¾—è°ƒç”¨
messages = [manual_pii_check(msg) for msg in messages]
response = client.chat.completions.create(...)
```

âŒ å®¹æ˜“å¿˜è®°
âŒ ä»£ç é‡å¤
âŒ éš¾ä»¥ç»´æŠ¤

#### åœºæ™¯ 2ï¼šå¯¹è¯æ‘˜è¦ï¼ˆSummarization Middlewareï¼‰

```python
agent = create_agent(
    model="deepseek-chat",
    tools=[...],
    middleware=[
        SummarizationMiddleware(
            model="claude-sonnet-4-5-20250929",
            trigger={"tokens": 500}  # è‡ªåŠ¨è§¦å‘æ‘˜è¦
        )
    ]
)
```

**æ‰‹åŠ¨å®ç°æ—¶ï¼š**
```python
# æ¯æ¬¡å¯¹è¯å‰æ£€æŸ¥ token æ•°
def check_and_summarize(messages):
    if count_tokens(messages) > 500:
        summary = summarize_messages(messages[:-2])
        messages = [messages[0], summary] + messages[-2:]
    return messages

# åœ¨æ¯ä¸ªå¯¹è¯å¾ªç¯ä¸­éƒ½è¦è°ƒç”¨
messages = check_and_summarize(messages)
response = client.chat.completions.create(...)
```

#### åœºæ™¯ 3ï¼šäººå·¥å®¡æ‰¹ï¼ˆHuman-in-the-Loop Middlewareï¼‰

```python
agent = create_agent(
    model="deepseek-chat",
    tools=[send_email, delete_database],
    middleware=[
        HumanInTheLoopMiddleware(
            interrupt_on={
                "send_email": {"allowed_decisions": ["approve", "edit", "reject"]},
                "delete_database": {"allowed_decisions": ["approve", "reject"]}
            }
        )
    ]
)
```

**æ‰‹åŠ¨å®ç°æ—¶ï¼š**
```python
# éœ€è¦å®ç°æš‚åœ/æ¢å¤æœºåˆ¶
def execute_with_approval(tool_call):
    if tool_call.name in ["send_email", "delete_database"]:
        approval = input(f"Approve {tool_call.name}? (y/n)")
        if approval != 'y':
            return "Rejected by user"
    return execute_tool(tool_call)

# è¿˜éœ€è¦å®ç°çŠ¶æ€ä¿å­˜/æ¢å¤...
```

---

### 3. **Built on LangGraphï¼šè‡ªåŠ¨è·å¾—ä¼ä¸šçº§ç‰¹æ€§**

```python
agent = create_agent(
    model="deepseek-chat",
    tools=[...],
    # ğŸ‘‡ è¿™äº›ç‰¹æ€§è‡ªåŠ¨å¯ç”¨
)

# âœ… æŒä¹…åŒ–ï¼šå¯¹è¯è‡ªåŠ¨ä¿å­˜
agent.invoke({"messages": [...]}, config={"thread_id": "user_123"})

# âœ… æ—¶é—´æ—…è¡Œï¼šå›æº¯åˆ°ä»»æ„çŠ¶æ€
agent.get_state(checkpoint_id="...")

# âœ… æµå¼è¾“å‡ºï¼šå®æ—¶çœ‹åˆ°å·¥å…·è°ƒç”¨
for chunk in agent.stream({...}):
    print(chunk)

# âœ… äººå·¥ä»‹å…¥ï¼šæš‚åœ agent ç­‰å¾…å®¡æ‰¹
agent.invoke({...})  # åœ¨éœ€è¦æ—¶è‡ªåŠ¨æš‚åœ
agent.update_state({"approved": True})  # äººå·¥å®¡æ‰¹åç»§ç»­
```

**æ‰‹åŠ¨å®ç°æ—¶ï¼š**
```python
# ä½ éœ€è¦è‡ªå·±å®ç°ï¼š
# - çŠ¶æ€åºåˆ—åŒ–/ååºåˆ—åŒ–
# - æ£€æŸ¥ç‚¹ç®¡ç†
# - æµå¼è¾“å‡ºçš„å¼‚æ­¥å¤„ç†
# - æš‚åœ/æ¢å¤æœºåˆ¶
# è¿™äº›éƒ½æ˜¯å¤æ‚çš„ç³»ç»Ÿçº§åŠŸèƒ½ï¼
```

---

### 4. **æ¨¡å‹æ— å…³æ€§ï¼ˆè·¨æä¾›å•†å·¥å…·è°ƒç”¨ï¼‰**

```python
# åŒä¸€å¥—ä»£ç æ”¯æŒå¤šä¸ªæ¨¡å‹
agent = create_agent(
    model="deepseek-chat",  # æˆ– "gpt-4o"ã€"claude-3-5-sonnet"
    tools=[search, calculator],
)
```

**é—®é¢˜ï¼š** ä¸åŒæ¨¡å‹çš„ tool calling æ ¼å¼ä¸åŒï¼š
- OpenAIï¼š`tools` + `tool_choice`
- Anthropicï¼šä¸åŒçš„ JSON schema
- DeepSeekï¼šåˆæ˜¯å¦ä¸€ç§æ ¼å¼

LangChain è‡ªåŠ¨å¤„ç†è¿™äº›å·®å¼‚ã€‚

---

### 5. **æ ‡å‡†åŒ–çš„ Content Blocks**

```python
response = model.invoke("What's the capital of France?")

for block in response.content_blocks:
    if block["type"] == "reasoning":  # Claude çš„æ¨ç†è¿‡ç¨‹
        print(f"Reasoning: {block['reasoning']}")
    elif block["type"] == "text":
        print(f"Answer: {block['text']}")
    elif block["type"] == "tool_call":
        print(f"Tool: {block['name']}({block['args']})")
```

**ä¼˜åŠ¿ï¼š** ç»Ÿä¸€çš„ API è®¿é—®ä¸åŒæ¨¡å‹çš„ç‰¹æ®ŠåŠŸèƒ½ï¼ˆæ¨ç†ã€å¼•ç”¨ã€å†…ç½®å·¥å…·ç­‰ï¼‰

---

## âŒ LangChain v1.0 çš„åŠ£åŠ¿

### 1. **ç®€å•åœºæ™¯ä¸‹ä»ç„¶è¿‡åº¦è®¾è®¡**

ä½ çš„ `langchain_critique_demo.py` æŒ‡å‡ºçš„é—®é¢˜åœ¨ v1.0 ä¸­**ä¾ç„¶å­˜åœ¨**ï¼š

```python
# å•æ¬¡ç¿»è¯‘ï¼šLangChain æ²¡æœ‰ä¼˜åŠ¿
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

chat = ChatOpenAI(temperature=0)
result = chat.invoke([HumanMessage(content="Translate...")])

# vs ç›´æ¥ç”¨ APIï¼ˆæ›´ç®€å•ï¼‰
response = client.chat.completions.create(
    model="deepseek-chat",
    messages=[{"role": "user", "content": "Translate..."}]
)
```

### 2. **å­¦ä¹ æ›²çº¿ä»ç„¶é™¡å³­**

è™½ç„¶ `create_agent` æ¯”æ—§çš„ `initialize_agent` ç®€å•ï¼Œä½†ï¼š
- Middleware æ¦‚å¿µéœ€è¦å­¦ä¹ 
- LangGraph çš„åº•å±‚æœºåˆ¶ï¼ˆcheckpointã€stateï¼‰
- ä¸åŒçš„æ¶ˆæ¯ç±»å‹å’Œ content blocks

### 3. **æŠ½è±¡ç¨ï¼ˆAbstraction Taxï¼‰**

```python
# LangChain
result = agent.invoke({"messages": [{"role": "user", "content": "..."}]})

# å†…éƒ¨åšäº†ä»€ä¹ˆï¼Ÿ
# - æ¶ˆæ¯æ ¼å¼è½¬æ¢
# - Middleware è°ƒç”¨é“¾
# - å·¥å…·ç»‘å®šå’Œè§£æ
# - çŠ¶æ€ç®¡ç†
# è¿™äº›éƒ½æœ‰æ€§èƒ½å¼€é”€
```

### 4. **ä¾èµ–è¿‡å¤š**

```bash
# å®‰è£… LangChain agent éœ€è¦ï¼š
pip install langchain langchain-openai langchain-core langgraph

# vs ç›´æ¥ç”¨ API
pip install openai
```

### 5. **è°ƒè¯•å›°éš¾**

å½“å‡ºé”™æ—¶ï¼š
- é”™è¯¯å¯èƒ½å‘ç”Ÿåœ¨å¤šä¸ªæŠ½è±¡å±‚
- éš¾ä»¥å®šä½æ˜¯ LLMã€å·¥å…·ã€è¿˜æ˜¯ middleware çš„é—®é¢˜
- Stack trace å¾ˆé•¿

---

## ğŸ¯ é€‚ç”¨åœºæ™¯åˆ†æ

### âœ… åº”è¯¥ä½¿ç”¨ LangChain v1.0 çš„åœºæ™¯

#### 1. **å¤æ‚çš„å¤šå·¥å…· Agent**
```python
# åœºæ™¯ï¼šéœ€è¦å¤šæ¬¡å·¥å…·è°ƒç”¨ã€é”™è¯¯å¤„ç†ã€å¾ªç¯æ§åˆ¶
agent = create_agent(
    model="deepseek-chat",
    tools=[
        search_web,      # å¯èƒ½å¤±è´¥
        analyze_data,    # éœ€è¦é‡è¯•
        send_email,      # éœ€è¦äººå·¥å®¡æ‰¹
        query_database   # éœ€è¦è„±æ•
    ],
    middleware=[
        PIIMiddleware(...),
        HumanInTheLoopMiddleware(...),
        SummarizationMiddleware(...)
    ]
)
```

**æ‰‹åŠ¨å®ç°æˆæœ¬å¤ªé«˜ï¼**

#### 2. **éœ€è¦ä¼ä¸šçº§ç‰¹æ€§**
- å¯¹è¯æŒä¹…åŒ–å’Œæ¢å¤
- äººå·¥å®¡æ‰¹æµç¨‹
- å®¡è®¡æ—¥å¿—
- æ—¶é—´æ—…è¡Œè°ƒè¯•

#### 3. **éœ€è¦è·¨æ¨¡å‹å…¼å®¹**
- åŒä¸€å¥—ä»£ç æ”¯æŒ OpenAIã€Anthropicã€DeepSeek ç­‰
- åˆ©ç”¨ä¸åŒæ¨¡å‹çš„ç‰¹æ®ŠåŠŸèƒ½ï¼ˆæ¨ç†ã€å¼•ç”¨ç­‰ï¼‰

#### 4. **é•¿æœŸç»´æŠ¤çš„ç”Ÿäº§ç³»ç»Ÿ**
- éœ€è¦æ ‡å‡†åŒ–çš„ agent æ¶æ„
- å›¢é˜Ÿåä½œï¼ˆç»Ÿä¸€çš„ API å’Œæ¨¡å¼ï¼‰

---

### âŒ ä¸åº”è¯¥ä½¿ç”¨ LangChain çš„åœºæ™¯

#### 1. **ç®€å•çš„å•æ¬¡ LLM è°ƒç”¨**
```python
# âŒ ä¸è¦ç”¨ LangChain
from langchain_openai import ChatOpenAI
result = ChatOpenAI().invoke("Translate this...")

# âœ… ç›´æ¥ç”¨ API
response = client.chat.completions.create(...)
```

#### 2. **ç®€å•çš„å¯¹è¯å†å²**
```python
# âŒ ä¸éœ€è¦ RunnableWithMessageHistory
# âœ… ç”¨åˆ—è¡¨å°±å¤Ÿäº†
messages = []
messages.append({"role": "user", "content": "..."})
response = client.chat.completions.create(messages=messages)
messages.append({"role": "assistant", "content": response.content})
```

#### 3. **åŸå‹å’Œå¿«é€Ÿå®éªŒ**
- LangChain çš„è®¾ç½®æ—¶é—´ > ç›´æ¥å†™ä»£ç çš„æ—¶é—´

#### 4. **æ€§èƒ½æ•æ„Ÿçš„åœºæ™¯**
- LangChain çš„æŠ½è±¡å±‚æœ‰æ€§èƒ½å¼€é”€
- ç›´æ¥ç”¨ API æ›´å¿«

#### 5. **éœ€è¦å®Œå…¨æ§åˆ¶**
- éœ€è¦è‡ªå®šä¹‰ç‰¹æ®Šçš„å·¥å…·è°ƒç”¨æ ¼å¼
- éœ€è¦ä¼˜åŒ–æ¯ä¸€æ¬¡ API è°ƒç”¨

---

## ğŸ“‹ å†³ç­–æ ‘

```
ä½ çš„ä»»åŠ¡æ˜¯æ„å»º Agentï¼Ÿ
â”œâ”€ å¦ â†’ âŒ ä¸è¦ç”¨ LangChainï¼Œç›´æ¥ç”¨ API
â””â”€ æ˜¯
   â”œâ”€ ç®€å•çš„ ReAct å¾ªç¯ï¼ˆ< 3 ä¸ªå·¥å…·ï¼Œæ— å¤æ‚é€»è¾‘ï¼‰ï¼Ÿ
   â”‚  â”œâ”€ æ˜¯ â†’ âŒ è€ƒè™‘æ‰‹åŠ¨å®ç°ï¼ˆ50-100è¡Œä»£ç ï¼‰
   â”‚  â””â”€ å¦ â†’ ç»§ç»­
   â”‚
   â”œâ”€ éœ€è¦ä¼ä¸šçº§ç‰¹æ€§ï¼ˆæŒä¹…åŒ–ã€å®¡æ‰¹ã€å®¡è®¡ï¼‰ï¼Ÿ
   â”‚  â”œâ”€ æ˜¯ â†’ âœ… ä½¿ç”¨ LangChain v1.0
   â”‚  â””â”€ å¦ â†’ ç»§ç»­
   â”‚
   â”œâ”€ éœ€è¦å¤æ‚çš„ middlewareï¼ˆè„±æ•ã€æ‘˜è¦ã€åŠ¨æ€æç¤ºï¼‰ï¼Ÿ
   â”‚  â”œâ”€ æ˜¯ â†’ âœ… ä½¿ç”¨ LangChain v1.0
   â”‚  â””â”€ å¦ â†’ ç»§ç»­
   â”‚
   â”œâ”€ éœ€è¦è·¨å¤šä¸ª LLM æä¾›å•†ï¼Ÿ
   â”‚  â”œâ”€ æ˜¯ â†’ âœ… ä½¿ç”¨ LangChain v1.0
   â”‚  â””â”€ å¦ â†’ ç»§ç»­
   â”‚
   â”œâ”€ å›¢é˜Ÿåä½œï¼Œéœ€è¦æ ‡å‡†åŒ–æ¶æ„ï¼Ÿ
   â”‚  â”œâ”€ æ˜¯ â†’ âœ… ä½¿ç”¨ LangChain v1.0
   â”‚  â””â”€ å¦ â†’ âŒ æ‰‹åŠ¨å®ç°æˆ–ç”¨æ›´è½»é‡çš„åº“
```

---

## ğŸ“ æ€»ç»“

### LangChain v1.0 çš„å®šä½

**ä¸æ˜¯**ï¼šæ‰€æœ‰ LLM åº”ç”¨çš„é»˜è®¤é€‰æ‹©
**è€Œæ˜¯**ï¼š**å¤æ‚ agent åº”ç”¨çš„ç”Ÿäº§çº§æ¡†æ¶**

### å…³é”®æ”¹è¿›ï¼ˆç›¸æ¯”æ—§ç‰ˆï¼‰

âœ… **é€æ˜åº¦æå‡**ï¼š`create_agent` æ¯”æ—§çš„ `initialize_agent` æ›´æ¸…æ™°
âœ… **Middleware åˆ›æ–°**ï¼šè§£å†³äº†å®é™…çš„ä¼ä¸šçº§éœ€æ±‚
âœ… **ç®€åŒ–å‘½åç©ºé—´**ï¼šå»é™¤äº†å¤§é‡é—ç•™åŠŸèƒ½
âœ… **LangGraph é›†æˆ**ï¼šè‡ªåŠ¨è·å¾—æŒä¹…åŒ–ã€æ—¶é—´æ—…è¡Œç­‰ç‰¹æ€§

### æ ¸å¿ƒæ‰¹è¯„ä¾ç„¶æˆç«‹

âŒ **ç®€å•åœºæ™¯ä¸‹è¿‡åº¦è®¾è®¡**ï¼šä½ çš„ `langchain_critique_demo.py` æŒ‡å‡ºçš„é—®é¢˜ä»ç„¶å­˜åœ¨
âŒ **å­¦ä¹ æ›²çº¿**ï¼šè™½ç„¶æ”¹è¿›ï¼Œä½†ä»éœ€æŠ•å…¥æ—¶é—´å­¦ä¹ 
âŒ **æŠ½è±¡ç¨**ï¼šæ€§èƒ½å¼€é”€å’Œè°ƒè¯•å›°éš¾

### æœ€ç»ˆå»ºè®®

```python
# 80% çš„æƒ…å†µï¼šç›´æ¥ç”¨ API
if task_is_simple():
    use_deepseek_api_directly()

# 20% çš„æƒ…å†µï¼šä½¿ç”¨ LangChain v1.0
elif need_production_agent_with_complex_features():
    use_langchain_create_agent()
```

**LangChain v1.0 çš„ä»·å€¼åœ¨äºå®ƒæä¾›äº†ç›´æ¥ç”¨ API å¾ˆéš¾å®ç°çš„ä¼ä¸šçº§ agent ç‰¹æ€§ï¼Œè€Œä¸æ˜¯ç®€åŒ–ç®€å•çš„ LLM è°ƒç”¨ã€‚**
```